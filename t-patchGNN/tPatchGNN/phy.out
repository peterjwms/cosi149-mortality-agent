/home/zepenghu/literature_project/t-PatchGNN/tPatchGNN/run_models.py
2024-09-12 21:39:15
run_models.py --dataset physionet --state def --history 24 --patience 10 --batch_size 32 --lr 1e-3 --patch_size 8 --stride 8 --nhead 1 --tf_layer 1 --nlayer 1 --te_dim 10 --node_dim 10 --hid_dim 64 --outlayer Linear --seed 1 --gpu 0
Namespace(state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=1, epoch=1000, patience=10, history=24, patch_size=8.0, stride=8.0, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='tPatchGNN', outlayer='Linear', hid_dim=64, te_dim=10, node_dim=10, gpu='0', npatch=3, device=device(type='cuda'), PID=25608, ndim=41)
Batch 0 Train - Loss (one batch): 0.17836
Batch 10 Train - Loss (one batch): 0.06686
Batch 20 Train - Loss (one batch): 0.06397
Batch 30 Train - Loss (one batch): 0.04338
Batch 40 Train - Loss (one batch): 0.01733
Batch 50 Train - Loss (one batch): 0.01694
Batch 60 Train - Loss (one batch): 0.02395
Batch 70 Train - Loss (one batch): 0.01205
Batch 80 Train - Loss (one batch): 0.01512
Batch 90 Train - Loss (one batch): 0.01175
Batch 100 Train - Loss (one batch): 0.01388
Batch 110 Train - Loss (one batch): 0.00916
Batch 120 Train - Loss (one batch): 0.00940
Batch 130 Train - Loss (one batch): 0.00978
Batch 140 Train - Loss (one batch): 0.00685
Batch 150 Train - Loss (one batch): 0.01008
Batch 160 Train - Loss (one batch): 0.00841
Batch 170 Train - Loss (one batch): 0.00799
Batch 180 Train - Loss (one batch): 0.00676
Batch 190 Train - Loss (one batch): 0.00893
Batch 200 Train - Loss (one batch): 0.00616
Batch 210 Train - Loss (one batch): 0.01528
Batch 220 Train - Loss (one batch): 0.00846
- Epoch 000, ExpID 66645
Train - Loss (one batch): 0.01085
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00809, 0.00809, 0.08994, 0.05167, 173.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.00793, 0.00793, 0.08906, 0.05188, 191.56%
Time spent: 30.21s
Batch 0 Train - Loss (one batch): 0.00772
Batch 10 Train - Loss (one batch): 0.00524
Batch 20 Train - Loss (one batch): 0.01061
Batch 30 Train - Loss (one batch): 0.00851
Batch 40 Train - Loss (one batch): 0.00721
Batch 50 Train - Loss (one batch): 0.00604
Batch 60 Train - Loss (one batch): 0.00594
Batch 70 Train - Loss (one batch): 0.00476
Batch 80 Train - Loss (one batch): 0.00598
Batch 90 Train - Loss (one batch): 0.00633
Batch 100 Train - Loss (one batch): 0.00786
Batch 110 Train - Loss (one batch): 0.00555
Batch 120 Train - Loss (one batch): 0.00584
Batch 130 Train - Loss (one batch): 0.00439
Batch 140 Train - Loss (one batch): 0.00692
Batch 150 Train - Loss (one batch): 0.00601
Batch 160 Train - Loss (one batch): 0.00422
Batch 170 Train - Loss (one batch): 0.00309
Batch 180 Train - Loss (one batch): 0.00524
Batch 190 Train - Loss (one batch): 0.00467
Batch 200 Train - Loss (one batch): 0.00614
Batch 210 Train - Loss (one batch): 0.00401
Batch 220 Train - Loss (one batch): 0.00614
- Epoch 001, ExpID 66645
Train - Loss (one batch): 0.00806
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00673, 0.00673, 0.08203, 0.04417, 89.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.00643, 0.00643, 0.08017, 0.04439, 95.65%
Time spent: 18.84s
Batch 0 Train - Loss (one batch): 0.00486
Batch 10 Train - Loss (one batch): 0.00503
Batch 20 Train - Loss (one batch): 0.00443
Batch 30 Train - Loss (one batch): 0.00654
Batch 40 Train - Loss (one batch): 0.00561
Batch 50 Train - Loss (one batch): 0.00786
Batch 60 Train - Loss (one batch): 0.00631
Batch 70 Train - Loss (one batch): 0.00532
Batch 80 Train - Loss (one batch): 0.00644
Batch 90 Train - Loss (one batch): 0.00478
Batch 100 Train - Loss (one batch): 0.00505
Batch 110 Train - Loss (one batch): 0.00388
Batch 120 Train - Loss (one batch): 0.01289
Batch 130 Train - Loss (one batch): 0.00652
Batch 140 Train - Loss (one batch): 0.00520
Batch 150 Train - Loss (one batch): 0.00865
Batch 160 Train - Loss (one batch): 0.00609
Batch 170 Train - Loss (one batch): 0.00456
Batch 180 Train - Loss (one batch): 0.00590
Batch 190 Train - Loss (one batch): 0.00739
Batch 200 Train - Loss (one batch): 0.00527
Batch 210 Train - Loss (one batch): 0.01311
Batch 220 Train - Loss (one batch): 0.00566
- Epoch 002, ExpID 66645
Train - Loss (one batch): 0.00518
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00641, 0.00641, 0.08004, 0.04310, 60.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.00616, 0.00616, 0.07847, 0.04340, 59.40%
Time spent: 18.35s
Batch 0 Train - Loss (one batch): 0.00425
Batch 10 Train - Loss (one batch): 0.00450
Batch 20 Train - Loss (one batch): 0.01447
Batch 30 Train - Loss (one batch): 0.00554
Batch 40 Train - Loss (one batch): 0.00555
Batch 50 Train - Loss (one batch): 0.00557
Batch 60 Train - Loss (one batch): 0.00553
Batch 70 Train - Loss (one batch): 0.00444
Batch 80 Train - Loss (one batch): 0.00577
Batch 90 Train - Loss (one batch): 0.00368
Batch 100 Train - Loss (one batch): 0.00593
Batch 110 Train - Loss (one batch): 0.00523
Batch 120 Train - Loss (one batch): 0.00632
Batch 130 Train - Loss (one batch): 0.00566
Batch 140 Train - Loss (one batch): 0.00526
Batch 150 Train - Loss (one batch): 0.00930
Batch 160 Train - Loss (one batch): 0.00718
Batch 170 Train - Loss (one batch): 0.00450
Batch 180 Train - Loss (one batch): 0.00350
Batch 190 Train - Loss (one batch): 0.00462
Batch 200 Train - Loss (one batch): 0.00606
Batch 210 Train - Loss (one batch): 0.00389
Batch 220 Train - Loss (one batch): 0.00425
- Epoch 003, ExpID 66645
Train - Loss (one batch): 0.00389
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00623, 0.00623, 0.07894, 0.04186, 70.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.00602, 0.00602, 0.07761, 0.04191, 69.82%
Time spent: 18.29s
Batch 0 Train - Loss (one batch): 0.00452
Batch 10 Train - Loss (one batch): 0.00369
Batch 20 Train - Loss (one batch): 0.00514
Batch 30 Train - Loss (one batch): 0.00602
Batch 40 Train - Loss (one batch): 0.00532
Batch 50 Train - Loss (one batch): 0.00402
Batch 60 Train - Loss (one batch): 0.00432
Batch 70 Train - Loss (one batch): 0.00404
Batch 80 Train - Loss (one batch): 0.00575
Batch 90 Train - Loss (one batch): 0.00537
Batch 100 Train - Loss (one batch): 0.00960
Batch 110 Train - Loss (one batch): 0.00438
Batch 120 Train - Loss (one batch): 0.00526
Batch 130 Train - Loss (one batch): 0.00636
Batch 140 Train - Loss (one batch): 0.00681
Batch 150 Train - Loss (one batch): 0.00554
Batch 160 Train - Loss (one batch): 0.00551
Batch 170 Train - Loss (one batch): 0.00696
Batch 180 Train - Loss (one batch): 0.00474
Batch 190 Train - Loss (one batch): 0.00314
Batch 200 Train - Loss (one batch): 0.00313
Batch 210 Train - Loss (one batch): 0.01048
Batch 220 Train - Loss (one batch): 0.00567
- Epoch 004, ExpID 66645
Train - Loss (one batch): 0.00476
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00694, 0.00694, 0.08328, 0.04434, 57.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.00602, 0.00602, 0.07761, 0.04191, 69.82%
Time spent: 16.02s
Batch 0 Train - Loss (one batch): 0.00531
Batch 10 Train - Loss (one batch): 0.00460
Batch 20 Train - Loss (one batch): 0.00466
Batch 30 Train - Loss (one batch): 0.00759
Batch 40 Train - Loss (one batch): 0.00449
Batch 50 Train - Loss (one batch): 0.00529
Batch 60 Train - Loss (one batch): 0.00479
Batch 70 Train - Loss (one batch): 0.01041
Batch 80 Train - Loss (one batch): 0.00459
Batch 90 Train - Loss (one batch): 0.00602
Batch 100 Train - Loss (one batch): 0.00436
Batch 110 Train - Loss (one batch): 0.00924
Batch 120 Train - Loss (one batch): 0.00433
Batch 130 Train - Loss (one batch): 0.00696
Batch 140 Train - Loss (one batch): 0.00421
Batch 150 Train - Loss (one batch): 0.00545
Batch 160 Train - Loss (one batch): 0.00467
Batch 170 Train - Loss (one batch): 0.00564
Batch 180 Train - Loss (one batch): 0.00446
Batch 190 Train - Loss (one batch): 0.00380
Batch 200 Train - Loss (one batch): 0.00349
Batch 210 Train - Loss (one batch): 0.00408
Batch 220 Train - Loss (one batch): 0.00642
- Epoch 005, ExpID 66645
Train - Loss (one batch): 0.00450
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00688, 0.00688, 0.08292, 0.04572, 133.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.00602, 0.00602, 0.07761, 0.04191, 69.82%
Time spent: 16.33s
Batch 0 Train - Loss (one batch): 0.00461
Batch 10 Train - Loss (one batch): 0.00450
Batch 20 Train - Loss (one batch): 0.00388
Batch 30 Train - Loss (one batch): 0.00356
Batch 40 Train - Loss (one batch): 0.00864
Batch 50 Train - Loss (one batch): 0.00417
Batch 60 Train - Loss (one batch): 0.00372
Batch 70 Train - Loss (one batch): 0.00634
Batch 80 Train - Loss (one batch): 0.00448
Batch 90 Train - Loss (one batch): 0.00573
Batch 100 Train - Loss (one batch): 0.00665
Batch 110 Train - Loss (one batch): 0.00464
Batch 120 Train - Loss (one batch): 0.00335
Batch 130 Train - Loss (one batch): 0.00402
Batch 140 Train - Loss (one batch): 0.00577
Batch 150 Train - Loss (one batch): 0.00374
Batch 160 Train - Loss (one batch): 0.00363
Batch 170 Train - Loss (one batch): 0.00477
Batch 180 Train - Loss (one batch): 0.00415
Batch 190 Train - Loss (one batch): 0.00418
Batch 200 Train - Loss (one batch): 0.00524
Batch 210 Train - Loss (one batch): 0.00395
Batch 220 Train - Loss (one batch): 0.00598
- Epoch 006, ExpID 66645
Train - Loss (one batch): 0.00525
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00618, 0.00618, 0.07858, 0.04193, 77.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00586, 0.00586, 0.07656, 0.04213, 77.14%
Time spent: 18.93s
Batch 0 Train - Loss (one batch): 0.00649
Batch 10 Train - Loss (one batch): 0.00368
Batch 20 Train - Loss (one batch): 0.00519
Batch 30 Train - Loss (one batch): 0.00476
Batch 40 Train - Loss (one batch): 0.00452
Batch 50 Train - Loss (one batch): 0.00332
Batch 60 Train - Loss (one batch): 0.00496
Batch 70 Train - Loss (one batch): 0.00470
Batch 80 Train - Loss (one batch): 0.00583
Batch 90 Train - Loss (one batch): 0.00576
Batch 100 Train - Loss (one batch): 0.00597
Batch 110 Train - Loss (one batch): 0.00348
Batch 120 Train - Loss (one batch): 0.00380
Batch 130 Train - Loss (one batch): 0.00414
Batch 140 Train - Loss (one batch): 0.00519
Batch 150 Train - Loss (one batch): 0.00519
Batch 160 Train - Loss (one batch): 0.00827
Batch 170 Train - Loss (one batch): 0.00262
Batch 180 Train - Loss (one batch): 0.00465
Batch 190 Train - Loss (one batch): 0.00553
Batch 200 Train - Loss (one batch): 0.00347
Batch 210 Train - Loss (one batch): 0.00380
Batch 220 Train - Loss (one batch): 0.00369
- Epoch 007, ExpID 66645
Train - Loss (one batch): 0.00568
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00692, 0.00692, 0.08316, 0.04704, 82.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00586, 0.00586, 0.07656, 0.04213, 77.14%
Time spent: 16.32s
Batch 0 Train - Loss (one batch): 0.00456
Batch 10 Train - Loss (one batch): 0.00365
Batch 20 Train - Loss (one batch): 0.00364
Batch 30 Train - Loss (one batch): 0.00504
Batch 40 Train - Loss (one batch): 0.00668
Batch 50 Train - Loss (one batch): 0.00882
Batch 60 Train - Loss (one batch): 0.00536
Batch 70 Train - Loss (one batch): 0.00388
Batch 80 Train - Loss (one batch): 0.00421
Batch 90 Train - Loss (one batch): 0.00415
Batch 100 Train - Loss (one batch): 0.00504
Batch 110 Train - Loss (one batch): 0.00531
Batch 120 Train - Loss (one batch): 0.00517
Batch 130 Train - Loss (one batch): 0.00466
Batch 140 Train - Loss (one batch): 0.00485
Batch 150 Train - Loss (one batch): 0.00401
Batch 160 Train - Loss (one batch): 0.00515
Batch 170 Train - Loss (one batch): 0.00448
Batch 180 Train - Loss (one batch): 0.00410
Batch 190 Train - Loss (one batch): 0.00388
Batch 200 Train - Loss (one batch): 0.00368
Batch 210 Train - Loss (one batch): 0.00486
Batch 220 Train - Loss (one batch): 0.00691
- Epoch 008, ExpID 66645
Train - Loss (one batch): 0.01151
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00612, 0.00612, 0.07823, 0.04224, 128.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.00586, 0.00586, 0.07652, 0.04226, 130.77%
Time spent: 19.10s
Batch 0 Train - Loss (one batch): 0.00346
Batch 10 Train - Loss (one batch): 0.00319
Batch 20 Train - Loss (one batch): 0.00355
Batch 30 Train - Loss (one batch): 0.00555
Batch 40 Train - Loss (one batch): 0.00455
Batch 50 Train - Loss (one batch): 0.00514
Batch 60 Train - Loss (one batch): 0.00465
Batch 70 Train - Loss (one batch): 0.00682
Batch 80 Train - Loss (one batch): 0.00514
Batch 90 Train - Loss (one batch): 0.00294
Batch 100 Train - Loss (one batch): 0.00503
Batch 110 Train - Loss (one batch): 0.00446
Batch 120 Train - Loss (one batch): 0.00706
Batch 130 Train - Loss (one batch): 0.00581
Batch 140 Train - Loss (one batch): 0.00440
Batch 150 Train - Loss (one batch): 0.00396
Batch 160 Train - Loss (one batch): 0.00383
Batch 170 Train - Loss (one batch): 0.00564
Batch 180 Train - Loss (one batch): 0.00406
Batch 190 Train - Loss (one batch): 0.00477
Batch 200 Train - Loss (one batch): 0.00516
Batch 210 Train - Loss (one batch): 0.00377
Batch 220 Train - Loss (one batch): 0.00666
- Epoch 009, ExpID 66645
Train - Loss (one batch): 0.00456
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00597, 0.00597, 0.07730, 0.03973, 113.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.00576, 0.00576, 0.07589, 0.03994, 116.02%
Time spent: 19.17s
Batch 0 Train - Loss (one batch): 0.00411
Batch 10 Train - Loss (one batch): 0.00308
Batch 20 Train - Loss (one batch): 0.00426
Batch 30 Train - Loss (one batch): 0.00521
Batch 40 Train - Loss (one batch): 0.00515
Batch 50 Train - Loss (one batch): 0.00419
Batch 60 Train - Loss (one batch): 0.00514
Batch 70 Train - Loss (one batch): 0.00469
Batch 80 Train - Loss (one batch): 0.00489
Batch 90 Train - Loss (one batch): 0.00472
Batch 100 Train - Loss (one batch): 0.00480
Batch 110 Train - Loss (one batch): 0.00993
Batch 120 Train - Loss (one batch): 0.00536
Batch 130 Train - Loss (one batch): 0.00508
Batch 140 Train - Loss (one batch): 0.00598
Batch 150 Train - Loss (one batch): 0.00645
Batch 160 Train - Loss (one batch): 0.00683
Batch 170 Train - Loss (one batch): 0.00591
Batch 180 Train - Loss (one batch): 0.00374
Batch 190 Train - Loss (one batch): 0.00253
Batch 200 Train - Loss (one batch): 0.00252
Batch 210 Train - Loss (one batch): 0.00561
Batch 220 Train - Loss (one batch): 0.00566
- Epoch 010, ExpID 66645
Train - Loss (one batch): 0.00509
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00585, 0.00585, 0.07651, 0.03944, 102.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.00562, 0.00562, 0.07498, 0.03946, 106.86%
Time spent: 19.74s
Batch 0 Train - Loss (one batch): 0.00544
Batch 10 Train - Loss (one batch): 0.00332
Batch 20 Train - Loss (one batch): 0.00519
Batch 30 Train - Loss (one batch): 0.00692
Batch 40 Train - Loss (one batch): 0.01014
Batch 50 Train - Loss (one batch): 0.00617
Batch 60 Train - Loss (one batch): 0.00354
Batch 70 Train - Loss (one batch): 0.00457
Batch 80 Train - Loss (one batch): 0.00486
Batch 90 Train - Loss (one batch): 0.00675
Batch 100 Train - Loss (one batch): 0.00544
Batch 110 Train - Loss (one batch): 0.00535
Batch 120 Train - Loss (one batch): 0.00489
Batch 130 Train - Loss (one batch): 0.00384
Batch 140 Train - Loss (one batch): 0.00461
Batch 150 Train - Loss (one batch): 0.00350
Batch 160 Train - Loss (one batch): 0.00900
Batch 170 Train - Loss (one batch): 0.00382
Batch 180 Train - Loss (one batch): 0.00505
Batch 190 Train - Loss (one batch): 0.00475
Batch 200 Train - Loss (one batch): 0.00439
Batch 210 Train - Loss (one batch): 0.00569
Batch 220 Train - Loss (one batch): 0.00677
- Epoch 011, ExpID 66645
Train - Loss (one batch): 0.00320
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00581, 0.00581, 0.07623, 0.03763, 84.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.00550, 0.00550, 0.07416, 0.03774, 86.65%
Time spent: 19.65s
Batch 0 Train - Loss (one batch): 0.00354
Batch 10 Train - Loss (one batch): 0.00947
Batch 20 Train - Loss (one batch): 0.00580
Batch 30 Train - Loss (one batch): 0.00407
Batch 40 Train - Loss (one batch): 0.00563
Batch 50 Train - Loss (one batch): 0.00709
Batch 60 Train - Loss (one batch): 0.00443
Batch 70 Train - Loss (one batch): 0.00746
Batch 80 Train - Loss (one batch): 0.00481
Batch 90 Train - Loss (one batch): 0.00561
Batch 100 Train - Loss (one batch): 0.00503
Batch 110 Train - Loss (one batch): 0.00551
Batch 120 Train - Loss (one batch): 0.00452
Batch 130 Train - Loss (one batch): 0.00443
Batch 140 Train - Loss (one batch): 0.00458
Batch 150 Train - Loss (one batch): 0.00413
Batch 160 Train - Loss (one batch): 0.00388
Batch 170 Train - Loss (one batch): 0.00395
Batch 180 Train - Loss (one batch): 0.00443
Batch 190 Train - Loss (one batch): 0.00384
Batch 200 Train - Loss (one batch): 0.00581
Batch 210 Train - Loss (one batch): 0.00417
Batch 220 Train - Loss (one batch): 0.00666
- Epoch 012, ExpID 66645
Train - Loss (one batch): 0.00468
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00601, 0.00601, 0.07750, 0.03881, 100.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.00550, 0.00550, 0.07416, 0.03774, 86.65%
Time spent: 16.50s
Batch 0 Train - Loss (one batch): 0.00334
Batch 10 Train - Loss (one batch): 0.00438
Batch 20 Train - Loss (one batch): 0.00508
Batch 30 Train - Loss (one batch): 0.00389
Batch 40 Train - Loss (one batch): 0.00368
Batch 50 Train - Loss (one batch): 0.00573
Batch 60 Train - Loss (one batch): 0.00471
Batch 70 Train - Loss (one batch): 0.00674
Batch 80 Train - Loss (one batch): 0.00583
Batch 90 Train - Loss (one batch): 0.00410
Batch 100 Train - Loss (one batch): 0.00439
Batch 110 Train - Loss (one batch): 0.00269
Batch 120 Train - Loss (one batch): 0.00321
Batch 130 Train - Loss (one batch): 0.00551
Batch 140 Train - Loss (one batch): 0.01062
Batch 150 Train - Loss (one batch): 0.00475
Batch 160 Train - Loss (one batch): 0.00433
Batch 170 Train - Loss (one batch): 0.00356
Batch 180 Train - Loss (one batch): 0.00486
Batch 190 Train - Loss (one batch): 0.00471
Batch 200 Train - Loss (one batch): 0.00336
Batch 210 Train - Loss (one batch): 0.00402
Batch 220 Train - Loss (one batch): 0.00246
- Epoch 013, ExpID 66645
Train - Loss (one batch): 0.00541
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00606, 0.00606, 0.07786, 0.03892, 109.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.00550, 0.00550, 0.07416, 0.03774, 86.65%
Time spent: 16.43s
Batch 0 Train - Loss (one batch): 0.00325
Batch 10 Train - Loss (one batch): 0.00304
Batch 20 Train - Loss (one batch): 0.00330
Batch 30 Train - Loss (one batch): 0.00494
Batch 40 Train - Loss (one batch): 0.00751
Batch 50 Train - Loss (one batch): 0.00561
Batch 60 Train - Loss (one batch): 0.00436
Batch 70 Train - Loss (one batch): 0.00837
Batch 80 Train - Loss (one batch): 0.00625
Batch 90 Train - Loss (one batch): 0.00264
Batch 100 Train - Loss (one batch): 0.00452
Batch 110 Train - Loss (one batch): 0.00305
Batch 120 Train - Loss (one batch): 0.00313
Batch 130 Train - Loss (one batch): 0.00503
Batch 140 Train - Loss (one batch): 0.00363
Batch 150 Train - Loss (one batch): 0.00383
Batch 160 Train - Loss (one batch): 0.00484
Batch 170 Train - Loss (one batch): 0.00373
Batch 180 Train - Loss (one batch): 0.00723
Batch 190 Train - Loss (one batch): 0.00351
Batch 200 Train - Loss (one batch): 0.00662
Batch 210 Train - Loss (one batch): 0.00320
Batch 220 Train - Loss (one batch): 0.00544
- Epoch 014, ExpID 66645
Train - Loss (one batch): 0.00595
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00604, 0.00604, 0.07774, 0.04110, 78.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.00550, 0.00550, 0.07416, 0.03774, 86.65%
Time spent: 16.61s
Batch 0 Train - Loss (one batch): 0.00449
Batch 10 Train - Loss (one batch): 0.00374
Batch 20 Train - Loss (one batch): 0.00296
Batch 30 Train - Loss (one batch): 0.00238
Batch 40 Train - Loss (one batch): 0.00438
Batch 50 Train - Loss (one batch): 0.00250
Batch 60 Train - Loss (one batch): 0.00420
Batch 70 Train - Loss (one batch): 0.00895
Batch 80 Train - Loss (one batch): 0.00453
Batch 90 Train - Loss (one batch): 0.00604
Batch 100 Train - Loss (one batch): 0.00467
Batch 110 Train - Loss (one batch): 0.00456
Batch 120 Train - Loss (one batch): 0.00383
Batch 130 Train - Loss (one batch): 0.00550
Batch 140 Train - Loss (one batch): 0.00344
Batch 150 Train - Loss (one batch): 0.00542
Batch 160 Train - Loss (one batch): 0.00432
Batch 170 Train - Loss (one batch): 0.00377
Batch 180 Train - Loss (one batch): 0.00413
Batch 190 Train - Loss (one batch): 0.00427
Batch 200 Train - Loss (one batch): 0.00393
Batch 210 Train - Loss (one batch): 0.00489
Batch 220 Train - Loss (one batch): 0.00549
- Epoch 015, ExpID 66645
Train - Loss (one batch): 0.00630
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00594, 0.00594, 0.07710, 0.03880, 69.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.00550, 0.00550, 0.07416, 0.03774, 86.65%
Time spent: 16.71s
Batch 0 Train - Loss (one batch): 0.00426
Batch 10 Train - Loss (one batch): 0.00435
Batch 20 Train - Loss (one batch): 0.00453
Batch 30 Train - Loss (one batch): 0.00552
Batch 40 Train - Loss (one batch): 0.00429
Batch 50 Train - Loss (one batch): 0.00374
Batch 60 Train - Loss (one batch): 0.00323
Batch 70 Train - Loss (one batch): 0.00432
Batch 80 Train - Loss (one batch): 0.00433
Batch 90 Train - Loss (one batch): 0.00308
Batch 100 Train - Loss (one batch): 0.00604
Batch 110 Train - Loss (one batch): 0.00553
Batch 120 Train - Loss (one batch): 0.00439
Batch 130 Train - Loss (one batch): 0.00458
Batch 140 Train - Loss (one batch): 0.00551
Batch 150 Train - Loss (one batch): 0.00500
Batch 160 Train - Loss (one batch): 0.00421
Batch 170 Train - Loss (one batch): 0.00799
Batch 180 Train - Loss (one batch): 0.00361
Batch 190 Train - Loss (one batch): 0.00286
Batch 200 Train - Loss (one batch): 0.00460
Batch 210 Train - Loss (one batch): 0.00465
Batch 220 Train - Loss (one batch): 0.00418
- Epoch 016, ExpID 66645
Train - Loss (one batch): 0.00389
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00642, 0.00642, 0.08015, 0.04285, 68.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.00550, 0.00550, 0.07416, 0.03774, 86.65%
Time spent: 17.32s
Batch 0 Train - Loss (one batch): 0.00412
Batch 10 Train - Loss (one batch): 0.00319
Batch 20 Train - Loss (one batch): 0.00488
Batch 30 Train - Loss (one batch): 0.00306
Batch 40 Train - Loss (one batch): 0.00464
Batch 50 Train - Loss (one batch): 0.01093
Batch 60 Train - Loss (one batch): 0.00355
Batch 70 Train - Loss (one batch): 0.00463
Batch 80 Train - Loss (one batch): 0.00855
Batch 90 Train - Loss (one batch): 0.00333
Batch 100 Train - Loss (one batch): 0.00411
Batch 110 Train - Loss (one batch): 0.00582
Batch 120 Train - Loss (one batch): 0.00470
Batch 130 Train - Loss (one batch): 0.00376
Batch 140 Train - Loss (one batch): 0.00421
Batch 150 Train - Loss (one batch): 0.00557
Batch 160 Train - Loss (one batch): 0.00638
Batch 170 Train - Loss (one batch): 0.00484
Batch 180 Train - Loss (one batch): 0.00431
Batch 190 Train - Loss (one batch): 0.00450
Batch 200 Train - Loss (one batch): 0.00430
Batch 210 Train - Loss (one batch): 0.00378
Batch 220 Train - Loss (one batch): 0.00412
- Epoch 017, ExpID 66645
Train - Loss (one batch): 0.00503
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00596, 0.00596, 0.07722, 0.04052, 140.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.00550, 0.00550, 0.07416, 0.03774, 86.65%
Time spent: 17.60s
Batch 0 Train - Loss (one batch): 0.00457
Batch 10 Train - Loss (one batch): 0.00401
Batch 20 Train - Loss (one batch): 0.00436
Batch 30 Train - Loss (one batch): 0.00416
Batch 40 Train - Loss (one batch): 0.00902
Batch 50 Train - Loss (one batch): 0.00411
Batch 60 Train - Loss (one batch): 0.00524
Batch 70 Train - Loss (one batch): 0.00521
Batch 80 Train - Loss (one batch): 0.00438
Batch 90 Train - Loss (one batch): 0.00294
Batch 100 Train - Loss (one batch): 0.00344
Batch 110 Train - Loss (one batch): 0.00357
Batch 120 Train - Loss (one batch): 0.00515
Batch 130 Train - Loss (one batch): 0.00391
Batch 140 Train - Loss (one batch): 0.00369
Batch 150 Train - Loss (one batch): 0.00302
Batch 160 Train - Loss (one batch): 0.00534
Batch 170 Train - Loss (one batch): 0.00441
Batch 180 Train - Loss (one batch): 0.00514
Batch 190 Train - Loss (one batch): 0.00440
Batch 200 Train - Loss (one batch): 0.00497
Batch 210 Train - Loss (one batch): 0.00403
Batch 220 Train - Loss (one batch): 0.00467
- Epoch 018, ExpID 66645
Train - Loss (one batch): 0.00458
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00591, 0.00591, 0.07689, 0.04109, 111.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.00550, 0.00550, 0.07416, 0.03774, 86.65%
Time spent: 16.68s
Batch 0 Train - Loss (one batch): 0.00488
Batch 10 Train - Loss (one batch): 0.00360
Batch 20 Train - Loss (one batch): 0.00410
Batch 30 Train - Loss (one batch): 0.00377
Batch 40 Train - Loss (one batch): 0.00431
Batch 50 Train - Loss (one batch): 0.00477
Batch 60 Train - Loss (one batch): 0.00397
Batch 70 Train - Loss (one batch): 0.00556
Batch 80 Train - Loss (one batch): 0.00542
Batch 90 Train - Loss (one batch): 0.00448
Batch 100 Train - Loss (one batch): 0.00445
Batch 110 Train - Loss (one batch): 0.00429
Batch 120 Train - Loss (one batch): 0.00551
Batch 130 Train - Loss (one batch): 0.00533
Batch 140 Train - Loss (one batch): 0.00282
Batch 150 Train - Loss (one batch): 0.00429
Batch 160 Train - Loss (one batch): 0.00524
Batch 170 Train - Loss (one batch): 0.00323
Batch 180 Train - Loss (one batch): 0.00727
Batch 190 Train - Loss (one batch): 0.00529
Batch 200 Train - Loss (one batch): 0.00669
Batch 210 Train - Loss (one batch): 0.00339
Batch 220 Train - Loss (one batch): 0.00575
- Epoch 019, ExpID 66645
Train - Loss (one batch): 0.00548
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00571, 0.00571, 0.07556, 0.03802, 93.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 19, 0.00541, 0.00541, 0.07352, 0.03787, 98.19%
Time spent: 18.96s
Batch 0 Train - Loss (one batch): 0.00367
Batch 10 Train - Loss (one batch): 0.00287
Batch 20 Train - Loss (one batch): 0.00434
Batch 30 Train - Loss (one batch): 0.00275
Batch 40 Train - Loss (one batch): 0.00438
Batch 50 Train - Loss (one batch): 0.00575
Batch 60 Train - Loss (one batch): 0.00397
Batch 70 Train - Loss (one batch): 0.00423
Batch 80 Train - Loss (one batch): 0.00754
Batch 90 Train - Loss (one batch): 0.00492
Batch 100 Train - Loss (one batch): 0.00560
Batch 110 Train - Loss (one batch): 0.00543
Batch 120 Train - Loss (one batch): 0.00544
Batch 130 Train - Loss (one batch): 0.00428
Batch 140 Train - Loss (one batch): 0.00595
Batch 150 Train - Loss (one batch): 0.00466
Batch 160 Train - Loss (one batch): 0.00387
Batch 170 Train - Loss (one batch): 0.00485
Batch 180 Train - Loss (one batch): 0.00355
Batch 190 Train - Loss (one batch): 0.00482
Batch 200 Train - Loss (one batch): 0.00409
Batch 210 Train - Loss (one batch): 0.00668
Batch 220 Train - Loss (one batch): 0.00765
- Epoch 020, ExpID 66645
Train - Loss (one batch): 0.00382
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00569, 0.00569, 0.07546, 0.03878, 102.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00544, 0.00544, 0.07376, 0.03865, 105.64%
Time spent: 18.89s
Batch 0 Train - Loss (one batch): 0.00416
Batch 10 Train - Loss (one batch): 0.00363
Batch 20 Train - Loss (one batch): 0.00276
Batch 30 Train - Loss (one batch): 0.00437
Batch 40 Train - Loss (one batch): 0.00512
Batch 50 Train - Loss (one batch): 0.00336
Batch 60 Train - Loss (one batch): 0.00416
Batch 70 Train - Loss (one batch): 0.00352
Batch 80 Train - Loss (one batch): 0.00333
Batch 90 Train - Loss (one batch): 0.00569
Batch 100 Train - Loss (one batch): 0.00382
Batch 110 Train - Loss (one batch): 0.00555
Batch 120 Train - Loss (one batch): 0.00458
Batch 130 Train - Loss (one batch): 0.00437
Batch 140 Train - Loss (one batch): 0.00397
Batch 150 Train - Loss (one batch): 0.00306
Batch 160 Train - Loss (one batch): 0.00508
Batch 170 Train - Loss (one batch): 0.00519
Batch 180 Train - Loss (one batch): 0.00422
Batch 190 Train - Loss (one batch): 0.00428
Batch 200 Train - Loss (one batch): 0.00369
Batch 210 Train - Loss (one batch): 0.00286
Batch 220 Train - Loss (one batch): 0.00519
- Epoch 021, ExpID 66645
Train - Loss (one batch): 0.00373
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00577, 0.00577, 0.07597, 0.03731, 51.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00544, 0.00544, 0.07376, 0.03865, 105.64%
Time spent: 16.40s
Batch 0 Train - Loss (one batch): 0.00549
Batch 10 Train - Loss (one batch): 0.00424
Batch 20 Train - Loss (one batch): 0.00589
Batch 30 Train - Loss (one batch): 0.00755
Batch 40 Train - Loss (one batch): 0.00455
Batch 50 Train - Loss (one batch): 0.00599
Batch 60 Train - Loss (one batch): 0.00309
Batch 70 Train - Loss (one batch): 0.00465
Batch 80 Train - Loss (one batch): 0.00676
Batch 90 Train - Loss (one batch): 0.00442
Batch 100 Train - Loss (one batch): 0.00306
Batch 110 Train - Loss (one batch): 0.00405
Batch 120 Train - Loss (one batch): 0.00575
Batch 130 Train - Loss (one batch): 0.00436
Batch 140 Train - Loss (one batch): 0.00434
Batch 150 Train - Loss (one batch): 0.00501
Batch 160 Train - Loss (one batch): 0.00559
Batch 170 Train - Loss (one batch): 0.00442
Batch 180 Train - Loss (one batch): 0.00612
Batch 190 Train - Loss (one batch): 0.00529
Batch 200 Train - Loss (one batch): 0.00441
Batch 210 Train - Loss (one batch): 0.00390
Batch 220 Train - Loss (one batch): 0.00404
- Epoch 022, ExpID 66645
Train - Loss (one batch): 0.00334
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00611, 0.00611, 0.07818, 0.04044, 137.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00544, 0.00544, 0.07376, 0.03865, 105.64%
Time spent: 16.57s
Batch 0 Train - Loss (one batch): 0.00458
Batch 10 Train - Loss (one batch): 0.00354
Batch 20 Train - Loss (one batch): 0.00394
Batch 30 Train - Loss (one batch): 0.00446
Batch 40 Train - Loss (one batch): 0.00604
Batch 50 Train - Loss (one batch): 0.00485
Batch 60 Train - Loss (one batch): 0.00438
Batch 70 Train - Loss (one batch): 0.00586
Batch 80 Train - Loss (one batch): 0.00585
Batch 90 Train - Loss (one batch): 0.00438
Batch 100 Train - Loss (one batch): 0.00455
Batch 110 Train - Loss (one batch): 0.00657
Batch 120 Train - Loss (one batch): 0.00352
Batch 130 Train - Loss (one batch): 0.00368
Batch 140 Train - Loss (one batch): 0.00394
Batch 150 Train - Loss (one batch): 0.00825
Batch 160 Train - Loss (one batch): 0.00408
Batch 170 Train - Loss (one batch): 0.00494
Batch 180 Train - Loss (one batch): 0.00572
Batch 190 Train - Loss (one batch): 0.00646
Batch 200 Train - Loss (one batch): 0.00390
Batch 210 Train - Loss (one batch): 0.00402
Batch 220 Train - Loss (one batch): 0.00353
- Epoch 023, ExpID 66645
Train - Loss (one batch): 0.00543
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00611, 0.00611, 0.07817, 0.03930, 47.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00544, 0.00544, 0.07376, 0.03865, 105.64%
Time spent: 16.53s
Batch 0 Train - Loss (one batch): 0.01128
Batch 10 Train - Loss (one batch): 0.00355
Batch 20 Train - Loss (one batch): 0.00496
Batch 30 Train - Loss (one batch): 0.00313
Batch 40 Train - Loss (one batch): 0.00468
Batch 50 Train - Loss (one batch): 0.00448
Batch 60 Train - Loss (one batch): 0.00457
Batch 70 Train - Loss (one batch): 0.00283
Batch 80 Train - Loss (one batch): 0.00556
Batch 90 Train - Loss (one batch): 0.00583
Batch 100 Train - Loss (one batch): 0.00416
Batch 110 Train - Loss (one batch): 0.00457
Batch 120 Train - Loss (one batch): 0.00430
Batch 130 Train - Loss (one batch): 0.00550
Batch 140 Train - Loss (one batch): 0.00344
Batch 150 Train - Loss (one batch): 0.00509
Batch 160 Train - Loss (one batch): 0.00601
Batch 170 Train - Loss (one batch): 0.00476
Batch 180 Train - Loss (one batch): 0.00445
Batch 190 Train - Loss (one batch): 0.00365
Batch 200 Train - Loss (one batch): 0.00316
Batch 210 Train - Loss (one batch): 0.00420
Batch 220 Train - Loss (one batch): 0.00346
- Epoch 024, ExpID 66645
Train - Loss (one batch): 0.00458
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00584, 0.00584, 0.07642, 0.03781, 71.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00544, 0.00544, 0.07376, 0.03865, 105.64%
Time spent: 16.46s
Batch 0 Train - Loss (one batch): 0.00726
Batch 10 Train - Loss (one batch): 0.00334
Batch 20 Train - Loss (one batch): 0.00773
Batch 30 Train - Loss (one batch): 0.00393
Batch 40 Train - Loss (one batch): 0.00738
Batch 50 Train - Loss (one batch): 0.00372
Batch 60 Train - Loss (one batch): 0.00501
Batch 70 Train - Loss (one batch): 0.00400
Batch 80 Train - Loss (one batch): 0.00313
Batch 90 Train - Loss (one batch): 0.00462
Batch 100 Train - Loss (one batch): 0.00546
Batch 110 Train - Loss (one batch): 0.00441
Batch 120 Train - Loss (one batch): 0.00511
Batch 130 Train - Loss (one batch): 0.00427
Batch 140 Train - Loss (one batch): 0.00556
Batch 150 Train - Loss (one batch): 0.00538
Batch 160 Train - Loss (one batch): 0.00433
Batch 170 Train - Loss (one batch): 0.00441
Batch 180 Train - Loss (one batch): 0.00294
Batch 190 Train - Loss (one batch): 0.00400
Batch 200 Train - Loss (one batch): 0.00407
Batch 210 Train - Loss (one batch): 0.00377
Batch 220 Train - Loss (one batch): 0.00423
- Epoch 025, ExpID 66645
Train - Loss (one batch): 0.00418
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00571, 0.00571, 0.07553, 0.03768, 114.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00544, 0.00544, 0.07376, 0.03865, 105.64%
Time spent: 16.51s
Batch 0 Train - Loss (one batch): 0.00322
Batch 10 Train - Loss (one batch): 0.00458
Batch 20 Train - Loss (one batch): 0.00350
Batch 30 Train - Loss (one batch): 0.00479
Batch 40 Train - Loss (one batch): 0.00409
Batch 50 Train - Loss (one batch): 0.00464
Batch 60 Train - Loss (one batch): 0.00459
Batch 70 Train - Loss (one batch): 0.00426
Batch 80 Train - Loss (one batch): 0.00447
Batch 90 Train - Loss (one batch): 0.00318
Batch 100 Train - Loss (one batch): 0.00427
Batch 110 Train - Loss (one batch): 0.00477
Batch 120 Train - Loss (one batch): 0.00378
Batch 130 Train - Loss (one batch): 0.00886
Batch 140 Train - Loss (one batch): 0.00410
Batch 150 Train - Loss (one batch): 0.00491
Batch 160 Train - Loss (one batch): 0.00263
Batch 170 Train - Loss (one batch): 0.00504
Batch 180 Train - Loss (one batch): 0.00387
Batch 190 Train - Loss (one batch): 0.00485
Batch 200 Train - Loss (one batch): 0.00514
Batch 210 Train - Loss (one batch): 0.00438
Batch 220 Train - Loss (one batch): 0.00469
- Epoch 026, ExpID 66645
Train - Loss (one batch): 0.00615
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00587, 0.00587, 0.07659, 0.03687, 55.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00544, 0.00544, 0.07376, 0.03865, 105.64%
Time spent: 16.41s
Batch 0 Train - Loss (one batch): 0.00377
Batch 10 Train - Loss (one batch): 0.00611
Batch 20 Train - Loss (one batch): 0.00251
Batch 30 Train - Loss (one batch): 0.00336
Batch 40 Train - Loss (one batch): 0.00376
Batch 50 Train - Loss (one batch): 0.00345
Batch 60 Train - Loss (one batch): 0.00468
Batch 70 Train - Loss (one batch): 0.00341
Batch 80 Train - Loss (one batch): 0.00452
Batch 90 Train - Loss (one batch): 0.00505
Batch 100 Train - Loss (one batch): 0.00269
Batch 110 Train - Loss (one batch): 0.00619
Batch 120 Train - Loss (one batch): 0.00394
Batch 130 Train - Loss (one batch): 0.00511
Batch 140 Train - Loss (one batch): 0.00511
Batch 150 Train - Loss (one batch): 0.00472
Batch 160 Train - Loss (one batch): 0.00831
Batch 170 Train - Loss (one batch): 0.00359
Batch 180 Train - Loss (one batch): 0.00353
Batch 190 Train - Loss (one batch): 0.00386
Batch 200 Train - Loss (one batch): 0.00448
Batch 210 Train - Loss (one batch): 0.00824
Batch 220 Train - Loss (one batch): 0.00344
- Epoch 027, ExpID 66645
Train - Loss (one batch): 0.00529
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00598, 0.00598, 0.07730, 0.04027, 119.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00544, 0.00544, 0.07376, 0.03865, 105.64%
Time spent: 16.42s
Batch 0 Train - Loss (one batch): 0.00799
Batch 10 Train - Loss (one batch): 0.00464
Batch 20 Train - Loss (one batch): 0.00368
Batch 30 Train - Loss (one batch): 0.00474
Batch 40 Train - Loss (one batch): 0.00410
Batch 50 Train - Loss (one batch): 0.00457
Batch 60 Train - Loss (one batch): 0.00458
Batch 70 Train - Loss (one batch): 0.00471
Batch 80 Train - Loss (one batch): 0.00484
Batch 90 Train - Loss (one batch): 0.00529
Batch 100 Train - Loss (one batch): 0.00403
Batch 110 Train - Loss (one batch): 0.00313
Batch 120 Train - Loss (one batch): 0.00361
Batch 130 Train - Loss (one batch): 0.00389
Batch 140 Train - Loss (one batch): 0.00570
Batch 150 Train - Loss (one batch): 0.00368
Batch 160 Train - Loss (one batch): 0.00322
Batch 170 Train - Loss (one batch): 0.00526
Batch 180 Train - Loss (one batch): 0.00356
Batch 190 Train - Loss (one batch): 0.00476
Batch 200 Train - Loss (one batch): 0.00420
Batch 210 Train - Loss (one batch): 0.00345
Batch 220 Train - Loss (one batch): 0.00482
- Epoch 028, ExpID 66645
Train - Loss (one batch): 0.00358
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00600, 0.00600, 0.07749, 0.03840, 82.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00544, 0.00544, 0.07376, 0.03865, 105.64%
Time spent: 16.53s
Batch 0 Train - Loss (one batch): 0.00451
Batch 10 Train - Loss (one batch): 0.00480
Batch 20 Train - Loss (one batch): 0.00346
Batch 30 Train - Loss (one batch): 0.00469
Batch 40 Train - Loss (one batch): 0.00503
Batch 50 Train - Loss (one batch): 0.00543
Batch 60 Train - Loss (one batch): 0.00433
Batch 70 Train - Loss (one batch): 0.00335
Batch 80 Train - Loss (one batch): 0.00351
Batch 90 Train - Loss (one batch): 0.00469
Batch 100 Train - Loss (one batch): 0.00530
Batch 110 Train - Loss (one batch): 0.00687
Batch 120 Train - Loss (one batch): 0.00416
Batch 130 Train - Loss (one batch): 0.00444
Batch 140 Train - Loss (one batch): 0.00447
Batch 150 Train - Loss (one batch): 0.00480
Batch 160 Train - Loss (one batch): 0.00484
Batch 170 Train - Loss (one batch): 0.00419
Batch 180 Train - Loss (one batch): 0.00326
Batch 190 Train - Loss (one batch): 0.00377
Batch 200 Train - Loss (one batch): 0.00275
Batch 210 Train - Loss (one batch): 0.01055
Batch 220 Train - Loss (one batch): 0.00477
- Epoch 029, ExpID 66645
Train - Loss (one batch): 0.00559
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00571, 0.00571, 0.07558, 0.03786, 84.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00544, 0.00544, 0.07376, 0.03865, 105.64%
Time spent: 16.40s
Batch 0 Train - Loss (one batch): 0.00369
Batch 10 Train - Loss (one batch): 0.00363
Batch 20 Train - Loss (one batch): 0.00367
Batch 30 Train - Loss (one batch): 0.00466
Batch 40 Train - Loss (one batch): 0.00287
Batch 50 Train - Loss (one batch): 0.00337
Batch 60 Train - Loss (one batch): 0.00635
Batch 70 Train - Loss (one batch): 0.00411
Batch 80 Train - Loss (one batch): 0.00457
Batch 90 Train - Loss (one batch): 0.00425
Batch 100 Train - Loss (one batch): 0.00313
Batch 110 Train - Loss (one batch): 0.00858
Batch 120 Train - Loss (one batch): 0.00421
Batch 130 Train - Loss (one batch): 0.00498
Batch 140 Train - Loss (one batch): 0.00385
Batch 150 Train - Loss (one batch): 0.00597
Batch 160 Train - Loss (one batch): 0.00524
Batch 170 Train - Loss (one batch): 0.00383
Batch 180 Train - Loss (one batch): 0.00393
Batch 190 Train - Loss (one batch): 0.00270
Batch 200 Train - Loss (one batch): 0.00432
Batch 210 Train - Loss (one batch): 0.00529
Batch 220 Train - Loss (one batch): 0.00451
- Epoch 030, ExpID 66645
Train - Loss (one batch): 0.00353
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00577, 0.00577, 0.07599, 0.03841, 96.10%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00544, 0.00544, 0.07376, 0.03865, 105.64%
Time spent: 16.41s
PID, device: 25608 cuda
Total records: 12000
Dataset n_samples: 12000 7200 2400 2400
Test record ids (first 20): ['137448', '148956', '136914', '155610', '133454', '156996', '145930', '154208', '138164', '144190', '141346', '136111', '133728', '135488', '145796', '153197', '133620', '150418', '138790', '137164']
Test record ids (last 20): ['152600', '137920', '145610', '144568', '134835', '143983', '133814', '156786', '145996', '162595', '149943', '135568', '150737', '143403', '151976', '135534', '162703', '146267', '142320', '143686']
data_max: tensor([9.0000e+01, 1.0000e+00, 4.6230e+02, 4.0000e+00, 4.7200e+02, 5.3000e+00,
        4.6950e+03, 1.6920e+04, 3.6400e+04, 8.2800e+01, 2.0900e+02, 3.6200e+02,
        2.2100e+01, 2.8300e+02, 1.0000e+00, 1.5000e+01, 1.5910e+03, 5.2000e+01,
        6.1200e+01, 3.0000e+02, 2.2900e+01, 3.1000e+01, 2.9000e+01, 2.9900e+02,
        1.0000e+00, 1.8000e+02, 2.1100e+02, 2.1800e+02, 3.0000e+02, 1.0000e+02,
        5.0000e+02, 7.3500e+02, 2.2920e+03, 1.0000e+02, 1.0000e+02, 2.9500e+02,
        4.2100e+01, 4.9600e+01, 2.9910e+01, 1.0245e+04, 6.2519e+03],
       device='cuda:0')
data_min: tensor([ 1.5000e+01, -1.0000e+00, -1.0000e+00,  1.0000e+00, -1.0000e+00,
         1.0000e+00,  1.1000e+01,  1.0000e+00,  5.0000e+00,  0.0000e+00,
         0.0000e+00,  2.8000e+01,  1.0000e-01, -1.0000e+00,  2.1000e-01,
         3.0000e+00,  8.0000e+00,  5.0000e+00,  5.0000e+00,  0.0000e+00,
         1.8000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,
         9.8000e+01, -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  4.0000e-01,  5.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -1.7800e+01,  1.0000e-01,  1.0000e-02,  0.0000e+00,
         0.0000e+00], device='cuda:0')
time_max: tensor(48., device='cuda:0')
n_train_batches: 225
Exp has been early stopped!
/home/zepenghu/literature_project/t-PatchGNN/tPatchGNN/run_models.py
2024-09-12 21:49:35
run_models.py --dataset physionet --state def --history 24 --patience 10 --batch_size 32 --lr 1e-3 --patch_size 8 --stride 8 --nhead 1 --tf_layer 1 --nlayer 1 --te_dim 10 --node_dim 10 --hid_dim 64 --outlayer Linear --seed 2 --gpu 0
Namespace(state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=1, epoch=1000, patience=10, history=24, patch_size=8.0, stride=8.0, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, save='experiments/', load=None, seed=2, dataset='physionet', quantization=0.0, model='tPatchGNN', outlayer='Linear', hid_dim=64, te_dim=10, node_dim=10, gpu='0', npatch=3, device=device(type='cuda'), PID=25881, ndim=41)
Batch 0 Train - Loss (one batch): 0.07136
Batch 10 Train - Loss (one batch): 0.04039
Batch 20 Train - Loss (one batch): 0.03241
Batch 30 Train - Loss (one batch): 0.01458
Batch 40 Train - Loss (one batch): 0.01149
Batch 50 Train - Loss (one batch): 0.01122
Batch 60 Train - Loss (one batch): 0.01279
Batch 70 Train - Loss (one batch): 0.00778
Batch 80 Train - Loss (one batch): 0.00907
Batch 90 Train - Loss (one batch): 0.01321
Batch 100 Train - Loss (one batch): 0.01026
Batch 110 Train - Loss (one batch): 0.01659
Batch 120 Train - Loss (one batch): 0.00676
Batch 130 Train - Loss (one batch): 0.00905
Batch 140 Train - Loss (one batch): 0.01024
Batch 150 Train - Loss (one batch): 0.01229
Batch 160 Train - Loss (one batch): 0.00844
Batch 170 Train - Loss (one batch): 0.00818
Batch 180 Train - Loss (one batch): 0.01617
Batch 190 Train - Loss (one batch): 0.01090
Batch 200 Train - Loss (one batch): 0.01254
Batch 210 Train - Loss (one batch): 0.00503
Batch 220 Train - Loss (one batch): 0.00476
- Epoch 000, ExpID 40393
Train - Loss (one batch): 0.00616
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00932, 0.00932, 0.09655, 0.05234, 105.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.00876, 0.00876, 0.09361, 0.05221, 110.84%
Time spent: 19.92s
Batch 0 Train - Loss (one batch): 0.01089
Batch 10 Train - Loss (one batch): 0.00524
Batch 20 Train - Loss (one batch): 0.00585
Batch 30 Train - Loss (one batch): 0.00519
Batch 40 Train - Loss (one batch): 0.00636
Batch 50 Train - Loss (one batch): 0.00683
Batch 60 Train - Loss (one batch): 0.00896
Batch 70 Train - Loss (one batch): 0.00770
Batch 80 Train - Loss (one batch): 0.00423
Batch 90 Train - Loss (one batch): 0.00634
Batch 100 Train - Loss (one batch): 0.00651
Batch 110 Train - Loss (one batch): 0.00641
Batch 120 Train - Loss (one batch): 0.00529
Batch 130 Train - Loss (one batch): 0.00679
Batch 140 Train - Loss (one batch): 0.00640
Batch 150 Train - Loss (one batch): 0.00646
Batch 160 Train - Loss (one batch): 0.00586
Batch 170 Train - Loss (one batch): 0.00595
Batch 180 Train - Loss (one batch): 0.00574
Batch 190 Train - Loss (one batch): 0.01081
Batch 200 Train - Loss (one batch): 0.00591
Batch 210 Train - Loss (one batch): 0.00911
Batch 220 Train - Loss (one batch): 0.00495
- Epoch 001, ExpID 40393
Train - Loss (one batch): 0.00603
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00715, 0.00715, 0.08458, 0.04616, 138.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.00665, 0.00665, 0.08153, 0.04561, 141.49%
Time spent: 18.33s
Batch 0 Train - Loss (one batch): 0.00576
Batch 10 Train - Loss (one batch): 0.00431
Batch 20 Train - Loss (one batch): 0.00637
Batch 30 Train - Loss (one batch): 0.00514
Batch 40 Train - Loss (one batch): 0.00363
Batch 50 Train - Loss (one batch): 0.00481
Batch 60 Train - Loss (one batch): 0.00414
Batch 70 Train - Loss (one batch): 0.00629
Batch 80 Train - Loss (one batch): 0.00422
Batch 90 Train - Loss (one batch): 0.00514
Batch 100 Train - Loss (one batch): 0.00467
Batch 110 Train - Loss (one batch): 0.00371
Batch 120 Train - Loss (one batch): 0.00677
Batch 130 Train - Loss (one batch): 0.00470
Batch 140 Train - Loss (one batch): 0.00602
Batch 150 Train - Loss (one batch): 0.00369
Batch 160 Train - Loss (one batch): 0.00540
Batch 170 Train - Loss (one batch): 0.00525
Batch 180 Train - Loss (one batch): 0.00669
Batch 190 Train - Loss (one batch): 0.00425
Batch 200 Train - Loss (one batch): 0.00482
Batch 210 Train - Loss (one batch): 0.00439
Batch 220 Train - Loss (one batch): 0.00344
- Epoch 002, ExpID 40393
Train - Loss (one batch): 0.00638
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00666, 0.00666, 0.08163, 0.04408, 94.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.00633, 0.00633, 0.07959, 0.04382, 96.67%
Time spent: 18.70s
Batch 0 Train - Loss (one batch): 0.00670
Batch 10 Train - Loss (one batch): 0.00564
Batch 20 Train - Loss (one batch): 0.00729
Batch 30 Train - Loss (one batch): 0.00747
Batch 40 Train - Loss (one batch): 0.00436
Batch 50 Train - Loss (one batch): 0.00508
Batch 60 Train - Loss (one batch): 0.00539
Batch 70 Train - Loss (one batch): 0.00473
Batch 80 Train - Loss (one batch): 0.00943
Batch 90 Train - Loss (one batch): 0.00676
Batch 100 Train - Loss (one batch): 0.00463
Batch 110 Train - Loss (one batch): 0.00483
Batch 120 Train - Loss (one batch): 0.00378
Batch 130 Train - Loss (one batch): 0.00568
Batch 140 Train - Loss (one batch): 0.00548
Batch 150 Train - Loss (one batch): 0.00701
Batch 160 Train - Loss (one batch): 0.00395
Batch 170 Train - Loss (one batch): 0.00516
Batch 180 Train - Loss (one batch): 0.00557
Batch 190 Train - Loss (one batch): 0.00517
Batch 200 Train - Loss (one batch): 0.00565
Batch 210 Train - Loss (one batch): 0.00332
Batch 220 Train - Loss (one batch): 0.00316
- Epoch 003, ExpID 40393
Train - Loss (one batch): 0.00524
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00630, 0.00630, 0.07939, 0.04333, 233.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.00590, 0.00590, 0.07679, 0.04311, 241.58%
Time spent: 18.44s
Batch 0 Train - Loss (one batch): 0.00456
Batch 10 Train - Loss (one batch): 0.00390
Batch 20 Train - Loss (one batch): 0.00338
Batch 30 Train - Loss (one batch): 0.00576
Batch 40 Train - Loss (one batch): 0.00395
Batch 50 Train - Loss (one batch): 0.00370
Batch 60 Train - Loss (one batch): 0.00486
Batch 70 Train - Loss (one batch): 0.00560
Batch 80 Train - Loss (one batch): 0.00342
Batch 90 Train - Loss (one batch): 0.00491
Batch 100 Train - Loss (one batch): 0.00350
Batch 110 Train - Loss (one batch): 0.00590
Batch 120 Train - Loss (one batch): 0.00496
Batch 130 Train - Loss (one batch): 0.00522
Batch 140 Train - Loss (one batch): 0.00442
Batch 150 Train - Loss (one batch): 0.00565
Batch 160 Train - Loss (one batch): 0.00365
Batch 170 Train - Loss (one batch): 0.00375
Batch 180 Train - Loss (one batch): 0.00454
Batch 190 Train - Loss (one batch): 0.00342
Batch 200 Train - Loss (one batch): 0.00874
Batch 210 Train - Loss (one batch): 0.00536
Batch 220 Train - Loss (one batch): 0.00359
- Epoch 004, ExpID 40393
Train - Loss (one batch): 0.00444
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00600, 0.00600, 0.07749, 0.03947, 90.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00567, 0.00567, 0.07531, 0.03926, 87.16%
Time spent: 18.27s
Batch 0 Train - Loss (one batch): 0.00528
Batch 10 Train - Loss (one batch): 0.00639
Batch 20 Train - Loss (one batch): 0.00384
Batch 30 Train - Loss (one batch): 0.00415
Batch 40 Train - Loss (one batch): 0.00589
Batch 50 Train - Loss (one batch): 0.00631
Batch 60 Train - Loss (one batch): 0.00366
Batch 70 Train - Loss (one batch): 0.00542
Batch 80 Train - Loss (one batch): 0.00310
Batch 90 Train - Loss (one batch): 0.00252
Batch 100 Train - Loss (one batch): 0.00554
Batch 110 Train - Loss (one batch): 0.00446
Batch 120 Train - Loss (one batch): 0.00794
Batch 130 Train - Loss (one batch): 0.00535
Batch 140 Train - Loss (one batch): 0.00494
Batch 150 Train - Loss (one batch): 0.00440
Batch 160 Train - Loss (one batch): 0.00368
Batch 170 Train - Loss (one batch): 0.00466
Batch 180 Train - Loss (one batch): 0.00367
Batch 190 Train - Loss (one batch): 0.00341
Batch 200 Train - Loss (one batch): 0.00495
Batch 210 Train - Loss (one batch): 0.00446
Batch 220 Train - Loss (one batch): 0.00553
- Epoch 005, ExpID 40393
Train - Loss (one batch): 0.00743
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00633, 0.00633, 0.07958, 0.04156, 91.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00567, 0.00567, 0.07531, 0.03926, 87.16%
Time spent: 15.96s
Batch 0 Train - Loss (one batch): 0.00550
Batch 10 Train - Loss (one batch): 0.00671
Batch 20 Train - Loss (one batch): 0.00332
Batch 30 Train - Loss (one batch): 0.00489
Batch 40 Train - Loss (one batch): 0.00363
Batch 50 Train - Loss (one batch): 0.00323
Batch 60 Train - Loss (one batch): 0.00517
Batch 70 Train - Loss (one batch): 0.00634
Batch 80 Train - Loss (one batch): 0.00591
Batch 90 Train - Loss (one batch): 0.00413
Batch 100 Train - Loss (one batch): 0.00465
Batch 110 Train - Loss (one batch): 0.00553
Batch 120 Train - Loss (one batch): 0.00568
Batch 130 Train - Loss (one batch): 0.00707
Batch 140 Train - Loss (one batch): 0.00386
Batch 150 Train - Loss (one batch): 0.00439
Batch 160 Train - Loss (one batch): 0.00286
Batch 170 Train - Loss (one batch): 0.00513
Batch 180 Train - Loss (one batch): 0.00452
Batch 190 Train - Loss (one batch): 0.00492
Batch 200 Train - Loss (one batch): 0.00502
Batch 210 Train - Loss (one batch): 0.00368
Batch 220 Train - Loss (one batch): 0.00645
- Epoch 006, ExpID 40393
Train - Loss (one batch): 0.00502
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00606, 0.00606, 0.07783, 0.04285, 211.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00567, 0.00567, 0.07531, 0.03926, 87.16%
Time spent: 16.33s
Batch 0 Train - Loss (one batch): 0.00476
Batch 10 Train - Loss (one batch): 0.00289
Batch 20 Train - Loss (one batch): 0.00376
Batch 30 Train - Loss (one batch): 0.00312
Batch 40 Train - Loss (one batch): 0.00662
Batch 50 Train - Loss (one batch): 0.00380
Batch 60 Train - Loss (one batch): 0.00388
Batch 70 Train - Loss (one batch): 0.00315
Batch 80 Train - Loss (one batch): 0.00482
Batch 90 Train - Loss (one batch): 0.00594
Batch 100 Train - Loss (one batch): 0.00922
Batch 110 Train - Loss (one batch): 0.00561
Batch 120 Train - Loss (one batch): 0.00522
Batch 130 Train - Loss (one batch): 0.00335
Batch 140 Train - Loss (one batch): 0.00714
Batch 150 Train - Loss (one batch): 0.00338
Batch 160 Train - Loss (one batch): 0.00484
Batch 170 Train - Loss (one batch): 0.00446
Batch 180 Train - Loss (one batch): 0.00291
Batch 190 Train - Loss (one batch): 0.00426
Batch 200 Train - Loss (one batch): 0.00411
Batch 210 Train - Loss (one batch): 0.00673
Batch 220 Train - Loss (one batch): 0.00342
- Epoch 007, ExpID 40393
Train - Loss (one batch): 0.00440
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00605, 0.00605, 0.07777, 0.03970, 82.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00567, 0.00567, 0.07531, 0.03926, 87.16%
Time spent: 16.27s
Batch 0 Train - Loss (one batch): 0.00614
Batch 10 Train - Loss (one batch): 0.00496
Batch 20 Train - Loss (one batch): 0.00313
Batch 30 Train - Loss (one batch): 0.00539
Batch 40 Train - Loss (one batch): 0.00261
Batch 50 Train - Loss (one batch): 0.00555
Batch 60 Train - Loss (one batch): 0.00648
Batch 70 Train - Loss (one batch): 0.00435
Batch 80 Train - Loss (one batch): 0.00507
Batch 90 Train - Loss (one batch): 0.00888
Batch 100 Train - Loss (one batch): 0.01173
Batch 110 Train - Loss (one batch): 0.00621
Batch 120 Train - Loss (one batch): 0.00345
Batch 130 Train - Loss (one batch): 0.00530
Batch 140 Train - Loss (one batch): 0.00496
Batch 150 Train - Loss (one batch): 0.00340
Batch 160 Train - Loss (one batch): 0.00478
Batch 170 Train - Loss (one batch): 0.00381
Batch 180 Train - Loss (one batch): 0.00514
Batch 190 Train - Loss (one batch): 0.00301
Batch 200 Train - Loss (one batch): 0.00494
Batch 210 Train - Loss (one batch): 0.00512
Batch 220 Train - Loss (one batch): 0.00548
- Epoch 008, ExpID 40393
Train - Loss (one batch): 0.00410
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00618, 0.00618, 0.07864, 0.03882, 86.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00567, 0.00567, 0.07531, 0.03926, 87.16%
Time spent: 16.35s
Batch 0 Train - Loss (one batch): 0.00337
Batch 10 Train - Loss (one batch): 0.00463
Batch 20 Train - Loss (one batch): 0.00602
Batch 30 Train - Loss (one batch): 0.00447
Batch 40 Train - Loss (one batch): 0.00401
Batch 50 Train - Loss (one batch): 0.00655
Batch 60 Train - Loss (one batch): 0.00411
Batch 70 Train - Loss (one batch): 0.00446
Batch 80 Train - Loss (one batch): 0.00493
Batch 90 Train - Loss (one batch): 0.00467
Batch 100 Train - Loss (one batch): 0.00591
Batch 110 Train - Loss (one batch): 0.00617
Batch 120 Train - Loss (one batch): 0.00490
Batch 130 Train - Loss (one batch): 0.00293
Batch 140 Train - Loss (one batch): 0.00709
Batch 150 Train - Loss (one batch): 0.00335
Batch 160 Train - Loss (one batch): 0.00428
Batch 170 Train - Loss (one batch): 0.00547
Batch 180 Train - Loss (one batch): 0.00548
Batch 190 Train - Loss (one batch): 0.00459
Batch 200 Train - Loss (one batch): 0.00302
Batch 210 Train - Loss (one batch): 0.00559
Batch 220 Train - Loss (one batch): 0.01434
- Epoch 009, ExpID 40393
Train - Loss (one batch): 0.00661
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00634, 0.00634, 0.07963, 0.04021, 85.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00567, 0.00567, 0.07531, 0.03926, 87.16%
Time spent: 16.96s
Batch 0 Train - Loss (one batch): 0.00348
Batch 10 Train - Loss (one batch): 0.00406
Batch 20 Train - Loss (one batch): 0.00420
Batch 30 Train - Loss (one batch): 0.00416
Batch 40 Train - Loss (one batch): 0.00531
Batch 50 Train - Loss (one batch): 0.00438
Batch 60 Train - Loss (one batch): 0.00403
Batch 70 Train - Loss (one batch): 0.00454
Batch 80 Train - Loss (one batch): 0.00442
Batch 90 Train - Loss (one batch): 0.00651
Batch 100 Train - Loss (one batch): 0.00444
Batch 110 Train - Loss (one batch): 0.00452
Batch 120 Train - Loss (one batch): 0.00441
Batch 130 Train - Loss (one batch): 0.00460
Batch 140 Train - Loss (one batch): 0.00424
Batch 150 Train - Loss (one batch): 0.00478
Batch 160 Train - Loss (one batch): 0.00586
Batch 170 Train - Loss (one batch): 0.00399
Batch 180 Train - Loss (one batch): 0.01187
Batch 190 Train - Loss (one batch): 0.00598
Batch 200 Train - Loss (one batch): 0.00656
Batch 210 Train - Loss (one batch): 0.00420
Batch 220 Train - Loss (one batch): 0.00457
- Epoch 010, ExpID 40393
Train - Loss (one batch): 0.00452
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00591, 0.00591, 0.07685, 0.03911, 81.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.00547, 0.00547, 0.07399, 0.03894, 78.92%
Time spent: 20.26s
Batch 0 Train - Loss (one batch): 0.00580
Batch 10 Train - Loss (one batch): 0.00576
Batch 20 Train - Loss (one batch): 0.00561
Batch 30 Train - Loss (one batch): 0.00452
Batch 40 Train - Loss (one batch): 0.00715
Batch 50 Train - Loss (one batch): 0.00659
Batch 60 Train - Loss (one batch): 0.00430
Batch 70 Train - Loss (one batch): 0.00427
Batch 80 Train - Loss (one batch): 0.00556
Batch 90 Train - Loss (one batch): 0.00513
Batch 100 Train - Loss (one batch): 0.00546
Batch 110 Train - Loss (one batch): 0.00600
Batch 120 Train - Loss (one batch): 0.00400
Batch 130 Train - Loss (one batch): 0.00743
Batch 140 Train - Loss (one batch): 0.00397
Batch 150 Train - Loss (one batch): 0.00463
Batch 160 Train - Loss (one batch): 0.01110
Batch 170 Train - Loss (one batch): 0.00344
Batch 180 Train - Loss (one batch): 0.00550
Batch 190 Train - Loss (one batch): 0.00421
Batch 200 Train - Loss (one batch): 0.00545
Batch 210 Train - Loss (one batch): 0.00360
Batch 220 Train - Loss (one batch): 0.00343
- Epoch 011, ExpID 40393
Train - Loss (one batch): 0.00453
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00592, 0.00592, 0.07692, 0.04043, 139.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.00547, 0.00547, 0.07399, 0.03894, 78.92%
Time spent: 17.64s
Batch 0 Train - Loss (one batch): 0.00476
Batch 10 Train - Loss (one batch): 0.00391
Batch 20 Train - Loss (one batch): 0.00315
Batch 30 Train - Loss (one batch): 0.00365
Batch 40 Train - Loss (one batch): 0.00390
Batch 50 Train - Loss (one batch): 0.00597
Batch 60 Train - Loss (one batch): 0.00343
Batch 70 Train - Loss (one batch): 0.00368
Batch 80 Train - Loss (one batch): 0.00349
Batch 90 Train - Loss (one batch): 0.00289
Batch 100 Train - Loss (one batch): 0.00440
Batch 110 Train - Loss (one batch): 0.00647
Batch 120 Train - Loss (one batch): 0.00446
Batch 130 Train - Loss (one batch): 0.00442
Batch 140 Train - Loss (one batch): 0.00309
Batch 150 Train - Loss (one batch): 0.00807
Batch 160 Train - Loss (one batch): 0.00424
Batch 170 Train - Loss (one batch): 0.00513
Batch 180 Train - Loss (one batch): 0.00448
Batch 190 Train - Loss (one batch): 0.00550
Batch 200 Train - Loss (one batch): 0.00283
Batch 210 Train - Loss (one batch): 0.00371
Batch 220 Train - Loss (one batch): 0.00402
- Epoch 012, ExpID 40393
Train - Loss (one batch): 0.00376
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00623, 0.00623, 0.07893, 0.04055, 104.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.00547, 0.00547, 0.07399, 0.03894, 78.92%
Time spent: 17.57s
Batch 0 Train - Loss (one batch): 0.00348
Batch 10 Train - Loss (one batch): 0.00326
Batch 20 Train - Loss (one batch): 0.00395
Batch 30 Train - Loss (one batch): 0.00507
Batch 40 Train - Loss (one batch): 0.00394
Batch 50 Train - Loss (one batch): 0.00368
Batch 60 Train - Loss (one batch): 0.00331
Batch 70 Train - Loss (one batch): 0.00590
Batch 80 Train - Loss (one batch): 0.00441
Batch 90 Train - Loss (one batch): 0.00476
Batch 100 Train - Loss (one batch): 0.00347
Batch 110 Train - Loss (one batch): 0.00655
Batch 120 Train - Loss (one batch): 0.00326
Batch 130 Train - Loss (one batch): 0.00340
Batch 140 Train - Loss (one batch): 0.00365
Batch 150 Train - Loss (one batch): 0.00283
Batch 160 Train - Loss (one batch): 0.00467
Batch 170 Train - Loss (one batch): 0.00221
Batch 180 Train - Loss (one batch): 0.00790
Batch 190 Train - Loss (one batch): 0.00826
Batch 200 Train - Loss (one batch): 0.00468
Batch 210 Train - Loss (one batch): 0.00468
Batch 220 Train - Loss (one batch): 0.00496
- Epoch 013, ExpID 40393
Train - Loss (one batch): 0.00573
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00613, 0.00613, 0.07831, 0.04067, 77.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.00547, 0.00547, 0.07399, 0.03894, 78.92%
Time spent: 17.17s
Batch 0 Train - Loss (one batch): 0.00427
Batch 10 Train - Loss (one batch): 0.00403
Batch 20 Train - Loss (one batch): 0.00294
Batch 30 Train - Loss (one batch): 0.00417
Batch 40 Train - Loss (one batch): 0.00608
Batch 50 Train - Loss (one batch): 0.00383
Batch 60 Train - Loss (one batch): 0.00374
Batch 70 Train - Loss (one batch): 0.00404
Batch 80 Train - Loss (one batch): 0.00293
Batch 90 Train - Loss (one batch): 0.01285
Batch 100 Train - Loss (one batch): 0.00566
Batch 110 Train - Loss (one batch): 0.00399
Batch 120 Train - Loss (one batch): 0.00275
Batch 130 Train - Loss (one batch): 0.00349
Batch 140 Train - Loss (one batch): 0.00386
Batch 150 Train - Loss (one batch): 0.00412
Batch 160 Train - Loss (one batch): 0.00465
Batch 170 Train - Loss (one batch): 0.00514
Batch 180 Train - Loss (one batch): 0.00410
Batch 190 Train - Loss (one batch): 0.00484
Batch 200 Train - Loss (one batch): 0.00496
Batch 210 Train - Loss (one batch): 0.00538
Batch 220 Train - Loss (one batch): 0.00390
- Epoch 014, ExpID 40393
Train - Loss (one batch): 0.00465
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00642, 0.00642, 0.08010, 0.04309, 98.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.00547, 0.00547, 0.07399, 0.03894, 78.92%
Time spent: 17.22s
Batch 0 Train - Loss (one batch): 0.00512
Batch 10 Train - Loss (one batch): 0.00533
Batch 20 Train - Loss (one batch): 0.00384
Batch 30 Train - Loss (one batch): 0.00469
Batch 40 Train - Loss (one batch): 0.00398
Batch 50 Train - Loss (one batch): 0.00391
Batch 60 Train - Loss (one batch): 0.00647
Batch 70 Train - Loss (one batch): 0.00330
Batch 80 Train - Loss (one batch): 0.00424
Batch 90 Train - Loss (one batch): 0.00347
Batch 100 Train - Loss (one batch): 0.00460
Batch 110 Train - Loss (one batch): 0.00437
Batch 120 Train - Loss (one batch): 0.00522
Batch 130 Train - Loss (one batch): 0.00427
Batch 140 Train - Loss (one batch): 0.00318
Batch 150 Train - Loss (one batch): 0.00428
Batch 160 Train - Loss (one batch): 0.00390
Batch 170 Train - Loss (one batch): 0.00882
Batch 180 Train - Loss (one batch): 0.00896
Batch 190 Train - Loss (one batch): 0.00396
Batch 200 Train - Loss (one batch): 0.00557
Batch 210 Train - Loss (one batch): 0.00431
Batch 220 Train - Loss (one batch): 0.00318
- Epoch 015, ExpID 40393
Train - Loss (one batch): 0.00527
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00577, 0.00577, 0.07594, 0.03719, 71.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 19.04s
Batch 0 Train - Loss (one batch): 0.00377
Batch 10 Train - Loss (one batch): 0.00421
Batch 20 Train - Loss (one batch): 0.00286
Batch 30 Train - Loss (one batch): 0.00418
Batch 40 Train - Loss (one batch): 0.00360
Batch 50 Train - Loss (one batch): 0.00389
Batch 60 Train - Loss (one batch): 0.00375
Batch 70 Train - Loss (one batch): 0.00443
Batch 80 Train - Loss (one batch): 0.00396
Batch 90 Train - Loss (one batch): 0.00456
Batch 100 Train - Loss (one batch): 0.00520
Batch 110 Train - Loss (one batch): 0.00483
Batch 120 Train - Loss (one batch): 0.00330
Batch 130 Train - Loss (one batch): 0.00435
Batch 140 Train - Loss (one batch): 0.00345
Batch 150 Train - Loss (one batch): 0.00494
Batch 160 Train - Loss (one batch): 0.00566
Batch 170 Train - Loss (one batch): 0.00396
Batch 180 Train - Loss (one batch): 0.00508
Batch 190 Train - Loss (one batch): 0.00369
Batch 200 Train - Loss (one batch): 0.00597
Batch 210 Train - Loss (one batch): 0.00568
Batch 220 Train - Loss (one batch): 0.00446
- Epoch 016, ExpID 40393
Train - Loss (one batch): 0.00601
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00603, 0.00603, 0.07765, 0.03919, 96.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 16.54s
Batch 0 Train - Loss (one batch): 0.00462
Batch 10 Train - Loss (one batch): 0.00436
Batch 20 Train - Loss (one batch): 0.00463
Batch 30 Train - Loss (one batch): 0.00399
Batch 40 Train - Loss (one batch): 0.00474
Batch 50 Train - Loss (one batch): 0.00390
Batch 60 Train - Loss (one batch): 0.00374
Batch 70 Train - Loss (one batch): 0.00440
Batch 80 Train - Loss (one batch): 0.00539
Batch 90 Train - Loss (one batch): 0.00457
Batch 100 Train - Loss (one batch): 0.00447
Batch 110 Train - Loss (one batch): 0.00376
Batch 120 Train - Loss (one batch): 0.00472
Batch 130 Train - Loss (one batch): 0.00379
Batch 140 Train - Loss (one batch): 0.00530
Batch 150 Train - Loss (one batch): 0.00353
Batch 160 Train - Loss (one batch): 0.00387
Batch 170 Train - Loss (one batch): 0.00281
Batch 180 Train - Loss (one batch): 0.00446
Batch 190 Train - Loss (one batch): 0.00482
Batch 200 Train - Loss (one batch): 0.00501
Batch 210 Train - Loss (one batch): 0.00320
Batch 220 Train - Loss (one batch): 0.00571
- Epoch 017, ExpID 40393
Train - Loss (one batch): 0.00416
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00638, 0.00638, 0.07990, 0.04020, 64.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 16.42s
Batch 0 Train - Loss (one batch): 0.00460
Batch 10 Train - Loss (one batch): 0.00473
Batch 20 Train - Loss (one batch): 0.00340
Batch 30 Train - Loss (one batch): 0.00302
Batch 40 Train - Loss (one batch): 0.00528
Batch 50 Train - Loss (one batch): 0.00496
Batch 60 Train - Loss (one batch): 0.00542
Batch 70 Train - Loss (one batch): 0.00410
Batch 80 Train - Loss (one batch): 0.00367
Batch 90 Train - Loss (one batch): 0.00408
Batch 100 Train - Loss (one batch): 0.00390
Batch 110 Train - Loss (one batch): 0.00292
Batch 120 Train - Loss (one batch): 0.00444
Batch 130 Train - Loss (one batch): 0.00479
Batch 140 Train - Loss (one batch): 0.00534
Batch 150 Train - Loss (one batch): 0.00340
Batch 160 Train - Loss (one batch): 0.00626
Batch 170 Train - Loss (one batch): 0.00509
Batch 180 Train - Loss (one batch): 0.00438
Batch 190 Train - Loss (one batch): 0.00660
Batch 200 Train - Loss (one batch): 0.00261
Batch 210 Train - Loss (one batch): 0.00464
Batch 220 Train - Loss (one batch): 0.00416
- Epoch 018, ExpID 40393
Train - Loss (one batch): 0.00405
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00614, 0.00614, 0.07838, 0.03965, 84.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 16.39s
Batch 0 Train - Loss (one batch): 0.00379
Batch 10 Train - Loss (one batch): 0.00441
Batch 20 Train - Loss (one batch): 0.00420
Batch 30 Train - Loss (one batch): 0.00399
Batch 40 Train - Loss (one batch): 0.00285
Batch 50 Train - Loss (one batch): 0.00538
Batch 60 Train - Loss (one batch): 0.00383
Batch 70 Train - Loss (one batch): 0.00318
Batch 80 Train - Loss (one batch): 0.00573
Batch 90 Train - Loss (one batch): 0.00432
Batch 100 Train - Loss (one batch): 0.00604
Batch 110 Train - Loss (one batch): 0.00576
Batch 120 Train - Loss (one batch): 0.00439
Batch 130 Train - Loss (one batch): 0.00569
Batch 140 Train - Loss (one batch): 0.00348
Batch 150 Train - Loss (one batch): 0.00461
Batch 160 Train - Loss (one batch): 0.00251
Batch 170 Train - Loss (one batch): 0.00379
Batch 180 Train - Loss (one batch): 0.00838
Batch 190 Train - Loss (one batch): 0.00502
Batch 200 Train - Loss (one batch): 0.00413
Batch 210 Train - Loss (one batch): 0.00409
Batch 220 Train - Loss (one batch): 0.00371
- Epoch 019, ExpID 40393
Train - Loss (one batch): 0.00533
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00613, 0.00613, 0.07828, 0.04158, 153.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 16.29s
Batch 0 Train - Loss (one batch): 0.00396
Batch 10 Train - Loss (one batch): 0.00385
Batch 20 Train - Loss (one batch): 0.00400
Batch 30 Train - Loss (one batch): 0.00306
Batch 40 Train - Loss (one batch): 0.00323
Batch 50 Train - Loss (one batch): 0.00633
Batch 60 Train - Loss (one batch): 0.00495
Batch 70 Train - Loss (one batch): 0.00360
Batch 80 Train - Loss (one batch): 0.00341
Batch 90 Train - Loss (one batch): 0.00501
Batch 100 Train - Loss (one batch): 0.00341
Batch 110 Train - Loss (one batch): 0.00494
Batch 120 Train - Loss (one batch): 0.00405
Batch 130 Train - Loss (one batch): 0.00438
Batch 140 Train - Loss (one batch): 0.00498
Batch 150 Train - Loss (one batch): 0.00502
Batch 160 Train - Loss (one batch): 0.00317
Batch 170 Train - Loss (one batch): 0.00342
Batch 180 Train - Loss (one batch): 0.00452
Batch 190 Train - Loss (one batch): 0.00358
Batch 200 Train - Loss (one batch): 0.00613
Batch 210 Train - Loss (one batch): 0.00276
Batch 220 Train - Loss (one batch): 0.00288
- Epoch 020, ExpID 40393
Train - Loss (one batch): 0.00299
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00611, 0.00611, 0.07815, 0.04049, 112.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 16.35s
Batch 0 Train - Loss (one batch): 0.00343
Batch 10 Train - Loss (one batch): 0.00464
Batch 20 Train - Loss (one batch): 0.00412
Batch 30 Train - Loss (one batch): 0.00427
Batch 40 Train - Loss (one batch): 0.00556
Batch 50 Train - Loss (one batch): 0.00468
Batch 60 Train - Loss (one batch): 0.00412
Batch 70 Train - Loss (one batch): 0.00426
Batch 80 Train - Loss (one batch): 0.00397
Batch 90 Train - Loss (one batch): 0.00372
Batch 100 Train - Loss (one batch): 0.00257
Batch 110 Train - Loss (one batch): 0.00321
Batch 120 Train - Loss (one batch): 0.00407
Batch 130 Train - Loss (one batch): 0.00599
Batch 140 Train - Loss (one batch): 0.00515
Batch 150 Train - Loss (one batch): 0.00398
Batch 160 Train - Loss (one batch): 0.00341
Batch 170 Train - Loss (one batch): 0.00504
Batch 180 Train - Loss (one batch): 0.00413
Batch 190 Train - Loss (one batch): 0.00883
Batch 200 Train - Loss (one batch): 0.00345
Batch 210 Train - Loss (one batch): 0.00527
Batch 220 Train - Loss (one batch): 0.00785
- Epoch 021, ExpID 40393
Train - Loss (one batch): 0.00705
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00603, 0.00603, 0.07765, 0.04382, 133.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 16.48s
Batch 0 Train - Loss (one batch): 0.00625
Batch 10 Train - Loss (one batch): 0.00239
Batch 20 Train - Loss (one batch): 0.00306
Batch 30 Train - Loss (one batch): 0.00428
Batch 40 Train - Loss (one batch): 0.00322
Batch 50 Train - Loss (one batch): 0.00456
Batch 60 Train - Loss (one batch): 0.00595
Batch 70 Train - Loss (one batch): 0.00388
Batch 80 Train - Loss (one batch): 0.00373
Batch 90 Train - Loss (one batch): 0.00529
Batch 100 Train - Loss (one batch): 0.00402
Batch 110 Train - Loss (one batch): 0.00373
Batch 120 Train - Loss (one batch): 0.00407
Batch 130 Train - Loss (one batch): 0.00428
Batch 140 Train - Loss (one batch): 0.00344
Batch 150 Train - Loss (one batch): 0.00382
Batch 160 Train - Loss (one batch): 0.01187
Batch 170 Train - Loss (one batch): 0.00287
Batch 180 Train - Loss (one batch): 0.00491
Batch 190 Train - Loss (one batch): 0.00425
Batch 200 Train - Loss (one batch): 0.00772
Batch 210 Train - Loss (one batch): 0.00346
Batch 220 Train - Loss (one batch): 0.00511
- Epoch 022, ExpID 40393
Train - Loss (one batch): 0.00452
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00590, 0.00590, 0.07682, 0.03817, 63.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 16.38s
Batch 0 Train - Loss (one batch): 0.00470
Batch 10 Train - Loss (one batch): 0.00378
Batch 20 Train - Loss (one batch): 0.00527
Batch 30 Train - Loss (one batch): 0.00748
Batch 40 Train - Loss (one batch): 0.00309
Batch 50 Train - Loss (one batch): 0.00511
Batch 60 Train - Loss (one batch): 0.00585
Batch 70 Train - Loss (one batch): 0.00442
Batch 80 Train - Loss (one batch): 0.00391
Batch 90 Train - Loss (one batch): 0.00327
Batch 100 Train - Loss (one batch): 0.00459
Batch 110 Train - Loss (one batch): 0.00421
Batch 120 Train - Loss (one batch): 0.00481
Batch 130 Train - Loss (one batch): 0.00353
Batch 140 Train - Loss (one batch): 0.00326
Batch 150 Train - Loss (one batch): 0.00505
Batch 160 Train - Loss (one batch): 0.00413
Batch 170 Train - Loss (one batch): 0.00482
Batch 180 Train - Loss (one batch): 0.00543
Batch 190 Train - Loss (one batch): 0.00690
Batch 200 Train - Loss (one batch): 0.00347
Batch 210 Train - Loss (one batch): 0.00346
Batch 220 Train - Loss (one batch): 0.00327
- Epoch 023, ExpID 40393
Train - Loss (one batch): 0.00245
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00575, 0.00575, 0.07585, 0.03689, 79.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 19.12s
Batch 0 Train - Loss (one batch): 0.00382
Batch 10 Train - Loss (one batch): 0.00472
Batch 20 Train - Loss (one batch): 0.00510
Batch 30 Train - Loss (one batch): 0.00371
Batch 40 Train - Loss (one batch): 0.00378
Batch 50 Train - Loss (one batch): 0.00478
Batch 60 Train - Loss (one batch): 0.00609
Batch 70 Train - Loss (one batch): 0.00492
Batch 80 Train - Loss (one batch): 0.00694
Batch 90 Train - Loss (one batch): 0.00447
Batch 100 Train - Loss (one batch): 0.00223
Batch 110 Train - Loss (one batch): 0.00380
Batch 120 Train - Loss (one batch): 0.00414
Batch 130 Train - Loss (one batch): 0.00797
Batch 140 Train - Loss (one batch): 0.00348
Batch 150 Train - Loss (one batch): 0.00554
Batch 160 Train - Loss (one batch): 0.00406
Batch 170 Train - Loss (one batch): 0.00436
Batch 180 Train - Loss (one batch): 0.00309
Batch 190 Train - Loss (one batch): 0.00524
Batch 200 Train - Loss (one batch): 0.00574
Batch 210 Train - Loss (one batch): 0.00417
Batch 220 Train - Loss (one batch): 0.00829
- Epoch 024, ExpID 40393
Train - Loss (one batch): 0.00253
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00586, 0.00586, 0.07655, 0.03844, 69.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.33s
Batch 0 Train - Loss (one batch): 0.00475
Batch 10 Train - Loss (one batch): 0.00454
Batch 20 Train - Loss (one batch): 0.00498
Batch 30 Train - Loss (one batch): 0.00473
Batch 40 Train - Loss (one batch): 0.00419
Batch 50 Train - Loss (one batch): 0.00514
Batch 60 Train - Loss (one batch): 0.00878
Batch 70 Train - Loss (one batch): 0.00560
Batch 80 Train - Loss (one batch): 0.00512
Batch 90 Train - Loss (one batch): 0.00372
Batch 100 Train - Loss (one batch): 0.00552
Batch 110 Train - Loss (one batch): 0.00690
Batch 120 Train - Loss (one batch): 0.00419
Batch 130 Train - Loss (one batch): 0.00455
Batch 140 Train - Loss (one batch): 0.00371
Batch 150 Train - Loss (one batch): 0.00226
Batch 160 Train - Loss (one batch): 0.00479
Batch 170 Train - Loss (one batch): 0.00396
Batch 180 Train - Loss (one batch): 0.00369
Batch 190 Train - Loss (one batch): 0.00527
Batch 200 Train - Loss (one batch): 0.00299
Batch 210 Train - Loss (one batch): 0.00471
Batch 220 Train - Loss (one batch): 0.00389
- Epoch 025, ExpID 40393
Train - Loss (one batch): 0.00628
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00598, 0.00598, 0.07731, 0.04212, 127.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.32s
Batch 0 Train - Loss (one batch): 0.00497
Batch 10 Train - Loss (one batch): 0.00505
Batch 20 Train - Loss (one batch): 0.00510
Batch 30 Train - Loss (one batch): 0.00344
Batch 40 Train - Loss (one batch): 0.00363
Batch 50 Train - Loss (one batch): 0.00494
Batch 60 Train - Loss (one batch): 0.00746
Batch 70 Train - Loss (one batch): 0.00551
Batch 80 Train - Loss (one batch): 0.00471
Batch 90 Train - Loss (one batch): 0.00359
Batch 100 Train - Loss (one batch): 0.00465
Batch 110 Train - Loss (one batch): 0.00432
Batch 120 Train - Loss (one batch): 0.00513
Batch 130 Train - Loss (one batch): 0.00304
Batch 140 Train - Loss (one batch): 0.00487
Batch 150 Train - Loss (one batch): 0.00490
Batch 160 Train - Loss (one batch): 0.00456
Batch 170 Train - Loss (one batch): 0.00597
Batch 180 Train - Loss (one batch): 0.00355
Batch 190 Train - Loss (one batch): 0.00400
Batch 200 Train - Loss (one batch): 0.00311
Batch 210 Train - Loss (one batch): 0.00434
Batch 220 Train - Loss (one batch): 0.00384
- Epoch 026, ExpID 40393
Train - Loss (one batch): 0.00438
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00587, 0.00587, 0.07664, 0.03972, 91.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.38s
Batch 0 Train - Loss (one batch): 0.00439
Batch 10 Train - Loss (one batch): 0.00388
Batch 20 Train - Loss (one batch): 0.00370
Batch 30 Train - Loss (one batch): 0.00469
Batch 40 Train - Loss (one batch): 0.00401
Batch 50 Train - Loss (one batch): 0.00424
Batch 60 Train - Loss (one batch): 0.00604
Batch 70 Train - Loss (one batch): 0.00779
Batch 80 Train - Loss (one batch): 0.00311
Batch 90 Train - Loss (one batch): 0.00325
Batch 100 Train - Loss (one batch): 0.00372
Batch 110 Train - Loss (one batch): 0.00478
Batch 120 Train - Loss (one batch): 0.00332
Batch 130 Train - Loss (one batch): 0.00410
Batch 140 Train - Loss (one batch): 0.00407
Batch 150 Train - Loss (one batch): 0.00289
Batch 160 Train - Loss (one batch): 0.00558
Batch 170 Train - Loss (one batch): 0.00355
Batch 180 Train - Loss (one batch): 0.00400
Batch 190 Train - Loss (one batch): 0.00358
Batch 200 Train - Loss (one batch): 0.00405
Batch 210 Train - Loss (one batch): 0.01054
Batch 220 Train - Loss (one batch): 0.00411
- Epoch 027, ExpID 40393
Train - Loss (one batch): 0.00440
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00580, 0.00580, 0.07614, 0.03836, 122.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.38s
Batch 0 Train - Loss (one batch): 0.00486
Batch 10 Train - Loss (one batch): 0.00508
Batch 20 Train - Loss (one batch): 0.00561
Batch 30 Train - Loss (one batch): 0.00461
Batch 40 Train - Loss (one batch): 0.00306
Batch 50 Train - Loss (one batch): 0.00412
Batch 60 Train - Loss (one batch): 0.00500
Batch 70 Train - Loss (one batch): 0.00452
Batch 80 Train - Loss (one batch): 0.00444
Batch 90 Train - Loss (one batch): 0.00469
Batch 100 Train - Loss (one batch): 0.00438
Batch 110 Train - Loss (one batch): 0.00357
Batch 120 Train - Loss (one batch): 0.00491
Batch 130 Train - Loss (one batch): 0.00479
Batch 140 Train - Loss (one batch): 0.00355
Batch 150 Train - Loss (one batch): 0.00288
Batch 160 Train - Loss (one batch): 0.00384
Batch 170 Train - Loss (one batch): 0.00378
Batch 180 Train - Loss (one batch): 0.00619
Batch 190 Train - Loss (one batch): 0.00332
Batch 200 Train - Loss (one batch): 0.00367
Batch 210 Train - Loss (one batch): 0.00295
Batch 220 Train - Loss (one batch): 0.00355
- Epoch 028, ExpID 40393
Train - Loss (one batch): 0.00453
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00590, 0.00590, 0.07678, 0.03942, 126.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.45s
Batch 0 Train - Loss (one batch): 0.00640
Batch 10 Train - Loss (one batch): 0.00610
Batch 20 Train - Loss (one batch): 0.00539
Batch 30 Train - Loss (one batch): 0.00373
Batch 40 Train - Loss (one batch): 0.00433
Batch 50 Train - Loss (one batch): 0.00568
Batch 60 Train - Loss (one batch): 0.00313
Batch 70 Train - Loss (one batch): 0.00386
Batch 80 Train - Loss (one batch): 0.00422
Batch 90 Train - Loss (one batch): 0.00384
Batch 100 Train - Loss (one batch): 0.00363
Batch 110 Train - Loss (one batch): 0.00306
Batch 120 Train - Loss (one batch): 0.00415
Batch 130 Train - Loss (one batch): 0.00349
Batch 140 Train - Loss (one batch): 0.01212
Batch 150 Train - Loss (one batch): 0.00465
Batch 160 Train - Loss (one batch): 0.00466
Batch 170 Train - Loss (one batch): 0.00570
Batch 180 Train - Loss (one batch): 0.00274
Batch 190 Train - Loss (one batch): 0.00397
Batch 200 Train - Loss (one batch): 0.00420
Batch 210 Train - Loss (one batch): 0.00367
Batch 220 Train - Loss (one batch): 0.00459
- Epoch 029, ExpID 40393
Train - Loss (one batch): 0.00455
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00582, 0.00582, 0.07626, 0.03833, 97.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.54s
Batch 0 Train - Loss (one batch): 0.00492
Batch 10 Train - Loss (one batch): 0.00832
Batch 20 Train - Loss (one batch): 0.00596
Batch 30 Train - Loss (one batch): 0.00388
Batch 40 Train - Loss (one batch): 0.00486
Batch 50 Train - Loss (one batch): 0.00611
Batch 60 Train - Loss (one batch): 0.00353
Batch 70 Train - Loss (one batch): 0.00456
Batch 80 Train - Loss (one batch): 0.00493
Batch 90 Train - Loss (one batch): 0.00518
Batch 100 Train - Loss (one batch): 0.00408
Batch 110 Train - Loss (one batch): 0.00383
Batch 120 Train - Loss (one batch): 0.00368
Batch 130 Train - Loss (one batch): 0.00467
Batch 140 Train - Loss (one batch): 0.00398
Batch 150 Train - Loss (one batch): 0.00456
Batch 160 Train - Loss (one batch): 0.00416
Batch 170 Train - Loss (one batch): 0.00523
Batch 180 Train - Loss (one batch): 0.00367
Batch 190 Train - Loss (one batch): 0.00390
Batch 200 Train - Loss (one batch): 0.00537
Batch 210 Train - Loss (one batch): 0.00333
Batch 220 Train - Loss (one batch): 0.00467
- Epoch 030, ExpID 40393
Train - Loss (one batch): 0.00416
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00581, 0.00581, 0.07621, 0.03954, 132.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.73s
Batch 0 Train - Loss (one batch): 0.00484
Batch 10 Train - Loss (one batch): 0.00388
Batch 20 Train - Loss (one batch): 0.00482
Batch 30 Train - Loss (one batch): 0.00433
Batch 40 Train - Loss (one batch): 0.00324
Batch 50 Train - Loss (one batch): 0.00331
Batch 60 Train - Loss (one batch): 0.00520
Batch 70 Train - Loss (one batch): 0.00395
Batch 80 Train - Loss (one batch): 0.00262
Batch 90 Train - Loss (one batch): 0.00509
Batch 100 Train - Loss (one batch): 0.00522
Batch 110 Train - Loss (one batch): 0.00542
Batch 120 Train - Loss (one batch): 0.00369
Batch 130 Train - Loss (one batch): 0.00465
Batch 140 Train - Loss (one batch): 0.00905
Batch 150 Train - Loss (one batch): 0.00451
Batch 160 Train - Loss (one batch): 0.00559
Batch 170 Train - Loss (one batch): 0.00367
Batch 180 Train - Loss (one batch): 0.00298
Batch 190 Train - Loss (one batch): 0.00317
Batch 200 Train - Loss (one batch): 0.00477
Batch 210 Train - Loss (one batch): 0.00417
Batch 220 Train - Loss (one batch): 0.00381
- Epoch 031, ExpID 40393
Train - Loss (one batch): 0.00325
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00586, 0.00586, 0.07654, 0.03765, 78.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.45s
Batch 0 Train - Loss (one batch): 0.00378
Batch 10 Train - Loss (one batch): 0.00457
Batch 20 Train - Loss (one batch): 0.00441
Batch 30 Train - Loss (one batch): 0.00408
Batch 40 Train - Loss (one batch): 0.00340
Batch 50 Train - Loss (one batch): 0.00511
Batch 60 Train - Loss (one batch): 0.00466
Batch 70 Train - Loss (one batch): 0.00359
Batch 80 Train - Loss (one batch): 0.00455
Batch 90 Train - Loss (one batch): 0.00558
Batch 100 Train - Loss (one batch): 0.00469
Batch 110 Train - Loss (one batch): 0.00323
Batch 120 Train - Loss (one batch): 0.00332
Batch 130 Train - Loss (one batch): 0.00499
Batch 140 Train - Loss (one batch): 0.00743
Batch 150 Train - Loss (one batch): 0.00454
Batch 160 Train - Loss (one batch): 0.00528
Batch 170 Train - Loss (one batch): 0.00397
Batch 180 Train - Loss (one batch): 0.00575
Batch 190 Train - Loss (one batch): 0.00380
Batch 200 Train - Loss (one batch): 0.00590
Batch 210 Train - Loss (one batch): 0.00348
Batch 220 Train - Loss (one batch): 0.00401
- Epoch 032, ExpID 40393
Train - Loss (one batch): 0.00424
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00605, 0.00605, 0.07775, 0.03884, 81.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.34s
Batch 0 Train - Loss (one batch): 0.00267
Batch 10 Train - Loss (one batch): 0.00505
Batch 20 Train - Loss (one batch): 0.00662
Batch 30 Train - Loss (one batch): 0.00370
Batch 40 Train - Loss (one batch): 0.00442
Batch 50 Train - Loss (one batch): 0.00440
Batch 60 Train - Loss (one batch): 0.00516
Batch 70 Train - Loss (one batch): 0.00584
Batch 80 Train - Loss (one batch): 0.00335
Batch 90 Train - Loss (one batch): 0.00387
Batch 100 Train - Loss (one batch): 0.00420
Batch 110 Train - Loss (one batch): 0.00348
Batch 120 Train - Loss (one batch): 0.00264
Batch 130 Train - Loss (one batch): 0.00759
Batch 140 Train - Loss (one batch): 0.00367
Batch 150 Train - Loss (one batch): 0.00356
Batch 160 Train - Loss (one batch): 0.00432
Batch 170 Train - Loss (one batch): 0.00338
Batch 180 Train - Loss (one batch): 0.00367
Batch 190 Train - Loss (one batch): 0.00444
Batch 200 Train - Loss (one batch): 0.00535
Batch 210 Train - Loss (one batch): 0.00493
Batch 220 Train - Loss (one batch): 0.00481
- Epoch 033, ExpID 40393
Train - Loss (one batch): 0.00474
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00593, 0.00593, 0.07698, 0.03783, 76.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.53s
PID, device: 25881 cuda
Total records: 12000
Dataset n_samples: 12000 7200 2400 2400
Test record ids (first 20): ['137448', '148956', '136914', '155610', '133454', '156996', '145930', '154208', '138164', '144190', '141346', '136111', '133728', '135488', '145796', '153197', '133620', '150418', '138790', '137164']
Test record ids (last 20): ['152600', '137920', '145610', '144568', '134835', '143983', '133814', '156786', '145996', '162595', '149943', '135568', '150737', '143403', '151976', '135534', '162703', '146267', '142320', '143686']
data_max: tensor([9.0000e+01, 1.0000e+00, 4.6230e+02, 4.0000e+00, 4.7200e+02, 5.3000e+00,
        4.6950e+03, 1.6920e+04, 3.6400e+04, 8.2800e+01, 2.0900e+02, 3.6200e+02,
        2.2100e+01, 2.8300e+02, 1.0000e+00, 1.5000e+01, 1.5910e+03, 5.2000e+01,
        6.1200e+01, 3.0000e+02, 2.2900e+01, 3.1000e+01, 2.9000e+01, 2.9900e+02,
        1.0000e+00, 1.8000e+02, 2.1100e+02, 2.1800e+02, 3.0000e+02, 1.0000e+02,
        5.0000e+02, 7.3500e+02, 2.2920e+03, 1.0000e+02, 1.0000e+02, 2.9500e+02,
        4.2100e+01, 4.9600e+01, 2.9910e+01, 1.0245e+04, 6.2519e+03],
       device='cuda:0')
data_min: tensor([ 1.5000e+01, -1.0000e+00, -1.0000e+00,  1.0000e+00, -1.0000e+00,
         1.0000e+00,  1.1000e+01,  1.0000e+00,  5.0000e+00,  0.0000e+00,
         0.0000e+00,  2.8000e+01,  1.0000e-01, -1.0000e+00,  2.1000e-01,
         3.0000e+00,  8.0000e+00,  5.0000e+00,  5.0000e+00,  0.0000e+00,
         1.8000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,
         9.8000e+01, -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  4.0000e-01,  5.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -1.7800e+01,  1.0000e-01,  1.0000e-02,  0.0000e+00,
         0.0000e+00], device='cuda:0')
time_max: tensor(48., device='cuda:0')
n_train_batches: 225
Exp has been early stopped!
/home/zepenghu/literature_project/t-PatchGNN/tPatchGNN/run_models.py
2024-09-12 22:00:26
run_models.py --dataset physionet --state def --history 24 --patience 10 --batch_size 32 --lr 1e-3 --patch_size 8 --stride 8 --nhead 1 --tf_layer 1 --nlayer 1 --te_dim 10 --node_dim 10 --hid_dim 64 --outlayer Linear --seed 3 --gpu 0
Namespace(state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=1, epoch=1000, patience=10, history=24, patch_size=8.0, stride=8.0, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, save='experiments/', load=None, seed=3, dataset='physionet', quantization=0.0, model='tPatchGNN', outlayer='Linear', hid_dim=64, te_dim=10, node_dim=10, gpu='0', npatch=3, device=device(type='cuda'), PID=26207, ndim=41)
Batch 0 Train - Loss (one batch): 0.13143
Batch 10 Train - Loss (one batch): 0.07086
Batch 20 Train - Loss (one batch): 0.05504
Batch 30 Train - Loss (one batch): 0.02210
Batch 40 Train - Loss (one batch): 0.00994
Batch 50 Train - Loss (one batch): 0.00961
Batch 60 Train - Loss (one batch): 0.01840
Batch 70 Train - Loss (one batch): 0.01181
Batch 80 Train - Loss (one batch): 0.01293
Batch 90 Train - Loss (one batch): 0.01222
Batch 100 Train - Loss (one batch): 0.00841
Batch 110 Train - Loss (one batch): 0.00979
Batch 120 Train - Loss (one batch): 0.00658
Batch 130 Train - Loss (one batch): 0.01303
Batch 140 Train - Loss (one batch): 0.00609
Batch 150 Train - Loss (one batch): 0.00657
Batch 160 Train - Loss (one batch): 0.00743
Batch 170 Train - Loss (one batch): 0.00706
Batch 180 Train - Loss (one batch): 0.00477
Batch 190 Train - Loss (one batch): 0.00764
Batch 200 Train - Loss (one batch): 0.00675
Batch 210 Train - Loss (one batch): 0.00550
Batch 220 Train - Loss (one batch): 0.00709
- Epoch 000, ExpID 58259
Train - Loss (one batch): 0.00711
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00760, 0.00760, 0.08720, 0.05248, 173.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.00737, 0.00737, 0.08587, 0.05245, 207.28%
Time spent: 20.09s
Batch 0 Train - Loss (one batch): 0.00588
Batch 10 Train - Loss (one batch): 0.00815
Batch 20 Train - Loss (one batch): 0.01276
Batch 30 Train - Loss (one batch): 0.00667
Batch 40 Train - Loss (one batch): 0.00612
Batch 50 Train - Loss (one batch): 0.00739
Batch 60 Train - Loss (one batch): 0.00736
Batch 70 Train - Loss (one batch): 0.00493
Batch 80 Train - Loss (one batch): 0.00898
Batch 90 Train - Loss (one batch): 0.01053
Batch 100 Train - Loss (one batch): 0.00708
Batch 110 Train - Loss (one batch): 0.00855
Batch 120 Train - Loss (one batch): 0.00589
Batch 130 Train - Loss (one batch): 0.00573
Batch 140 Train - Loss (one batch): 0.00606
Batch 150 Train - Loss (one batch): 0.00511
Batch 160 Train - Loss (one batch): 0.00571
Batch 170 Train - Loss (one batch): 0.00479
Batch 180 Train - Loss (one batch): 0.00618
Batch 190 Train - Loss (one batch): 0.00523
Batch 200 Train - Loss (one batch): 0.00684
Batch 210 Train - Loss (one batch): 0.00723
Batch 220 Train - Loss (one batch): 0.00543
- Epoch 001, ExpID 58259
Train - Loss (one batch): 0.00474
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00636, 0.00636, 0.07977, 0.04255, 138.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.00620, 0.00620, 0.07873, 0.04285, 142.47%
Time spent: 19.13s
Batch 0 Train - Loss (one batch): 0.00421
Batch 10 Train - Loss (one batch): 0.00427
Batch 20 Train - Loss (one batch): 0.00616
Batch 30 Train - Loss (one batch): 0.00515
Batch 40 Train - Loss (one batch): 0.00596
Batch 50 Train - Loss (one batch): 0.00621
Batch 60 Train - Loss (one batch): 0.00369
Batch 70 Train - Loss (one batch): 0.00433
Batch 80 Train - Loss (one batch): 0.00543
Batch 90 Train - Loss (one batch): 0.00434
Batch 100 Train - Loss (one batch): 0.00434
Batch 110 Train - Loss (one batch): 0.00645
Batch 120 Train - Loss (one batch): 0.00506
Batch 130 Train - Loss (one batch): 0.00460
Batch 140 Train - Loss (one batch): 0.00500
Batch 150 Train - Loss (one batch): 0.00349
Batch 160 Train - Loss (one batch): 0.00533
Batch 170 Train - Loss (one batch): 0.00384
Batch 180 Train - Loss (one batch): 0.00312
Batch 190 Train - Loss (one batch): 0.00955
Batch 200 Train - Loss (one batch): 0.00568
Batch 210 Train - Loss (one batch): 0.00474
Batch 220 Train - Loss (one batch): 0.00598
- Epoch 002, ExpID 58259
Train - Loss (one batch): 0.00664
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00621, 0.00621, 0.07878, 0.04154, 81.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.00597, 0.00597, 0.07724, 0.04142, 80.25%
Time spent: 19.05s
Batch 0 Train - Loss (one batch): 0.00480
Batch 10 Train - Loss (one batch): 0.01245
Batch 20 Train - Loss (one batch): 0.00678
Batch 30 Train - Loss (one batch): 0.00539
Batch 40 Train - Loss (one batch): 0.00542
Batch 50 Train - Loss (one batch): 0.00446
Batch 60 Train - Loss (one batch): 0.00410
Batch 70 Train - Loss (one batch): 0.00481
Batch 80 Train - Loss (one batch): 0.00370
Batch 90 Train - Loss (one batch): 0.00714
Batch 100 Train - Loss (one batch): 0.00292
Batch 110 Train - Loss (one batch): 0.00453
Batch 120 Train - Loss (one batch): 0.00530
Batch 130 Train - Loss (one batch): 0.00454
Batch 140 Train - Loss (one batch): 0.00771
Batch 150 Train - Loss (one batch): 0.00564
Batch 160 Train - Loss (one batch): 0.00396
Batch 170 Train - Loss (one batch): 0.00430
Batch 180 Train - Loss (one batch): 0.00397
Batch 190 Train - Loss (one batch): 0.00651
Batch 200 Train - Loss (one batch): 0.00452
Batch 210 Train - Loss (one batch): 0.00357
Batch 220 Train - Loss (one batch): 0.00407
- Epoch 003, ExpID 58259
Train - Loss (one batch): 0.00528
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00599, 0.00599, 0.07740, 0.03925, 72.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.00569, 0.00569, 0.07545, 0.03927, 75.17%
Time spent: 18.94s
Batch 0 Train - Loss (one batch): 0.00486
Batch 10 Train - Loss (one batch): 0.01032
Batch 20 Train - Loss (one batch): 0.00569
Batch 30 Train - Loss (one batch): 0.00433
Batch 40 Train - Loss (one batch): 0.00391
Batch 50 Train - Loss (one batch): 0.00568
Batch 60 Train - Loss (one batch): 0.00431
Batch 70 Train - Loss (one batch): 0.00454
Batch 80 Train - Loss (one batch): 0.00480
Batch 90 Train - Loss (one batch): 0.00440
Batch 100 Train - Loss (one batch): 0.00432
Batch 110 Train - Loss (one batch): 0.00349
Batch 120 Train - Loss (one batch): 0.00676
Batch 130 Train - Loss (one batch): 0.00760
Batch 140 Train - Loss (one batch): 0.00539
Batch 150 Train - Loss (one batch): 0.00444
Batch 160 Train - Loss (one batch): 0.00469
Batch 170 Train - Loss (one batch): 0.00572
Batch 180 Train - Loss (one batch): 0.00931
Batch 190 Train - Loss (one batch): 0.00393
Batch 200 Train - Loss (one batch): 0.00478
Batch 210 Train - Loss (one batch): 0.00471
Batch 220 Train - Loss (one batch): 0.00288
- Epoch 004, ExpID 58259
Train - Loss (one batch): 0.00378
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00587, 0.00587, 0.07661, 0.03859, 76.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00561, 0.00561, 0.07492, 0.03883, 79.10%
Time spent: 19.04s
Batch 0 Train - Loss (one batch): 0.00479
Batch 10 Train - Loss (one batch): 0.00439
Batch 20 Train - Loss (one batch): 0.00498
Batch 30 Train - Loss (one batch): 0.00340
Batch 40 Train - Loss (one batch): 0.00446
Batch 50 Train - Loss (one batch): 0.00590
Batch 60 Train - Loss (one batch): 0.00277
Batch 70 Train - Loss (one batch): 0.00389
Batch 80 Train - Loss (one batch): 0.00563
Batch 90 Train - Loss (one batch): 0.00344
Batch 100 Train - Loss (one batch): 0.00501
Batch 110 Train - Loss (one batch): 0.00597
Batch 120 Train - Loss (one batch): 0.00702
Batch 130 Train - Loss (one batch): 0.00364
Batch 140 Train - Loss (one batch): 0.00562
Batch 150 Train - Loss (one batch): 0.00346
Batch 160 Train - Loss (one batch): 0.00802
Batch 170 Train - Loss (one batch): 0.00372
Batch 180 Train - Loss (one batch): 0.00454
Batch 190 Train - Loss (one batch): 0.00462
Batch 200 Train - Loss (one batch): 0.00566
Batch 210 Train - Loss (one batch): 0.00494
Batch 220 Train - Loss (one batch): 0.00532
- Epoch 005, ExpID 58259
Train - Loss (one batch): 0.00758
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00618, 0.00618, 0.07862, 0.04168, 79.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00561, 0.00561, 0.07492, 0.03883, 79.10%
Time spent: 16.54s
Batch 0 Train - Loss (one batch): 0.00342
Batch 10 Train - Loss (one batch): 0.00504
Batch 20 Train - Loss (one batch): 0.00379
Batch 30 Train - Loss (one batch): 0.00296
Batch 40 Train - Loss (one batch): 0.00492
Batch 50 Train - Loss (one batch): 0.00414
Batch 60 Train - Loss (one batch): 0.00620
Batch 70 Train - Loss (one batch): 0.00521
Batch 80 Train - Loss (one batch): 0.00522
Batch 90 Train - Loss (one batch): 0.00569
Batch 100 Train - Loss (one batch): 0.00455
Batch 110 Train - Loss (one batch): 0.00410
Batch 120 Train - Loss (one batch): 0.00433
Batch 130 Train - Loss (one batch): 0.00532
Batch 140 Train - Loss (one batch): 0.00368
Batch 150 Train - Loss (one batch): 0.00484
Batch 160 Train - Loss (one batch): 0.00346
Batch 170 Train - Loss (one batch): 0.00501
Batch 180 Train - Loss (one batch): 0.00584
Batch 190 Train - Loss (one batch): 0.00525
Batch 200 Train - Loss (one batch): 0.00481
Batch 210 Train - Loss (one batch): 0.00468
Batch 220 Train - Loss (one batch): 0.00502
- Epoch 006, ExpID 58259
Train - Loss (one batch): 0.00591
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00586, 0.00586, 0.07655, 0.03941, 84.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00558, 0.00558, 0.07472, 0.03981, 85.39%
Time spent: 18.95s
Batch 0 Train - Loss (one batch): 0.00258
Batch 10 Train - Loss (one batch): 0.00326
Batch 20 Train - Loss (one batch): 0.00418
Batch 30 Train - Loss (one batch): 0.00607
Batch 40 Train - Loss (one batch): 0.00432
Batch 50 Train - Loss (one batch): 0.00565
Batch 60 Train - Loss (one batch): 0.00684
Batch 70 Train - Loss (one batch): 0.00524
Batch 80 Train - Loss (one batch): 0.00343
Batch 90 Train - Loss (one batch): 0.00475
Batch 100 Train - Loss (one batch): 0.00542
Batch 110 Train - Loss (one batch): 0.00433
Batch 120 Train - Loss (one batch): 0.00420
Batch 130 Train - Loss (one batch): 0.00456
Batch 140 Train - Loss (one batch): 0.00305
Batch 150 Train - Loss (one batch): 0.00327
Batch 160 Train - Loss (one batch): 0.00376
Batch 170 Train - Loss (one batch): 0.00386
Batch 180 Train - Loss (one batch): 0.01311
Batch 190 Train - Loss (one batch): 0.00353
Batch 200 Train - Loss (one batch): 0.00524
Batch 210 Train - Loss (one batch): 0.00362
Batch 220 Train - Loss (one batch): 0.00387
- Epoch 007, ExpID 58259
Train - Loss (one batch): 0.00415
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00585, 0.00585, 0.07649, 0.03905, 72.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.00562, 0.00562, 0.07497, 0.03919, 71.91%
Time spent: 18.95s
Batch 0 Train - Loss (one batch): 0.00546
Batch 10 Train - Loss (one batch): 0.00399
Batch 20 Train - Loss (one batch): 0.00420
Batch 30 Train - Loss (one batch): 0.00370
Batch 40 Train - Loss (one batch): 0.00355
Batch 50 Train - Loss (one batch): 0.00429
Batch 60 Train - Loss (one batch): 0.00462
Batch 70 Train - Loss (one batch): 0.00374
Batch 80 Train - Loss (one batch): 0.00435
Batch 90 Train - Loss (one batch): 0.00522
Batch 100 Train - Loss (one batch): 0.00363
Batch 110 Train - Loss (one batch): 0.00393
Batch 120 Train - Loss (one batch): 0.00422
Batch 130 Train - Loss (one batch): 0.00835
Batch 140 Train - Loss (one batch): 0.00520
Batch 150 Train - Loss (one batch): 0.00529
Batch 160 Train - Loss (one batch): 0.00668
Batch 170 Train - Loss (one batch): 0.00903
Batch 180 Train - Loss (one batch): 0.00343
Batch 190 Train - Loss (one batch): 0.00357
Batch 200 Train - Loss (one batch): 0.00431
Batch 210 Train - Loss (one batch): 0.00390
Batch 220 Train - Loss (one batch): 0.00668
- Epoch 008, ExpID 58259
Train - Loss (one batch): 0.00612
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00596, 0.00596, 0.07718, 0.03890, 72.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.00562, 0.00562, 0.07497, 0.03919, 71.91%
Time spent: 16.53s
Batch 0 Train - Loss (one batch): 0.00449
Batch 10 Train - Loss (one batch): 0.00378
Batch 20 Train - Loss (one batch): 0.00602
Batch 30 Train - Loss (one batch): 0.00395
Batch 40 Train - Loss (one batch): 0.00340
Batch 50 Train - Loss (one batch): 0.00391
Batch 60 Train - Loss (one batch): 0.00399
Batch 70 Train - Loss (one batch): 0.00502
Batch 80 Train - Loss (one batch): 0.00504
Batch 90 Train - Loss (one batch): 0.00452
Batch 100 Train - Loss (one batch): 0.00403
Batch 110 Train - Loss (one batch): 0.00440
Batch 120 Train - Loss (one batch): 0.00738
Batch 130 Train - Loss (one batch): 0.00486
Batch 140 Train - Loss (one batch): 0.00461
Batch 150 Train - Loss (one batch): 0.00377
Batch 160 Train - Loss (one batch): 0.00422
Batch 170 Train - Loss (one batch): 0.00373
Batch 180 Train - Loss (one batch): 0.00334
Batch 190 Train - Loss (one batch): 0.00379
Batch 200 Train - Loss (one batch): 0.00572
Batch 210 Train - Loss (one batch): 0.00392
Batch 220 Train - Loss (one batch): 0.00337
- Epoch 009, ExpID 58259
Train - Loss (one batch): 0.00754
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00608, 0.00608, 0.07797, 0.04062, 98.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.00562, 0.00562, 0.07497, 0.03919, 71.91%
Time spent: 16.50s
Batch 0 Train - Loss (one batch): 0.00397
Batch 10 Train - Loss (one batch): 0.00358
Batch 20 Train - Loss (one batch): 0.00535
Batch 30 Train - Loss (one batch): 0.00552
Batch 40 Train - Loss (one batch): 0.00542
Batch 50 Train - Loss (one batch): 0.00410
Batch 60 Train - Loss (one batch): 0.00494
Batch 70 Train - Loss (one batch): 0.00466
Batch 80 Train - Loss (one batch): 0.00360
Batch 90 Train - Loss (one batch): 0.00371
Batch 100 Train - Loss (one batch): 0.00387
Batch 110 Train - Loss (one batch): 0.00412
Batch 120 Train - Loss (one batch): 0.00522
Batch 130 Train - Loss (one batch): 0.00332
Batch 140 Train - Loss (one batch): 0.00372
Batch 150 Train - Loss (one batch): 0.00890
Batch 160 Train - Loss (one batch): 0.00496
Batch 170 Train - Loss (one batch): 0.00372
Batch 180 Train - Loss (one batch): 0.00339
Batch 190 Train - Loss (one batch): 0.00483
Batch 200 Train - Loss (one batch): 0.00341
Batch 210 Train - Loss (one batch): 0.00435
Batch 220 Train - Loss (one batch): 0.00820
- Epoch 010, ExpID 58259
Train - Loss (one batch): 0.00461
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00706, 0.00706, 0.08405, 0.04733, 85.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.00562, 0.00562, 0.07497, 0.03919, 71.91%
Time spent: 16.55s
Batch 0 Train - Loss (one batch): 0.00583
Batch 10 Train - Loss (one batch): 0.00285
Batch 20 Train - Loss (one batch): 0.00327
Batch 30 Train - Loss (one batch): 0.00548
Batch 40 Train - Loss (one batch): 0.00503
Batch 50 Train - Loss (one batch): 0.00457
Batch 60 Train - Loss (one batch): 0.00501
Batch 70 Train - Loss (one batch): 0.00352
Batch 80 Train - Loss (one batch): 0.00442
Batch 90 Train - Loss (one batch): 0.00374
Batch 100 Train - Loss (one batch): 0.00538
Batch 110 Train - Loss (one batch): 0.00504
Batch 120 Train - Loss (one batch): 0.00427
Batch 130 Train - Loss (one batch): 0.00598
Batch 140 Train - Loss (one batch): 0.00866
Batch 150 Train - Loss (one batch): 0.00430
Batch 160 Train - Loss (one batch): 0.00507
Batch 170 Train - Loss (one batch): 0.00536
Batch 180 Train - Loss (one batch): 0.00321
Batch 190 Train - Loss (one batch): 0.00478
Batch 200 Train - Loss (one batch): 0.00352
Batch 210 Train - Loss (one batch): 0.00376
Batch 220 Train - Loss (one batch): 0.00389
- Epoch 011, ExpID 58259
Train - Loss (one batch): 0.00308
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00592, 0.00592, 0.07693, 0.03960, 88.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.00562, 0.00562, 0.07497, 0.03919, 71.91%
Time spent: 16.48s
Batch 0 Train - Loss (one batch): 0.00395
Batch 10 Train - Loss (one batch): 0.00505
Batch 20 Train - Loss (one batch): 0.00815
Batch 30 Train - Loss (one batch): 0.00554
Batch 40 Train - Loss (one batch): 0.00476
Batch 50 Train - Loss (one batch): 0.00540
Batch 60 Train - Loss (one batch): 0.00418
Batch 70 Train - Loss (one batch): 0.00422
Batch 80 Train - Loss (one batch): 0.00439
Batch 90 Train - Loss (one batch): 0.00338
Batch 100 Train - Loss (one batch): 0.00529
Batch 110 Train - Loss (one batch): 0.00455
Batch 120 Train - Loss (one batch): 0.00360
Batch 130 Train - Loss (one batch): 0.00520
Batch 140 Train - Loss (one batch): 0.00595
Batch 150 Train - Loss (one batch): 0.00337
Batch 160 Train - Loss (one batch): 0.00526
Batch 170 Train - Loss (one batch): 0.00333
Batch 180 Train - Loss (one batch): 0.00432
Batch 190 Train - Loss (one batch): 0.00427
Batch 200 Train - Loss (one batch): 0.00465
Batch 210 Train - Loss (one batch): 0.00567
Batch 220 Train - Loss (one batch): 0.00338
- Epoch 012, ExpID 58259
Train - Loss (one batch): 0.00503
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00594, 0.00594, 0.07710, 0.03874, 79.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.00562, 0.00562, 0.07497, 0.03919, 71.91%
Time spent: 16.48s
Batch 0 Train - Loss (one batch): 0.01304
Batch 10 Train - Loss (one batch): 0.00704
Batch 20 Train - Loss (one batch): 0.00599
Batch 30 Train - Loss (one batch): 0.00502
Batch 40 Train - Loss (one batch): 0.00439
Batch 50 Train - Loss (one batch): 0.00467
Batch 60 Train - Loss (one batch): 0.00561
Batch 70 Train - Loss (one batch): 0.00382
Batch 80 Train - Loss (one batch): 0.00399
Batch 90 Train - Loss (one batch): 0.00554
Batch 100 Train - Loss (one batch): 0.00460
Batch 110 Train - Loss (one batch): 0.00517
Batch 120 Train - Loss (one batch): 0.00478
Batch 130 Train - Loss (one batch): 0.00581
Batch 140 Train - Loss (one batch): 0.00462
Batch 150 Train - Loss (one batch): 0.00572
Batch 160 Train - Loss (one batch): 0.00305
Batch 170 Train - Loss (one batch): 0.00551
Batch 180 Train - Loss (one batch): 0.00269
Batch 190 Train - Loss (one batch): 0.00572
Batch 200 Train - Loss (one batch): 0.00334
Batch 210 Train - Loss (one batch): 0.00534
Batch 220 Train - Loss (one batch): 0.00375
- Epoch 013, ExpID 58259
Train - Loss (one batch): 0.00318
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00585, 0.00585, 0.07647, 0.03773, 65.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.00538, 0.00538, 0.07337, 0.03731, 63.23%
Time spent: 19.01s
Batch 0 Train - Loss (one batch): 0.00386
Batch 10 Train - Loss (one batch): 0.00463
Batch 20 Train - Loss (one batch): 0.00329
Batch 30 Train - Loss (one batch): 0.00275
Batch 40 Train - Loss (one batch): 0.00453
Batch 50 Train - Loss (one batch): 0.00463
Batch 60 Train - Loss (one batch): 0.00466
Batch 70 Train - Loss (one batch): 0.00352
Batch 80 Train - Loss (one batch): 0.00370
Batch 90 Train - Loss (one batch): 0.00435
Batch 100 Train - Loss (one batch): 0.00548
Batch 110 Train - Loss (one batch): 0.00553
Batch 120 Train - Loss (one batch): 0.00975
Batch 130 Train - Loss (one batch): 0.00388
Batch 140 Train - Loss (one batch): 0.00351
Batch 150 Train - Loss (one batch): 0.00733
Batch 160 Train - Loss (one batch): 0.00390
Batch 170 Train - Loss (one batch): 0.00459
Batch 180 Train - Loss (one batch): 0.00353
Batch 190 Train - Loss (one batch): 0.00500
Batch 200 Train - Loss (one batch): 0.00375
Batch 210 Train - Loss (one batch): 0.00314
Batch 220 Train - Loss (one batch): 0.00515
- Epoch 014, ExpID 58259
Train - Loss (one batch): 0.00528
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00573, 0.00573, 0.07571, 0.03672, 56.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 14, 0.00538, 0.00538, 0.07334, 0.03666, 53.95%
Time spent: 19.03s
Batch 0 Train - Loss (one batch): 0.00343
Batch 10 Train - Loss (one batch): 0.00250
Batch 20 Train - Loss (one batch): 0.00322
Batch 30 Train - Loss (one batch): 0.00383
Batch 40 Train - Loss (one batch): 0.00338
Batch 50 Train - Loss (one batch): 0.00363
Batch 60 Train - Loss (one batch): 0.00324
Batch 70 Train - Loss (one batch): 0.00641
Batch 80 Train - Loss (one batch): 0.00539
Batch 90 Train - Loss (one batch): 0.00399
Batch 100 Train - Loss (one batch): 0.00360
Batch 110 Train - Loss (one batch): 0.00638
Batch 120 Train - Loss (one batch): 0.00499
Batch 130 Train - Loss (one batch): 0.00420
Batch 140 Train - Loss (one batch): 0.00335
Batch 150 Train - Loss (one batch): 0.00306
Batch 160 Train - Loss (one batch): 0.00273
Batch 170 Train - Loss (one batch): 0.00418
Batch 180 Train - Loss (one batch): 0.00405
Batch 190 Train - Loss (one batch): 0.00585
Batch 200 Train - Loss (one batch): 0.00650
Batch 210 Train - Loss (one batch): 0.00377
Batch 220 Train - Loss (one batch): 0.00439
- Epoch 015, ExpID 58259
Train - Loss (one batch): 0.00517
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00572, 0.00572, 0.07565, 0.03758, 77.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00558, 0.00558, 0.07470, 0.03788, 73.49%
Time spent: 19.05s
Batch 0 Train - Loss (one batch): 0.00302
Batch 10 Train - Loss (one batch): 0.00397
Batch 20 Train - Loss (one batch): 0.00330
Batch 30 Train - Loss (one batch): 0.00407
Batch 40 Train - Loss (one batch): 0.00453
Batch 50 Train - Loss (one batch): 0.00374
Batch 60 Train - Loss (one batch): 0.00310
Batch 70 Train - Loss (one batch): 0.01194
Batch 80 Train - Loss (one batch): 0.00415
Batch 90 Train - Loss (one batch): 0.00240
Batch 100 Train - Loss (one batch): 0.00451
Batch 110 Train - Loss (one batch): 0.00388
Batch 120 Train - Loss (one batch): 0.00308
Batch 130 Train - Loss (one batch): 0.00541
Batch 140 Train - Loss (one batch): 0.00499
Batch 150 Train - Loss (one batch): 0.00878
Batch 160 Train - Loss (one batch): 0.00370
Batch 170 Train - Loss (one batch): 0.00312
Batch 180 Train - Loss (one batch): 0.00346
Batch 190 Train - Loss (one batch): 0.00292
Batch 200 Train - Loss (one batch): 0.00425
Batch 210 Train - Loss (one batch): 0.00571
Batch 220 Train - Loss (one batch): 0.00363
- Epoch 016, ExpID 58259
Train - Loss (one batch): 0.00464
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00608, 0.00608, 0.07795, 0.04041, 64.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00558, 0.00558, 0.07470, 0.03788, 73.49%
Time spent: 16.49s
Batch 0 Train - Loss (one batch): 0.00395
Batch 10 Train - Loss (one batch): 0.00443
Batch 20 Train - Loss (one batch): 0.00345
Batch 30 Train - Loss (one batch): 0.00397
Batch 40 Train - Loss (one batch): 0.00337
Batch 50 Train - Loss (one batch): 0.00474
Batch 60 Train - Loss (one batch): 0.00445
Batch 70 Train - Loss (one batch): 0.00440
Batch 80 Train - Loss (one batch): 0.00454
Batch 90 Train - Loss (one batch): 0.00447
Batch 100 Train - Loss (one batch): 0.00395
Batch 110 Train - Loss (one batch): 0.00444
Batch 120 Train - Loss (one batch): 0.00466
Batch 130 Train - Loss (one batch): 0.00491
Batch 140 Train - Loss (one batch): 0.00408
Batch 150 Train - Loss (one batch): 0.00351
Batch 160 Train - Loss (one batch): 0.00407
Batch 170 Train - Loss (one batch): 0.00785
Batch 180 Train - Loss (one batch): 0.00568
Batch 190 Train - Loss (one batch): 0.00568
Batch 200 Train - Loss (one batch): 0.00500
Batch 210 Train - Loss (one batch): 0.00506
Batch 220 Train - Loss (one batch): 0.00505
- Epoch 017, ExpID 58259
Train - Loss (one batch): 0.00699
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00588, 0.00588, 0.07670, 0.04043, 81.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00558, 0.00558, 0.07470, 0.03788, 73.49%
Time spent: 16.53s
Batch 0 Train - Loss (one batch): 0.00529
Batch 10 Train - Loss (one batch): 0.00412
Batch 20 Train - Loss (one batch): 0.00508
Batch 30 Train - Loss (one batch): 0.00450
Batch 40 Train - Loss (one batch): 0.00296
Batch 50 Train - Loss (one batch): 0.00454
Batch 60 Train - Loss (one batch): 0.00431
Batch 70 Train - Loss (one batch): 0.00350
Batch 80 Train - Loss (one batch): 0.00624
Batch 90 Train - Loss (one batch): 0.00367
Batch 100 Train - Loss (one batch): 0.00899
Batch 110 Train - Loss (one batch): 0.00333
Batch 120 Train - Loss (one batch): 0.00338
Batch 130 Train - Loss (one batch): 0.00552
Batch 140 Train - Loss (one batch): 0.00325
Batch 150 Train - Loss (one batch): 0.00442
Batch 160 Train - Loss (one batch): 0.00400
Batch 170 Train - Loss (one batch): 0.00481
Batch 180 Train - Loss (one batch): 0.00607
Batch 190 Train - Loss (one batch): 0.01314
Batch 200 Train - Loss (one batch): 0.00506
Batch 210 Train - Loss (one batch): 0.00439
Batch 220 Train - Loss (one batch): 0.00298
- Epoch 018, ExpID 58259
Train - Loss (one batch): 0.00278
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00609, 0.00609, 0.07806, 0.03954, 74.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00558, 0.00558, 0.07470, 0.03788, 73.49%
Time spent: 16.51s
Batch 0 Train - Loss (one batch): 0.00486
Batch 10 Train - Loss (one batch): 0.00552
Batch 20 Train - Loss (one batch): 0.00439
Batch 30 Train - Loss (one batch): 0.00382
Batch 40 Train - Loss (one batch): 0.00468
Batch 50 Train - Loss (one batch): 0.00402
Batch 60 Train - Loss (one batch): 0.00684
Batch 70 Train - Loss (one batch): 0.00355
Batch 80 Train - Loss (one batch): 0.00417
Batch 90 Train - Loss (one batch): 0.00919
Batch 100 Train - Loss (one batch): 0.00453
Batch 110 Train - Loss (one batch): 0.00269
Batch 120 Train - Loss (one batch): 0.00421
Batch 130 Train - Loss (one batch): 0.00646
Batch 140 Train - Loss (one batch): 0.00370
Batch 150 Train - Loss (one batch): 0.00571
Batch 160 Train - Loss (one batch): 0.00383
Batch 170 Train - Loss (one batch): 0.00545
Batch 180 Train - Loss (one batch): 0.00379
Batch 190 Train - Loss (one batch): 0.00403
Batch 200 Train - Loss (one batch): 0.00394
Batch 210 Train - Loss (one batch): 0.00608
Batch 220 Train - Loss (one batch): 0.00398
- Epoch 019, ExpID 58259
Train - Loss (one batch): 0.00553
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00618, 0.00618, 0.07862, 0.04359, 129.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00558, 0.00558, 0.07470, 0.03788, 73.49%
Time spent: 16.57s
Batch 0 Train - Loss (one batch): 0.00339
Batch 10 Train - Loss (one batch): 0.00527
Batch 20 Train - Loss (one batch): 0.00454
Batch 30 Train - Loss (one batch): 0.00426
Batch 40 Train - Loss (one batch): 0.00727
Batch 50 Train - Loss (one batch): 0.00351
Batch 60 Train - Loss (one batch): 0.00497
Batch 70 Train - Loss (one batch): 0.00341
Batch 80 Train - Loss (one batch): 0.00390
Batch 90 Train - Loss (one batch): 0.01119
Batch 100 Train - Loss (one batch): 0.00461
Batch 110 Train - Loss (one batch): 0.00595
Batch 120 Train - Loss (one batch): 0.00427
Batch 130 Train - Loss (one batch): 0.00371
Batch 140 Train - Loss (one batch): 0.00428
Batch 150 Train - Loss (one batch): 0.00571
Batch 160 Train - Loss (one batch): 0.00475
Batch 170 Train - Loss (one batch): 0.00348
Batch 180 Train - Loss (one batch): 0.00382
Batch 190 Train - Loss (one batch): 0.00335
Batch 200 Train - Loss (one batch): 0.00323
Batch 210 Train - Loss (one batch): 0.00402
Batch 220 Train - Loss (one batch): 0.00551
- Epoch 020, ExpID 58259
Train - Loss (one batch): 0.00359
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00593, 0.00593, 0.07702, 0.04123, 130.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00558, 0.00558, 0.07470, 0.03788, 73.49%
Time spent: 16.48s
Batch 0 Train - Loss (one batch): 0.00744
Batch 10 Train - Loss (one batch): 0.00321
Batch 20 Train - Loss (one batch): 0.00570
Batch 30 Train - Loss (one batch): 0.00276
Batch 40 Train - Loss (one batch): 0.00737
Batch 50 Train - Loss (one batch): 0.00498
Batch 60 Train - Loss (one batch): 0.00383
Batch 70 Train - Loss (one batch): 0.00521
Batch 80 Train - Loss (one batch): 0.00541
Batch 90 Train - Loss (one batch): 0.00319
Batch 100 Train - Loss (one batch): 0.00399
Batch 110 Train - Loss (one batch): 0.00358
Batch 120 Train - Loss (one batch): 0.00345
Batch 130 Train - Loss (one batch): 0.00406
Batch 140 Train - Loss (one batch): 0.00560
Batch 150 Train - Loss (one batch): 0.00401
Batch 160 Train - Loss (one batch): 0.00502
Batch 170 Train - Loss (one batch): 0.00441
Batch 180 Train - Loss (one batch): 0.00370
Batch 190 Train - Loss (one batch): 0.00389
Batch 200 Train - Loss (one batch): 0.00422
Batch 210 Train - Loss (one batch): 0.00644
Batch 220 Train - Loss (one batch): 0.00345
- Epoch 021, ExpID 58259
Train - Loss (one batch): 0.00372
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00578, 0.00578, 0.07600, 0.03766, 62.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00558, 0.00558, 0.07470, 0.03788, 73.49%
Time spent: 16.62s
Batch 0 Train - Loss (one batch): 0.00272
Batch 10 Train - Loss (one batch): 0.00326
Batch 20 Train - Loss (one batch): 0.00444
Batch 30 Train - Loss (one batch): 0.00411
Batch 40 Train - Loss (one batch): 0.00450
Batch 50 Train - Loss (one batch): 0.00418
Batch 60 Train - Loss (one batch): 0.00448
Batch 70 Train - Loss (one batch): 0.00382
Batch 80 Train - Loss (one batch): 0.00406
Batch 90 Train - Loss (one batch): 0.00318
Batch 100 Train - Loss (one batch): 0.00489
Batch 110 Train - Loss (one batch): 0.00525
Batch 120 Train - Loss (one batch): 0.00376
Batch 130 Train - Loss (one batch): 0.00540
Batch 140 Train - Loss (one batch): 0.00255
Batch 150 Train - Loss (one batch): 0.00519
Batch 160 Train - Loss (one batch): 0.00437
Batch 170 Train - Loss (one batch): 0.00319
Batch 180 Train - Loss (one batch): 0.00359
Batch 190 Train - Loss (one batch): 0.00340
Batch 200 Train - Loss (one batch): 0.00491
Batch 210 Train - Loss (one batch): 0.00392
Batch 220 Train - Loss (one batch): 0.00481
- Epoch 022, ExpID 58259
Train - Loss (one batch): 0.00461
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00567, 0.00567, 0.07529, 0.03701, 81.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.00536, 0.00536, 0.07320, 0.03699, 81.71%
Time spent: 19.57s
Batch 0 Train - Loss (one batch): 0.00445
Batch 10 Train - Loss (one batch): 0.00535
Batch 20 Train - Loss (one batch): 0.00420
Batch 30 Train - Loss (one batch): 0.00569
Batch 40 Train - Loss (one batch): 0.00405
Batch 50 Train - Loss (one batch): 0.00399
Batch 60 Train - Loss (one batch): 0.00252
Batch 70 Train - Loss (one batch): 0.00411
Batch 80 Train - Loss (one batch): 0.00518
Batch 90 Train - Loss (one batch): 0.00826
Batch 100 Train - Loss (one batch): 0.00456
Batch 110 Train - Loss (one batch): 0.00433
Batch 120 Train - Loss (one batch): 0.00411
Batch 130 Train - Loss (one batch): 0.00357
Batch 140 Train - Loss (one batch): 0.00417
Batch 150 Train - Loss (one batch): 0.00433
Batch 160 Train - Loss (one batch): 0.00924
Batch 170 Train - Loss (one batch): 0.00397
Batch 180 Train - Loss (one batch): 0.00769
Batch 190 Train - Loss (one batch): 0.00301
Batch 200 Train - Loss (one batch): 0.00271
Batch 210 Train - Loss (one batch): 0.00479
Batch 220 Train - Loss (one batch): 0.00453
- Epoch 023, ExpID 58259
Train - Loss (one batch): 0.00402
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00578, 0.00578, 0.07602, 0.04245, 169.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.00536, 0.00536, 0.07320, 0.03699, 81.71%
Time spent: 16.51s
Batch 0 Train - Loss (one batch): 0.00588
Batch 10 Train - Loss (one batch): 0.00287
Batch 20 Train - Loss (one batch): 0.00452
Batch 30 Train - Loss (one batch): 0.00378
Batch 40 Train - Loss (one batch): 0.00382
Batch 50 Train - Loss (one batch): 0.00481
Batch 60 Train - Loss (one batch): 0.00353
Batch 70 Train - Loss (one batch): 0.00352
Batch 80 Train - Loss (one batch): 0.00468
Batch 90 Train - Loss (one batch): 0.00368
Batch 100 Train - Loss (one batch): 0.00441
Batch 110 Train - Loss (one batch): 0.00301
Batch 120 Train - Loss (one batch): 0.00475
Batch 130 Train - Loss (one batch): 0.00266
Batch 140 Train - Loss (one batch): 0.00382
Batch 150 Train - Loss (one batch): 0.01112
Batch 160 Train - Loss (one batch): 0.00355
Batch 170 Train - Loss (one batch): 0.00317
Batch 180 Train - Loss (one batch): 0.00379
Batch 190 Train - Loss (one batch): 0.00476
Batch 200 Train - Loss (one batch): 0.00251
Batch 210 Train - Loss (one batch): 0.00241
Batch 220 Train - Loss (one batch): 0.00488
- Epoch 024, ExpID 58259
Train - Loss (one batch): 0.00504
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00582, 0.00582, 0.07628, 0.03875, 67.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.00536, 0.00536, 0.07320, 0.03699, 81.71%
Time spent: 16.47s
Batch 0 Train - Loss (one batch): 0.00367
Batch 10 Train - Loss (one batch): 0.00635
Batch 20 Train - Loss (one batch): 0.00500
Batch 30 Train - Loss (one batch): 0.00653
Batch 40 Train - Loss (one batch): 0.00465
Batch 50 Train - Loss (one batch): 0.00444
Batch 60 Train - Loss (one batch): 0.00385
Batch 70 Train - Loss (one batch): 0.00476
Batch 80 Train - Loss (one batch): 0.00350
Batch 90 Train - Loss (one batch): 0.00541
Batch 100 Train - Loss (one batch): 0.00431
Batch 110 Train - Loss (one batch): 0.00246
Batch 120 Train - Loss (one batch): 0.00266
Batch 130 Train - Loss (one batch): 0.00451
Batch 140 Train - Loss (one batch): 0.00379
Batch 150 Train - Loss (one batch): 0.00340
Batch 160 Train - Loss (one batch): 0.00250
Batch 170 Train - Loss (one batch): 0.00678
Batch 180 Train - Loss (one batch): 0.00407
Batch 190 Train - Loss (one batch): 0.01064
Batch 200 Train - Loss (one batch): 0.00547
Batch 210 Train - Loss (one batch): 0.00648
Batch 220 Train - Loss (one batch): 0.00465
- Epoch 025, ExpID 58259
Train - Loss (one batch): 0.00577
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00590, 0.00590, 0.07681, 0.03994, 84.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.00536, 0.00536, 0.07320, 0.03699, 81.71%
Time spent: 16.50s
Batch 0 Train - Loss (one batch): 0.00323
Batch 10 Train - Loss (one batch): 0.00454
Batch 20 Train - Loss (one batch): 0.00344
Batch 30 Train - Loss (one batch): 0.00361
Batch 40 Train - Loss (one batch): 0.00834
Batch 50 Train - Loss (one batch): 0.00372
Batch 60 Train - Loss (one batch): 0.00506
Batch 70 Train - Loss (one batch): 0.00601
Batch 80 Train - Loss (one batch): 0.00552
Batch 90 Train - Loss (one batch): 0.00373
Batch 100 Train - Loss (one batch): 0.00614
Batch 110 Train - Loss (one batch): 0.00467
Batch 120 Train - Loss (one batch): 0.00484
Batch 130 Train - Loss (one batch): 0.00394
Batch 140 Train - Loss (one batch): 0.00802
Batch 150 Train - Loss (one batch): 0.00306
Batch 160 Train - Loss (one batch): 0.00341
Batch 170 Train - Loss (one batch): 0.00476
Batch 180 Train - Loss (one batch): 0.00360
Batch 190 Train - Loss (one batch): 0.00428
Batch 200 Train - Loss (one batch): 0.00337
Batch 210 Train - Loss (one batch): 0.00613
Batch 220 Train - Loss (one batch): 0.00286
- Epoch 026, ExpID 58259
Train - Loss (one batch): 0.00590
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00572, 0.00572, 0.07562, 0.03687, 85.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.00536, 0.00536, 0.07320, 0.03699, 81.71%
Time spent: 16.47s
Batch 0 Train - Loss (one batch): 0.00905
Batch 10 Train - Loss (one batch): 0.00470
Batch 20 Train - Loss (one batch): 0.00438
Batch 30 Train - Loss (one batch): 0.00337
Batch 40 Train - Loss (one batch): 0.00369
Batch 50 Train - Loss (one batch): 0.00488
Batch 60 Train - Loss (one batch): 0.00383
Batch 70 Train - Loss (one batch): 0.00481
Batch 80 Train - Loss (one batch): 0.00747
Batch 90 Train - Loss (one batch): 0.00384
Batch 100 Train - Loss (one batch): 0.00966
Batch 110 Train - Loss (one batch): 0.00262
Batch 120 Train - Loss (one batch): 0.00332
Batch 130 Train - Loss (one batch): 0.00428
Batch 140 Train - Loss (one batch): 0.00422
Batch 150 Train - Loss (one batch): 0.00494
Batch 160 Train - Loss (one batch): 0.00486
Batch 170 Train - Loss (one batch): 0.00888
Batch 180 Train - Loss (one batch): 0.00418
Batch 190 Train - Loss (one batch): 0.00344
Batch 200 Train - Loss (one batch): 0.00439
Batch 210 Train - Loss (one batch): 0.00535
Batch 220 Train - Loss (one batch): 0.00540
- Epoch 027, ExpID 58259
Train - Loss (one batch): 0.00510
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00623, 0.00623, 0.07895, 0.04100, 76.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.00536, 0.00536, 0.07320, 0.03699, 81.71%
Time spent: 16.50s
Batch 0 Train - Loss (one batch): 0.00379
Batch 10 Train - Loss (one batch): 0.00472
Batch 20 Train - Loss (one batch): 0.00497
Batch 30 Train - Loss (one batch): 0.00352
Batch 40 Train - Loss (one batch): 0.00529
Batch 50 Train - Loss (one batch): 0.00478
Batch 60 Train - Loss (one batch): 0.00360
Batch 70 Train - Loss (one batch): 0.00217
Batch 80 Train - Loss (one batch): 0.00309
Batch 90 Train - Loss (one batch): 0.00414
Batch 100 Train - Loss (one batch): 0.00196
Batch 110 Train - Loss (one batch): 0.00617
Batch 120 Train - Loss (one batch): 0.00576
Batch 130 Train - Loss (one batch): 0.00537
Batch 140 Train - Loss (one batch): 0.00372
Batch 150 Train - Loss (one batch): 0.00546
Batch 160 Train - Loss (one batch): 0.00584
Batch 170 Train - Loss (one batch): 0.00479
Batch 180 Train - Loss (one batch): 0.00424
Batch 190 Train - Loss (one batch): 0.00585
Batch 200 Train - Loss (one batch): 0.00524
Batch 210 Train - Loss (one batch): 0.00304
Batch 220 Train - Loss (one batch): 0.00495
- Epoch 028, ExpID 58259
Train - Loss (one batch): 0.00439
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00583, 0.00583, 0.07638, 0.03970, 107.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.00536, 0.00536, 0.07320, 0.03699, 81.71%
Time spent: 16.45s
Batch 0 Train - Loss (one batch): 0.00553
Batch 10 Train - Loss (one batch): 0.00542
Batch 20 Train - Loss (one batch): 0.00465
Batch 30 Train - Loss (one batch): 0.00478
Batch 40 Train - Loss (one batch): 0.00641
Batch 50 Train - Loss (one batch): 0.00345
Batch 60 Train - Loss (one batch): 0.00426
Batch 70 Train - Loss (one batch): 0.00420
Batch 80 Train - Loss (one batch): 0.00553
Batch 90 Train - Loss (one batch): 0.00444
Batch 100 Train - Loss (one batch): 0.00301
Batch 110 Train - Loss (one batch): 0.00502
Batch 120 Train - Loss (one batch): 0.00487
Batch 130 Train - Loss (one batch): 0.00294
Batch 140 Train - Loss (one batch): 0.00486
Batch 150 Train - Loss (one batch): 0.00431
Batch 160 Train - Loss (one batch): 0.00338
Batch 170 Train - Loss (one batch): 0.00393
Batch 180 Train - Loss (one batch): 0.00376
Batch 190 Train - Loss (one batch): 0.00425
Batch 200 Train - Loss (one batch): 0.00317
Batch 210 Train - Loss (one batch): 0.00319
Batch 220 Train - Loss (one batch): 0.01157
- Epoch 029, ExpID 58259
Train - Loss (one batch): 0.00568
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00557, 0.00557, 0.07461, 0.03901, 149.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 18.96s
Batch 0 Train - Loss (one batch): 0.00259
Batch 10 Train - Loss (one batch): 0.00305
Batch 20 Train - Loss (one batch): 0.00349
Batch 30 Train - Loss (one batch): 0.00341
Batch 40 Train - Loss (one batch): 0.00496
Batch 50 Train - Loss (one batch): 0.00400
Batch 60 Train - Loss (one batch): 0.00351
Batch 70 Train - Loss (one batch): 0.00415
Batch 80 Train - Loss (one batch): 0.00311
Batch 90 Train - Loss (one batch): 0.00580
Batch 100 Train - Loss (one batch): 0.00558
Batch 110 Train - Loss (one batch): 0.00420
Batch 120 Train - Loss (one batch): 0.00395
Batch 130 Train - Loss (one batch): 0.00434
Batch 140 Train - Loss (one batch): 0.00335
Batch 150 Train - Loss (one batch): 0.00483
Batch 160 Train - Loss (one batch): 0.00294
Batch 170 Train - Loss (one batch): 0.00490
Batch 180 Train - Loss (one batch): 0.00869
Batch 190 Train - Loss (one batch): 0.00313
Batch 200 Train - Loss (one batch): 0.00635
Batch 210 Train - Loss (one batch): 0.00280
Batch 220 Train - Loss (one batch): 0.00362
- Epoch 030, ExpID 58259
Train - Loss (one batch): 0.00457
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00586, 0.00586, 0.07656, 0.03800, 76.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 16.41s
Batch 0 Train - Loss (one batch): 0.00323
Batch 10 Train - Loss (one batch): 0.00442
Batch 20 Train - Loss (one batch): 0.00490
Batch 30 Train - Loss (one batch): 0.00434
Batch 40 Train - Loss (one batch): 0.01329
Batch 50 Train - Loss (one batch): 0.00451
Batch 60 Train - Loss (one batch): 0.00269
Batch 70 Train - Loss (one batch): 0.00405
Batch 80 Train - Loss (one batch): 0.00363
Batch 90 Train - Loss (one batch): 0.00524
Batch 100 Train - Loss (one batch): 0.00424
Batch 110 Train - Loss (one batch): 0.00306
Batch 120 Train - Loss (one batch): 0.00397
Batch 130 Train - Loss (one batch): 0.00335
Batch 140 Train - Loss (one batch): 0.00301
Batch 150 Train - Loss (one batch): 0.00450
Batch 160 Train - Loss (one batch): 0.00322
Batch 170 Train - Loss (one batch): 0.00484
Batch 180 Train - Loss (one batch): 0.00434
Batch 190 Train - Loss (one batch): 0.00389
Batch 200 Train - Loss (one batch): 0.00849
Batch 210 Train - Loss (one batch): 0.00627
Batch 220 Train - Loss (one batch): 0.00361
- Epoch 031, ExpID 58259
Train - Loss (one batch): 0.00275
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00597, 0.00597, 0.07725, 0.04050, 101.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 16.47s
Batch 0 Train - Loss (one batch): 0.00459
Batch 10 Train - Loss (one batch): 0.00511
Batch 20 Train - Loss (one batch): 0.00562
Batch 30 Train - Loss (one batch): 0.01130
Batch 40 Train - Loss (one batch): 0.00344
Batch 50 Train - Loss (one batch): 0.00613
Batch 60 Train - Loss (one batch): 0.00449
Batch 70 Train - Loss (one batch): 0.00401
Batch 80 Train - Loss (one batch): 0.00340
Batch 90 Train - Loss (one batch): 0.00372
Batch 100 Train - Loss (one batch): 0.00451
Batch 110 Train - Loss (one batch): 0.00598
Batch 120 Train - Loss (one batch): 0.00317
Batch 130 Train - Loss (one batch): 0.00508
Batch 140 Train - Loss (one batch): 0.00523
Batch 150 Train - Loss (one batch): 0.00612
Batch 160 Train - Loss (one batch): 0.00510
Batch 170 Train - Loss (one batch): 0.00263
Batch 180 Train - Loss (one batch): 0.00445
Batch 190 Train - Loss (one batch): 0.00488
Batch 200 Train - Loss (one batch): 0.00297
Batch 210 Train - Loss (one batch): 0.00537
Batch 220 Train - Loss (one batch): 0.00460
- Epoch 032, ExpID 58259
Train - Loss (one batch): 0.00504
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00564, 0.00564, 0.07513, 0.03729, 66.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 16.74s
Batch 0 Train - Loss (one batch): 0.00546
Batch 10 Train - Loss (one batch): 0.00409
Batch 20 Train - Loss (one batch): 0.00415
Batch 30 Train - Loss (one batch): 0.00296
Batch 40 Train - Loss (one batch): 0.00445
Batch 50 Train - Loss (one batch): 0.00378
Batch 60 Train - Loss (one batch): 0.00299
Batch 70 Train - Loss (one batch): 0.00326
Batch 80 Train - Loss (one batch): 0.00434
Batch 90 Train - Loss (one batch): 0.00341
Batch 100 Train - Loss (one batch): 0.00779
Batch 110 Train - Loss (one batch): 0.00366
Batch 120 Train - Loss (one batch): 0.00506
Batch 130 Train - Loss (one batch): 0.00479
Batch 140 Train - Loss (one batch): 0.00447
Batch 150 Train - Loss (one batch): 0.00639
Batch 160 Train - Loss (one batch): 0.00540
Batch 170 Train - Loss (one batch): 0.00441
Batch 180 Train - Loss (one batch): 0.00452
Batch 190 Train - Loss (one batch): 0.00465
Batch 200 Train - Loss (one batch): 0.00630
Batch 210 Train - Loss (one batch): 0.00378
Batch 220 Train - Loss (one batch): 0.00515
- Epoch 033, ExpID 58259
Train - Loss (one batch): 0.00470
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00587, 0.00587, 0.07660, 0.03829, 65.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 17.43s
Batch 0 Train - Loss (one batch): 0.00340
Batch 10 Train - Loss (one batch): 0.00458
Batch 20 Train - Loss (one batch): 0.00386
Batch 30 Train - Loss (one batch): 0.00352
Batch 40 Train - Loss (one batch): 0.00263
Batch 50 Train - Loss (one batch): 0.00283
Batch 60 Train - Loss (one batch): 0.00658
Batch 70 Train - Loss (one batch): 0.00493
Batch 80 Train - Loss (one batch): 0.00362
Batch 90 Train - Loss (one batch): 0.00937
Batch 100 Train - Loss (one batch): 0.00444
Batch 110 Train - Loss (one batch): 0.00369
Batch 120 Train - Loss (one batch): 0.00417
Batch 130 Train - Loss (one batch): 0.00279
Batch 140 Train - Loss (one batch): 0.00354
Batch 150 Train - Loss (one batch): 0.00291
Batch 160 Train - Loss (one batch): 0.00478
Batch 170 Train - Loss (one batch): 0.00416
Batch 180 Train - Loss (one batch): 0.00581
Batch 190 Train - Loss (one batch): 0.00372
Batch 200 Train - Loss (one batch): 0.00603
Batch 210 Train - Loss (one batch): 0.00331
Batch 220 Train - Loss (one batch): 0.00619
- Epoch 034, ExpID 58259
Train - Loss (one batch): 0.00316
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00657, 0.00657, 0.08103, 0.04222, 70.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 16.42s
Batch 0 Train - Loss (one batch): 0.00835
Batch 10 Train - Loss (one batch): 0.00740
Batch 20 Train - Loss (one batch): 0.00615
Batch 30 Train - Loss (one batch): 0.00353
Batch 40 Train - Loss (one batch): 0.00573
Batch 50 Train - Loss (one batch): 0.00555
Batch 60 Train - Loss (one batch): 0.00559
Batch 70 Train - Loss (one batch): 0.00329
Batch 80 Train - Loss (one batch): 0.00392
Batch 90 Train - Loss (one batch): 0.00639
Batch 100 Train - Loss (one batch): 0.00364
Batch 110 Train - Loss (one batch): 0.00319
Batch 120 Train - Loss (one batch): 0.00280
Batch 130 Train - Loss (one batch): 0.00421
Batch 140 Train - Loss (one batch): 0.00336
Batch 150 Train - Loss (one batch): 0.00386
Batch 160 Train - Loss (one batch): 0.00409
Batch 170 Train - Loss (one batch): 0.00347
Batch 180 Train - Loss (one batch): 0.00435
Batch 190 Train - Loss (one batch): 0.00331
Batch 200 Train - Loss (one batch): 0.00390
Batch 210 Train - Loss (one batch): 0.00451
Batch 220 Train - Loss (one batch): 0.00429
- Epoch 035, ExpID 58259
Train - Loss (one batch): 0.00430
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00585, 0.00585, 0.07646, 0.03925, 73.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 16.56s
Batch 0 Train - Loss (one batch): 0.00427
Batch 10 Train - Loss (one batch): 0.00568
Batch 20 Train - Loss (one batch): 0.00446
Batch 30 Train - Loss (one batch): 0.00442
Batch 40 Train - Loss (one batch): 0.00556
Batch 50 Train - Loss (one batch): 0.00370
Batch 60 Train - Loss (one batch): 0.00399
Batch 70 Train - Loss (one batch): 0.00259
Batch 80 Train - Loss (one batch): 0.00423
Batch 90 Train - Loss (one batch): 0.00699
Batch 100 Train - Loss (one batch): 0.00321
Batch 110 Train - Loss (one batch): 0.00481
Batch 120 Train - Loss (one batch): 0.00509
Batch 130 Train - Loss (one batch): 0.00603
Batch 140 Train - Loss (one batch): 0.00375
Batch 150 Train - Loss (one batch): 0.00402
Batch 160 Train - Loss (one batch): 0.00480
Batch 170 Train - Loss (one batch): 0.00453
Batch 180 Train - Loss (one batch): 0.00684
Batch 190 Train - Loss (one batch): 0.00465
Batch 200 Train - Loss (one batch): 0.00410
Batch 210 Train - Loss (one batch): 0.00468
Batch 220 Train - Loss (one batch): 0.00357
- Epoch 036, ExpID 58259
Train - Loss (one batch): 0.00408
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00591, 0.00591, 0.07688, 0.03737, 66.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 16.44s
Batch 0 Train - Loss (one batch): 0.00985
Batch 10 Train - Loss (one batch): 0.00422
Batch 20 Train - Loss (one batch): 0.00330
Batch 30 Train - Loss (one batch): 0.00264
Batch 40 Train - Loss (one batch): 0.00315
Batch 50 Train - Loss (one batch): 0.00567
Batch 60 Train - Loss (one batch): 0.00405
Batch 70 Train - Loss (one batch): 0.00481
Batch 80 Train - Loss (one batch): 0.00369
Batch 90 Train - Loss (one batch): 0.00517
Batch 100 Train - Loss (one batch): 0.00387
Batch 110 Train - Loss (one batch): 0.00299
Batch 120 Train - Loss (one batch): 0.00496
Batch 130 Train - Loss (one batch): 0.00349
Batch 140 Train - Loss (one batch): 0.00390
Batch 150 Train - Loss (one batch): 0.00409
Batch 160 Train - Loss (one batch): 0.00287
Batch 170 Train - Loss (one batch): 0.00451
Batch 180 Train - Loss (one batch): 0.00442
Batch 190 Train - Loss (one batch): 0.00341
Batch 200 Train - Loss (one batch): 0.00432
Batch 210 Train - Loss (one batch): 0.00582
Batch 220 Train - Loss (one batch): 0.00363
- Epoch 037, ExpID 58259
Train - Loss (one batch): 0.00306
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00609, 0.00609, 0.07803, 0.03834, 74.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 16.36s
Batch 0 Train - Loss (one batch): 0.00582
Batch 10 Train - Loss (one batch): 0.00364
Batch 20 Train - Loss (one batch): 0.00339
Batch 30 Train - Loss (one batch): 0.00338
Batch 40 Train - Loss (one batch): 0.00425
Batch 50 Train - Loss (one batch): 0.00531
Batch 60 Train - Loss (one batch): 0.00481
Batch 70 Train - Loss (one batch): 0.00377
Batch 80 Train - Loss (one batch): 0.00406
Batch 90 Train - Loss (one batch): 0.00400
Batch 100 Train - Loss (one batch): 0.01134
Batch 110 Train - Loss (one batch): 0.00335
Batch 120 Train - Loss (one batch): 0.00397
Batch 130 Train - Loss (one batch): 0.00402
Batch 140 Train - Loss (one batch): 0.00529
Batch 150 Train - Loss (one batch): 0.00446
Batch 160 Train - Loss (one batch): 0.00401
Batch 170 Train - Loss (one batch): 0.00427
Batch 180 Train - Loss (one batch): 0.00342
Batch 190 Train - Loss (one batch): 0.00636
Batch 200 Train - Loss (one batch): 0.00418
Batch 210 Train - Loss (one batch): 0.00819
Batch 220 Train - Loss (one batch): 0.00650
- Epoch 038, ExpID 58259
Train - Loss (one batch): 0.00820
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00585, 0.00585, 0.07650, 0.03789, 99.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 16.55s
Batch 0 Train - Loss (one batch): 0.00436
Batch 10 Train - Loss (one batch): 0.00403
Batch 20 Train - Loss (one batch): 0.00603
Batch 30 Train - Loss (one batch): 0.00388
Batch 40 Train - Loss (one batch): 0.00404
Batch 50 Train - Loss (one batch): 0.00953
Batch 60 Train - Loss (one batch): 0.00552
Batch 70 Train - Loss (one batch): 0.00322
Batch 80 Train - Loss (one batch): 0.00495
Batch 90 Train - Loss (one batch): 0.00549
Batch 100 Train - Loss (one batch): 0.00346
Batch 110 Train - Loss (one batch): 0.00405
Batch 120 Train - Loss (one batch): 0.00427
Batch 130 Train - Loss (one batch): 0.00804
Batch 140 Train - Loss (one batch): 0.00466
Batch 150 Train - Loss (one batch): 0.00342
Batch 160 Train - Loss (one batch): 0.00363
Batch 170 Train - Loss (one batch): 0.00325
Batch 180 Train - Loss (one batch): 0.00361
Batch 190 Train - Loss (one batch): 0.00590
Batch 200 Train - Loss (one batch): 0.00329
Batch 210 Train - Loss (one batch): 0.00366
Batch 220 Train - Loss (one batch): 0.00528
- Epoch 039, ExpID 58259
Train - Loss (one batch): 0.00320
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00562, 0.00562, 0.07495, 0.03694, 75.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 16.47s
PID, device: 26207 cuda
Total records: 12000
Dataset n_samples: 12000 7200 2400 2400
Test record ids (first 20): ['137448', '148956', '136914', '155610', '133454', '156996', '145930', '154208', '138164', '144190', '141346', '136111', '133728', '135488', '145796', '153197', '133620', '150418', '138790', '137164']
Test record ids (last 20): ['152600', '137920', '145610', '144568', '134835', '143983', '133814', '156786', '145996', '162595', '149943', '135568', '150737', '143403', '151976', '135534', '162703', '146267', '142320', '143686']
data_max: tensor([9.0000e+01, 1.0000e+00, 4.6230e+02, 4.0000e+00, 4.7200e+02, 5.3000e+00,
        4.6950e+03, 1.6920e+04, 3.6400e+04, 8.2800e+01, 2.0900e+02, 3.6200e+02,
        2.2100e+01, 2.8300e+02, 1.0000e+00, 1.5000e+01, 1.5910e+03, 5.2000e+01,
        6.1200e+01, 3.0000e+02, 2.2900e+01, 3.1000e+01, 2.9000e+01, 2.9900e+02,
        1.0000e+00, 1.8000e+02, 2.1100e+02, 2.1800e+02, 3.0000e+02, 1.0000e+02,
        5.0000e+02, 7.3500e+02, 2.2920e+03, 1.0000e+02, 1.0000e+02, 2.9500e+02,
        4.2100e+01, 4.9600e+01, 2.9910e+01, 1.0245e+04, 6.2519e+03],
       device='cuda:0')
data_min: tensor([ 1.5000e+01, -1.0000e+00, -1.0000e+00,  1.0000e+00, -1.0000e+00,
         1.0000e+00,  1.1000e+01,  1.0000e+00,  5.0000e+00,  0.0000e+00,
         0.0000e+00,  2.8000e+01,  1.0000e-01, -1.0000e+00,  2.1000e-01,
         3.0000e+00,  8.0000e+00,  5.0000e+00,  5.0000e+00,  0.0000e+00,
         1.8000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,
         9.8000e+01, -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  4.0000e-01,  5.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -1.7800e+01,  1.0000e-01,  1.0000e-02,  0.0000e+00,
         0.0000e+00], device='cuda:0')
time_max: tensor(48., device='cuda:0')
n_train_batches: 225
Exp has been early stopped!
/home/zepenghu/literature_project/t-PatchGNN/tPatchGNN/run_models.py
2024-09-12 22:13:08
run_models.py --dataset physionet --state def --history 24 --patience 10 --batch_size 32 --lr 1e-3 --patch_size 8 --stride 8 --nhead 1 --tf_layer 1 --nlayer 1 --te_dim 10 --node_dim 10 --hid_dim 64 --outlayer Linear --seed 4 --gpu 0
Namespace(state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=1, epoch=1000, patience=10, history=24, patch_size=8.0, stride=8.0, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, save='experiments/', load=None, seed=4, dataset='physionet', quantization=0.0, model='tPatchGNN', outlayer='Linear', hid_dim=64, te_dim=10, node_dim=10, gpu='0', npatch=3, device=device(type='cuda'), PID=26505, ndim=41)
Batch 0 Train - Loss (one batch): 0.11841
Batch 10 Train - Loss (one batch): 0.06069
Batch 20 Train - Loss (one batch): 0.01897
Batch 30 Train - Loss (one batch): 0.02235
Batch 40 Train - Loss (one batch): 0.01358
Batch 50 Train - Loss (one batch): 0.01164
Batch 60 Train - Loss (one batch): 0.01026
Batch 70 Train - Loss (one batch): 0.01327
Batch 80 Train - Loss (one batch): 0.01011
Batch 90 Train - Loss (one batch): 0.01116
Batch 100 Train - Loss (one batch): 0.01110
Batch 110 Train - Loss (one batch): 0.00736
Batch 120 Train - Loss (one batch): 0.00798
Batch 130 Train - Loss (one batch): 0.00710
Batch 140 Train - Loss (one batch): 0.00718
Batch 150 Train - Loss (one batch): 0.00819
Batch 160 Train - Loss (one batch): 0.00719
Batch 170 Train - Loss (one batch): 0.00944
Batch 180 Train - Loss (one batch): 0.00696
Batch 190 Train - Loss (one batch): 0.00668
Batch 200 Train - Loss (one batch): 0.00756
Batch 210 Train - Loss (one batch): 0.00626
Batch 220 Train - Loss (one batch): 0.00631
- Epoch 000, ExpID 88344
Train - Loss (one batch): 0.00632
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00775, 0.00775, 0.08806, 0.05023, 323.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.00723, 0.00723, 0.08505, 0.05052, 371.43%
Time spent: 20.18s
Batch 0 Train - Loss (one batch): 0.00481
Batch 10 Train - Loss (one batch): 0.00548
Batch 20 Train - Loss (one batch): 0.00709
Batch 30 Train - Loss (one batch): 0.00605
Batch 40 Train - Loss (one batch): 0.01406
Batch 50 Train - Loss (one batch): 0.00617
Batch 60 Train - Loss (one batch): 0.00413
Batch 70 Train - Loss (one batch): 0.00959
Batch 80 Train - Loss (one batch): 0.00892
Batch 90 Train - Loss (one batch): 0.00477
Batch 100 Train - Loss (one batch): 0.00648
Batch 110 Train - Loss (one batch): 0.00444
Batch 120 Train - Loss (one batch): 0.01397
Batch 130 Train - Loss (one batch): 0.00471
Batch 140 Train - Loss (one batch): 0.00619
Batch 150 Train - Loss (one batch): 0.00430
Batch 160 Train - Loss (one batch): 0.00758
Batch 170 Train - Loss (one batch): 0.00430
Batch 180 Train - Loss (one batch): 0.00587
Batch 190 Train - Loss (one batch): 0.00445
Batch 200 Train - Loss (one batch): 0.00831
Batch 210 Train - Loss (one batch): 0.00412
Batch 220 Train - Loss (one batch): 0.00507
- Epoch 001, ExpID 88344
Train - Loss (one batch): 0.00657
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00629, 0.00629, 0.07929, 0.04136, 84.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.00576, 0.00576, 0.07593, 0.04104, 88.00%
Time spent: 18.91s
Batch 0 Train - Loss (one batch): 0.00585
Batch 10 Train - Loss (one batch): 0.00525
Batch 20 Train - Loss (one batch): 0.00383
Batch 30 Train - Loss (one batch): 0.00482
Batch 40 Train - Loss (one batch): 0.00383
Batch 50 Train - Loss (one batch): 0.00448
Batch 60 Train - Loss (one batch): 0.00410
Batch 70 Train - Loss (one batch): 0.00450
Batch 80 Train - Loss (one batch): 0.00791
Batch 90 Train - Loss (one batch): 0.01438
Batch 100 Train - Loss (one batch): 0.00649
Batch 110 Train - Loss (one batch): 0.00468
Batch 120 Train - Loss (one batch): 0.00641
Batch 130 Train - Loss (one batch): 0.00413
Batch 140 Train - Loss (one batch): 0.00815
Batch 150 Train - Loss (one batch): 0.00550
Batch 160 Train - Loss (one batch): 0.00392
Batch 170 Train - Loss (one batch): 0.00552
Batch 180 Train - Loss (one batch): 0.00500
Batch 190 Train - Loss (one batch): 0.00470
Batch 200 Train - Loss (one batch): 0.00368
Batch 210 Train - Loss (one batch): 0.00402
Batch 220 Train - Loss (one batch): 0.00449
- Epoch 002, ExpID 88344
Train - Loss (one batch): 0.00551
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00646, 0.00646, 0.08035, 0.04228, 125.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.00576, 0.00576, 0.07593, 0.04104, 88.00%
Time spent: 16.42s
Batch 0 Train - Loss (one batch): 0.00487
Batch 10 Train - Loss (one batch): 0.00420
Batch 20 Train - Loss (one batch): 0.00498
Batch 30 Train - Loss (one batch): 0.00573
Batch 40 Train - Loss (one batch): 0.00402
Batch 50 Train - Loss (one batch): 0.01096
Batch 60 Train - Loss (one batch): 0.00491
Batch 70 Train - Loss (one batch): 0.00455
Batch 80 Train - Loss (one batch): 0.00739
Batch 90 Train - Loss (one batch): 0.00544
Batch 100 Train - Loss (one batch): 0.00453
Batch 110 Train - Loss (one batch): 0.00390
Batch 120 Train - Loss (one batch): 0.00399
Batch 130 Train - Loss (one batch): 0.00502
Batch 140 Train - Loss (one batch): 0.00463
Batch 150 Train - Loss (one batch): 0.00375
Batch 160 Train - Loss (one batch): 0.00482
Batch 170 Train - Loss (one batch): 0.00446
Batch 180 Train - Loss (one batch): 0.00447
Batch 190 Train - Loss (one batch): 0.00444
Batch 200 Train - Loss (one batch): 0.00523
Batch 210 Train - Loss (one batch): 0.00587
Batch 220 Train - Loss (one batch): 0.00496
- Epoch 003, ExpID 88344
Train - Loss (one batch): 0.00953
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00596, 0.00596, 0.07721, 0.04119, 166.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.00555, 0.00555, 0.07448, 0.04129, 179.13%
Time spent: 18.77s
Batch 0 Train - Loss (one batch): 0.00316
Batch 10 Train - Loss (one batch): 0.00273
Batch 20 Train - Loss (one batch): 0.00670
Batch 30 Train - Loss (one batch): 0.00306
Batch 40 Train - Loss (one batch): 0.00473
Batch 50 Train - Loss (one batch): 0.00675
Batch 60 Train - Loss (one batch): 0.00555
Batch 70 Train - Loss (one batch): 0.00461
Batch 80 Train - Loss (one batch): 0.00349
Batch 90 Train - Loss (one batch): 0.01022
Batch 100 Train - Loss (one batch): 0.00323
Batch 110 Train - Loss (one batch): 0.00418
Batch 120 Train - Loss (one batch): 0.00361
Batch 130 Train - Loss (one batch): 0.00332
Batch 140 Train - Loss (one batch): 0.00567
Batch 150 Train - Loss (one batch): 0.00287
Batch 160 Train - Loss (one batch): 0.00378
Batch 170 Train - Loss (one batch): 0.00569
Batch 180 Train - Loss (one batch): 0.00607
Batch 190 Train - Loss (one batch): 0.00273
Batch 200 Train - Loss (one batch): 0.00346
Batch 210 Train - Loss (one batch): 0.00348
Batch 220 Train - Loss (one batch): 0.00589
- Epoch 004, ExpID 88344
Train - Loss (one batch): 0.00372
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00589, 0.00589, 0.07674, 0.03839, 91.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00541, 0.00541, 0.07355, 0.03816, 95.21%
Time spent: 18.77s
Batch 0 Train - Loss (one batch): 0.00487
Batch 10 Train - Loss (one batch): 0.00992
Batch 20 Train - Loss (one batch): 0.00365
Batch 30 Train - Loss (one batch): 0.00387
Batch 40 Train - Loss (one batch): 0.00491
Batch 50 Train - Loss (one batch): 0.00675
Batch 60 Train - Loss (one batch): 0.00507
Batch 70 Train - Loss (one batch): 0.00725
Batch 80 Train - Loss (one batch): 0.00534
Batch 90 Train - Loss (one batch): 0.00592
Batch 100 Train - Loss (one batch): 0.00655
Batch 110 Train - Loss (one batch): 0.00539
Batch 120 Train - Loss (one batch): 0.00573
Batch 130 Train - Loss (one batch): 0.00518
Batch 140 Train - Loss (one batch): 0.00350
Batch 150 Train - Loss (one batch): 0.00533
Batch 160 Train - Loss (one batch): 0.00385
Batch 170 Train - Loss (one batch): 0.00274
Batch 180 Train - Loss (one batch): 0.00376
Batch 190 Train - Loss (one batch): 0.00356
Batch 200 Train - Loss (one batch): 0.00522
Batch 210 Train - Loss (one batch): 0.00505
Batch 220 Train - Loss (one batch): 0.00380
- Epoch 005, ExpID 88344
Train - Loss (one batch): 0.00437
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00616, 0.00616, 0.07846, 0.04035, 90.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00541, 0.00541, 0.07355, 0.03816, 95.21%
Time spent: 16.42s
Batch 0 Train - Loss (one batch): 0.00450
Batch 10 Train - Loss (one batch): 0.00486
Batch 20 Train - Loss (one batch): 0.00444
Batch 30 Train - Loss (one batch): 0.00565
Batch 40 Train - Loss (one batch): 0.00439
Batch 50 Train - Loss (one batch): 0.00550
Batch 60 Train - Loss (one batch): 0.00485
Batch 70 Train - Loss (one batch): 0.00511
Batch 80 Train - Loss (one batch): 0.00461
Batch 90 Train - Loss (one batch): 0.00494
Batch 100 Train - Loss (one batch): 0.00523
Batch 110 Train - Loss (one batch): 0.00379
Batch 120 Train - Loss (one batch): 0.00334
Batch 130 Train - Loss (one batch): 0.00372
Batch 140 Train - Loss (one batch): 0.00585
Batch 150 Train - Loss (one batch): 0.00513
Batch 160 Train - Loss (one batch): 0.00372
Batch 170 Train - Loss (one batch): 0.00354
Batch 180 Train - Loss (one batch): 0.00419
Batch 190 Train - Loss (one batch): 0.00517
Batch 200 Train - Loss (one batch): 0.00435
Batch 210 Train - Loss (one batch): 0.00279
Batch 220 Train - Loss (one batch): 0.00478
- Epoch 006, ExpID 88344
Train - Loss (one batch): 0.00384
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00577, 0.00577, 0.07595, 0.03727, 92.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 18.82s
Batch 0 Train - Loss (one batch): 0.00426
Batch 10 Train - Loss (one batch): 0.00403
Batch 20 Train - Loss (one batch): 0.00353
Batch 30 Train - Loss (one batch): 0.00442
Batch 40 Train - Loss (one batch): 0.00381
Batch 50 Train - Loss (one batch): 0.00414
Batch 60 Train - Loss (one batch): 0.00379
Batch 70 Train - Loss (one batch): 0.00454
Batch 80 Train - Loss (one batch): 0.00394
Batch 90 Train - Loss (one batch): 0.00554
Batch 100 Train - Loss (one batch): 0.00527
Batch 110 Train - Loss (one batch): 0.00474
Batch 120 Train - Loss (one batch): 0.00871
Batch 130 Train - Loss (one batch): 0.00438
Batch 140 Train - Loss (one batch): 0.00428
Batch 150 Train - Loss (one batch): 0.00612
Batch 160 Train - Loss (one batch): 0.00340
Batch 170 Train - Loss (one batch): 0.00863
Batch 180 Train - Loss (one batch): 0.00834
Batch 190 Train - Loss (one batch): 0.00340
Batch 200 Train - Loss (one batch): 0.00362
Batch 210 Train - Loss (one batch): 0.00439
Batch 220 Train - Loss (one batch): 0.00532
- Epoch 007, ExpID 88344
Train - Loss (one batch): 0.00403
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00590, 0.00590, 0.07684, 0.04110, 136.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.30s
Batch 0 Train - Loss (one batch): 0.00464
Batch 10 Train - Loss (one batch): 0.00435
Batch 20 Train - Loss (one batch): 0.00513
Batch 30 Train - Loss (one batch): 0.00444
Batch 40 Train - Loss (one batch): 0.00494
Batch 50 Train - Loss (one batch): 0.00526
Batch 60 Train - Loss (one batch): 0.00616
Batch 70 Train - Loss (one batch): 0.00371
Batch 80 Train - Loss (one batch): 0.00425
Batch 90 Train - Loss (one batch): 0.00335
Batch 100 Train - Loss (one batch): 0.00375
Batch 110 Train - Loss (one batch): 0.00491
Batch 120 Train - Loss (one batch): 0.00382
Batch 130 Train - Loss (one batch): 0.00405
Batch 140 Train - Loss (one batch): 0.00484
Batch 150 Train - Loss (one batch): 0.00348
Batch 160 Train - Loss (one batch): 0.00562
Batch 170 Train - Loss (one batch): 0.00532
Batch 180 Train - Loss (one batch): 0.00441
Batch 190 Train - Loss (one batch): 0.00511
Batch 200 Train - Loss (one batch): 0.00571
Batch 210 Train - Loss (one batch): 0.00585
Batch 220 Train - Loss (one batch): 0.00453
- Epoch 008, ExpID 88344
Train - Loss (one batch): 0.00462
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00584, 0.00584, 0.07640, 0.03878, 88.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.37s
Batch 0 Train - Loss (one batch): 0.00454
Batch 10 Train - Loss (one batch): 0.00428
Batch 20 Train - Loss (one batch): 0.00612
Batch 30 Train - Loss (one batch): 0.00429
Batch 40 Train - Loss (one batch): 0.00418
Batch 50 Train - Loss (one batch): 0.00374
Batch 60 Train - Loss (one batch): 0.00433
Batch 70 Train - Loss (one batch): 0.00554
Batch 80 Train - Loss (one batch): 0.00647
Batch 90 Train - Loss (one batch): 0.00327
Batch 100 Train - Loss (one batch): 0.00871
Batch 110 Train - Loss (one batch): 0.00408
Batch 120 Train - Loss (one batch): 0.00393
Batch 130 Train - Loss (one batch): 0.00427
Batch 140 Train - Loss (one batch): 0.00477
Batch 150 Train - Loss (one batch): 0.00570
Batch 160 Train - Loss (one batch): 0.00542
Batch 170 Train - Loss (one batch): 0.00489
Batch 180 Train - Loss (one batch): 0.00453
Batch 190 Train - Loss (one batch): 0.00261
Batch 200 Train - Loss (one batch): 0.00677
Batch 210 Train - Loss (one batch): 0.00282
Batch 220 Train - Loss (one batch): 0.00502
- Epoch 009, ExpID 88344
Train - Loss (one batch): 0.00314
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00581, 0.00581, 0.07621, 0.03785, 114.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.37s
Batch 0 Train - Loss (one batch): 0.00931
Batch 10 Train - Loss (one batch): 0.00426
Batch 20 Train - Loss (one batch): 0.00409
Batch 30 Train - Loss (one batch): 0.00947
Batch 40 Train - Loss (one batch): 0.00397
Batch 50 Train - Loss (one batch): 0.00646
Batch 60 Train - Loss (one batch): 0.00469
Batch 70 Train - Loss (one batch): 0.00508
Batch 80 Train - Loss (one batch): 0.00560
Batch 90 Train - Loss (one batch): 0.00371
Batch 100 Train - Loss (one batch): 0.00381
Batch 110 Train - Loss (one batch): 0.00545
Batch 120 Train - Loss (one batch): 0.00512
Batch 130 Train - Loss (one batch): 0.00499
Batch 140 Train - Loss (one batch): 0.00549
Batch 150 Train - Loss (one batch): 0.00551
Batch 160 Train - Loss (one batch): 0.00406
Batch 170 Train - Loss (one batch): 0.00521
Batch 180 Train - Loss (one batch): 0.00404
Batch 190 Train - Loss (one batch): 0.00353
Batch 200 Train - Loss (one batch): 0.00357
Batch 210 Train - Loss (one batch): 0.00503
Batch 220 Train - Loss (one batch): 0.00450
- Epoch 010, ExpID 88344
Train - Loss (one batch): 0.00412
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00600, 0.00600, 0.07749, 0.03825, 55.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.40s
Batch 0 Train - Loss (one batch): 0.00369
Batch 10 Train - Loss (one batch): 0.00330
Batch 20 Train - Loss (one batch): 0.00406
Batch 30 Train - Loss (one batch): 0.00588
Batch 40 Train - Loss (one batch): 0.00428
Batch 50 Train - Loss (one batch): 0.00357
Batch 60 Train - Loss (one batch): 0.00268
Batch 70 Train - Loss (one batch): 0.00501
Batch 80 Train - Loss (one batch): 0.00519
Batch 90 Train - Loss (one batch): 0.00364
Batch 100 Train - Loss (one batch): 0.00365
Batch 110 Train - Loss (one batch): 0.00419
Batch 120 Train - Loss (one batch): 0.00353
Batch 130 Train - Loss (one batch): 0.00443
Batch 140 Train - Loss (one batch): 0.00473
Batch 150 Train - Loss (one batch): 0.00392
Batch 160 Train - Loss (one batch): 0.00548
Batch 170 Train - Loss (one batch): 0.00398
Batch 180 Train - Loss (one batch): 0.00693
Batch 190 Train - Loss (one batch): 0.00576
Batch 200 Train - Loss (one batch): 0.00489
Batch 210 Train - Loss (one batch): 0.00535
Batch 220 Train - Loss (one batch): 0.00402
- Epoch 011, ExpID 88344
Train - Loss (one batch): 0.00327
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00602, 0.00602, 0.07757, 0.03948, 86.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.37s
Batch 0 Train - Loss (one batch): 0.00384
Batch 10 Train - Loss (one batch): 0.00425
Batch 20 Train - Loss (one batch): 0.00363
Batch 30 Train - Loss (one batch): 0.00335
Batch 40 Train - Loss (one batch): 0.00572
Batch 50 Train - Loss (one batch): 0.00368
Batch 60 Train - Loss (one batch): 0.00374
Batch 70 Train - Loss (one batch): 0.01019
Batch 80 Train - Loss (one batch): 0.00377
Batch 90 Train - Loss (one batch): 0.00432
Batch 100 Train - Loss (one batch): 0.00340
Batch 110 Train - Loss (one batch): 0.00288
Batch 120 Train - Loss (one batch): 0.00228
Batch 130 Train - Loss (one batch): 0.00403
Batch 140 Train - Loss (one batch): 0.00441
Batch 150 Train - Loss (one batch): 0.00373
Batch 160 Train - Loss (one batch): 0.00382
Batch 170 Train - Loss (one batch): 0.00434
Batch 180 Train - Loss (one batch): 0.00437
Batch 190 Train - Loss (one batch): 0.00300
Batch 200 Train - Loss (one batch): 0.00405
Batch 210 Train - Loss (one batch): 0.00433
Batch 220 Train - Loss (one batch): 0.00371
- Epoch 012, ExpID 88344
Train - Loss (one batch): 0.00384
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00587, 0.00587, 0.07662, 0.03862, 88.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.46s
Batch 0 Train - Loss (one batch): 0.00418
Batch 10 Train - Loss (one batch): 0.00270
Batch 20 Train - Loss (one batch): 0.00372
Batch 30 Train - Loss (one batch): 0.00545
Batch 40 Train - Loss (one batch): 0.00556
Batch 50 Train - Loss (one batch): 0.00468
Batch 60 Train - Loss (one batch): 0.00380
Batch 70 Train - Loss (one batch): 0.00546
Batch 80 Train - Loss (one batch): 0.00577
Batch 90 Train - Loss (one batch): 0.00363
Batch 100 Train - Loss (one batch): 0.00474
Batch 110 Train - Loss (one batch): 0.00490
Batch 120 Train - Loss (one batch): 0.00481
Batch 130 Train - Loss (one batch): 0.00305
Batch 140 Train - Loss (one batch): 0.00398
Batch 150 Train - Loss (one batch): 0.00516
Batch 160 Train - Loss (one batch): 0.00625
Batch 170 Train - Loss (one batch): 0.00326
Batch 180 Train - Loss (one batch): 0.00476
Batch 190 Train - Loss (one batch): 0.00426
Batch 200 Train - Loss (one batch): 0.00493
Batch 210 Train - Loss (one batch): 0.00448
Batch 220 Train - Loss (one batch): 0.00279
- Epoch 013, ExpID 88344
Train - Loss (one batch): 0.00412
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00607, 0.00607, 0.07788, 0.03761, 89.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.42s
Batch 0 Train - Loss (one batch): 0.00427
Batch 10 Train - Loss (one batch): 0.00280
Batch 20 Train - Loss (one batch): 0.00510
Batch 30 Train - Loss (one batch): 0.00606
Batch 40 Train - Loss (one batch): 0.00736
Batch 50 Train - Loss (one batch): 0.00379
Batch 60 Train - Loss (one batch): 0.00590
Batch 70 Train - Loss (one batch): 0.00463
Batch 80 Train - Loss (one batch): 0.00352
Batch 90 Train - Loss (one batch): 0.00562
Batch 100 Train - Loss (one batch): 0.00476
Batch 110 Train - Loss (one batch): 0.00438
Batch 120 Train - Loss (one batch): 0.00538
Batch 130 Train - Loss (one batch): 0.00411
Batch 140 Train - Loss (one batch): 0.00327
Batch 150 Train - Loss (one batch): 0.00330
Batch 160 Train - Loss (one batch): 0.00451
Batch 170 Train - Loss (one batch): 0.00455
Batch 180 Train - Loss (one batch): 0.00395
Batch 190 Train - Loss (one batch): 0.00504
Batch 200 Train - Loss (one batch): 0.00283
Batch 210 Train - Loss (one batch): 0.00376
Batch 220 Train - Loss (one batch): 0.00406
- Epoch 014, ExpID 88344
Train - Loss (one batch): 0.00370
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00591, 0.00591, 0.07688, 0.03953, 166.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.33s
Batch 0 Train - Loss (one batch): 0.00501
Batch 10 Train - Loss (one batch): 0.00374
Batch 20 Train - Loss (one batch): 0.00958
Batch 30 Train - Loss (one batch): 0.00480
Batch 40 Train - Loss (one batch): 0.00318
Batch 50 Train - Loss (one batch): 0.00477
Batch 60 Train - Loss (one batch): 0.00449
Batch 70 Train - Loss (one batch): 0.00287
Batch 80 Train - Loss (one batch): 0.00416
Batch 90 Train - Loss (one batch): 0.00574
Batch 100 Train - Loss (one batch): 0.00576
Batch 110 Train - Loss (one batch): 0.00567
Batch 120 Train - Loss (one batch): 0.00372
Batch 130 Train - Loss (one batch): 0.00380
Batch 140 Train - Loss (one batch): 0.00524
Batch 150 Train - Loss (one batch): 0.00372
Batch 160 Train - Loss (one batch): 0.00370
Batch 170 Train - Loss (one batch): 0.00468
Batch 180 Train - Loss (one batch): 0.00612
Batch 190 Train - Loss (one batch): 0.00342
Batch 200 Train - Loss (one batch): 0.00497
Batch 210 Train - Loss (one batch): 0.00525
Batch 220 Train - Loss (one batch): 0.00495
- Epoch 015, ExpID 88344
Train - Loss (one batch): 0.00355
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00612, 0.00612, 0.07825, 0.04025, 60.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.35s
Batch 0 Train - Loss (one batch): 0.00473
Batch 10 Train - Loss (one batch): 0.00444
Batch 20 Train - Loss (one batch): 0.00606
Batch 30 Train - Loss (one batch): 0.00343
Batch 40 Train - Loss (one batch): 0.00389
Batch 50 Train - Loss (one batch): 0.00474
Batch 60 Train - Loss (one batch): 0.00420
Batch 70 Train - Loss (one batch): 0.00363
Batch 80 Train - Loss (one batch): 0.00486
Batch 90 Train - Loss (one batch): 0.00504
Batch 100 Train - Loss (one batch): 0.00420
Batch 110 Train - Loss (one batch): 0.00459
Batch 120 Train - Loss (one batch): 0.00497
Batch 130 Train - Loss (one batch): 0.00366
Batch 140 Train - Loss (one batch): 0.00667
Batch 150 Train - Loss (one batch): 0.00454
Batch 160 Train - Loss (one batch): 0.00261
Batch 170 Train - Loss (one batch): 0.00350
Batch 180 Train - Loss (one batch): 0.00407
Batch 190 Train - Loss (one batch): 0.00677
Batch 200 Train - Loss (one batch): 0.00319
Batch 210 Train - Loss (one batch): 0.00437
Batch 220 Train - Loss (one batch): 0.00488
- Epoch 016, ExpID 88344
Train - Loss (one batch): 0.00334
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00585, 0.00585, 0.07649, 0.03745, 78.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.39s
PID, device: 26505 cuda
Total records: 12000
Dataset n_samples: 12000 7200 2400 2400
Test record ids (first 20): ['137448', '148956', '136914', '155610', '133454', '156996', '145930', '154208', '138164', '144190', '141346', '136111', '133728', '135488', '145796', '153197', '133620', '150418', '138790', '137164']
Test record ids (last 20): ['152600', '137920', '145610', '144568', '134835', '143983', '133814', '156786', '145996', '162595', '149943', '135568', '150737', '143403', '151976', '135534', '162703', '146267', '142320', '143686']
data_max: tensor([9.0000e+01, 1.0000e+00, 4.6230e+02, 4.0000e+00, 4.7200e+02, 5.3000e+00,
        4.6950e+03, 1.6920e+04, 3.6400e+04, 8.2800e+01, 2.0900e+02, 3.6200e+02,
        2.2100e+01, 2.8300e+02, 1.0000e+00, 1.5000e+01, 1.5910e+03, 5.2000e+01,
        6.1200e+01, 3.0000e+02, 2.2900e+01, 3.1000e+01, 2.9000e+01, 2.9900e+02,
        1.0000e+00, 1.8000e+02, 2.1100e+02, 2.1800e+02, 3.0000e+02, 1.0000e+02,
        5.0000e+02, 7.3500e+02, 2.2920e+03, 1.0000e+02, 1.0000e+02, 2.9500e+02,
        4.2100e+01, 4.9600e+01, 2.9910e+01, 1.0245e+04, 6.2519e+03],
       device='cuda:0')
data_min: tensor([ 1.5000e+01, -1.0000e+00, -1.0000e+00,  1.0000e+00, -1.0000e+00,
         1.0000e+00,  1.1000e+01,  1.0000e+00,  5.0000e+00,  0.0000e+00,
         0.0000e+00,  2.8000e+01,  1.0000e-01, -1.0000e+00,  2.1000e-01,
         3.0000e+00,  8.0000e+00,  5.0000e+00,  5.0000e+00,  0.0000e+00,
         1.8000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,
         9.8000e+01, -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  4.0000e-01,  5.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -1.7800e+01,  1.0000e-01,  1.0000e-02,  0.0000e+00,
         0.0000e+00], device='cuda:0')
time_max: tensor(48., device='cuda:0')
n_train_batches: 225
Exp has been early stopped!
/home/zepenghu/literature_project/t-PatchGNN/tPatchGNN/run_models.py
2024-09-12 22:19:10
run_models.py --dataset physionet --state def --history 24 --patience 10 --batch_size 32 --lr 1e-3 --patch_size 8 --stride 8 --nhead 1 --tf_layer 1 --nlayer 1 --te_dim 10 --node_dim 10 --hid_dim 64 --outlayer Linear --seed 5 --gpu 0
Namespace(state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=1, epoch=1000, patience=10, history=24, patch_size=8.0, stride=8.0, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, save='experiments/', load=None, seed=5, dataset='physionet', quantization=0.0, model='tPatchGNN', outlayer='Linear', hid_dim=64, te_dim=10, node_dim=10, gpu='0', npatch=3, device=device(type='cuda'), PID=26708, ndim=41)
Batch 0 Train - Loss (one batch): 0.19215
Batch 10 Train - Loss (one batch): 0.07353
Batch 20 Train - Loss (one batch): 0.06358
Batch 30 Train - Loss (one batch): 0.03495
Batch 40 Train - Loss (one batch): 0.01711
Batch 50 Train - Loss (one batch): 0.01298
Batch 60 Train - Loss (one batch): 0.01935
Batch 70 Train - Loss (one batch): 0.01119
Batch 80 Train - Loss (one batch): 0.01083
Batch 90 Train - Loss (one batch): 0.00799
Batch 100 Train - Loss (one batch): 0.00893
Batch 110 Train - Loss (one batch): 0.00939
Batch 120 Train - Loss (one batch): 0.00917
Batch 130 Train - Loss (one batch): 0.00905
Batch 140 Train - Loss (one batch): 0.00963
Batch 150 Train - Loss (one batch): 0.00744
Batch 160 Train - Loss (one batch): 0.01144
Batch 170 Train - Loss (one batch): 0.00765
Batch 180 Train - Loss (one batch): 0.00753
Batch 190 Train - Loss (one batch): 0.00520
Batch 200 Train - Loss (one batch): 0.00836
Batch 210 Train - Loss (one batch): 0.00654
Batch 220 Train - Loss (one batch): 0.00942
- Epoch 000, ExpID 70285
Train - Loss (one batch): 0.00827
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00773, 0.00773, 0.08791, 0.05117, 112.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.00745, 0.00745, 0.08633, 0.05113, 115.24%
Time spent: 19.87s
Batch 0 Train - Loss (one batch): 0.00494
Batch 10 Train - Loss (one batch): 0.00774
Batch 20 Train - Loss (one batch): 0.00448
Batch 30 Train - Loss (one batch): 0.00893
Batch 40 Train - Loss (one batch): 0.00562
Batch 50 Train - Loss (one batch): 0.00667
Batch 60 Train - Loss (one batch): 0.00503
Batch 70 Train - Loss (one batch): 0.00603
Batch 80 Train - Loss (one batch): 0.00563
Batch 90 Train - Loss (one batch): 0.00553
Batch 100 Train - Loss (one batch): 0.00503
Batch 110 Train - Loss (one batch): 0.00743
Batch 120 Train - Loss (one batch): 0.00963
Batch 130 Train - Loss (one batch): 0.00852
Batch 140 Train - Loss (one batch): 0.00703
Batch 150 Train - Loss (one batch): 0.00474
Batch 160 Train - Loss (one batch): 0.00517
Batch 170 Train - Loss (one batch): 0.00434
Batch 180 Train - Loss (one batch): 0.00582
Batch 190 Train - Loss (one batch): 0.00504
Batch 200 Train - Loss (one batch): 0.00517
Batch 210 Train - Loss (one batch): 0.00611
Batch 220 Train - Loss (one batch): 0.00533
- Epoch 001, ExpID 70285
Train - Loss (one batch): 0.00519
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00689, 0.00689, 0.08300, 0.04555, 141.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.00658, 0.00658, 0.08110, 0.04550, 152.19%
Time spent: 18.37s
Batch 0 Train - Loss (one batch): 0.00508
Batch 10 Train - Loss (one batch): 0.00514
Batch 20 Train - Loss (one batch): 0.00837
Batch 30 Train - Loss (one batch): 0.00362
Batch 40 Train - Loss (one batch): 0.00531
Batch 50 Train - Loss (one batch): 0.00534
Batch 60 Train - Loss (one batch): 0.01100
Batch 70 Train - Loss (one batch): 0.00344
Batch 80 Train - Loss (one batch): 0.00451
Batch 90 Train - Loss (one batch): 0.00428
Batch 100 Train - Loss (one batch): 0.00469
Batch 110 Train - Loss (one batch): 0.00790
Batch 120 Train - Loss (one batch): 0.00588
Batch 130 Train - Loss (one batch): 0.01101
Batch 140 Train - Loss (one batch): 0.00659
Batch 150 Train - Loss (one batch): 0.00421
Batch 160 Train - Loss (one batch): 0.00516
Batch 170 Train - Loss (one batch): 0.00504
Batch 180 Train - Loss (one batch): 0.00563
Batch 190 Train - Loss (one batch): 0.00671
Batch 200 Train - Loss (one batch): 0.00694
Batch 210 Train - Loss (one batch): 0.00434
Batch 220 Train - Loss (one batch): 0.00538
- Epoch 002, ExpID 70285
Train - Loss (one batch): 0.00593
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00683, 0.00683, 0.08266, 0.04555, 90.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.00680, 0.00680, 0.08244, 0.04583, 94.42%
Time spent: 18.38s
Batch 0 Train - Loss (one batch): 0.00471
Batch 10 Train - Loss (one batch): 0.00592
Batch 20 Train - Loss (one batch): 0.00679
Batch 30 Train - Loss (one batch): 0.00670
Batch 40 Train - Loss (one batch): 0.00682
Batch 50 Train - Loss (one batch): 0.00463
Batch 60 Train - Loss (one batch): 0.00446
Batch 70 Train - Loss (one batch): 0.00571
Batch 80 Train - Loss (one batch): 0.00609
Batch 90 Train - Loss (one batch): 0.00527
Batch 100 Train - Loss (one batch): 0.00373
Batch 110 Train - Loss (one batch): 0.00652
Batch 120 Train - Loss (one batch): 0.00555
Batch 130 Train - Loss (one batch): 0.00567
Batch 140 Train - Loss (one batch): 0.00466
Batch 150 Train - Loss (one batch): 0.00512
Batch 160 Train - Loss (one batch): 0.00588
Batch 170 Train - Loss (one batch): 0.00608
Batch 180 Train - Loss (one batch): 0.00419
Batch 190 Train - Loss (one batch): 0.00530
Batch 200 Train - Loss (one batch): 0.00361
Batch 210 Train - Loss (one batch): 0.00388
Batch 220 Train - Loss (one batch): 0.00586
- Epoch 003, ExpID 70285
Train - Loss (one batch): 0.00461
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00643, 0.00643, 0.08016, 0.04362, 74.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.00626, 0.00626, 0.07915, 0.04392, 76.64%
Time spent: 18.36s
Batch 0 Train - Loss (one batch): 0.00400
Batch 10 Train - Loss (one batch): 0.00467
Batch 20 Train - Loss (one batch): 0.00496
Batch 30 Train - Loss (one batch): 0.00415
Batch 40 Train - Loss (one batch): 0.00581
Batch 50 Train - Loss (one batch): 0.00435
Batch 60 Train - Loss (one batch): 0.00401
Batch 70 Train - Loss (one batch): 0.00415
Batch 80 Train - Loss (one batch): 0.00362
Batch 90 Train - Loss (one batch): 0.00615
Batch 100 Train - Loss (one batch): 0.00693
Batch 110 Train - Loss (one batch): 0.00377
Batch 120 Train - Loss (one batch): 0.00436
Batch 130 Train - Loss (one batch): 0.00797
Batch 140 Train - Loss (one batch): 0.00572
Batch 150 Train - Loss (one batch): 0.00375
Batch 160 Train - Loss (one batch): 0.00355
Batch 170 Train - Loss (one batch): 0.00452
Batch 180 Train - Loss (one batch): 0.00624
Batch 190 Train - Loss (one batch): 0.00567
Batch 200 Train - Loss (one batch): 0.00606
Batch 210 Train - Loss (one batch): 0.00496
Batch 220 Train - Loss (one batch): 0.00565
- Epoch 004, ExpID 70285
Train - Loss (one batch): 0.00381
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00656, 0.00656, 0.08102, 0.04405, 87.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.00626, 0.00626, 0.07915, 0.04392, 76.64%
Time spent: 16.00s
Batch 0 Train - Loss (one batch): 0.00659
Batch 10 Train - Loss (one batch): 0.00477
Batch 20 Train - Loss (one batch): 0.00322
Batch 30 Train - Loss (one batch): 0.00384
Batch 40 Train - Loss (one batch): 0.00363
Batch 50 Train - Loss (one batch): 0.00529
Batch 60 Train - Loss (one batch): 0.00426
Batch 70 Train - Loss (one batch): 0.00474
Batch 80 Train - Loss (one batch): 0.00570
Batch 90 Train - Loss (one batch): 0.00801
Batch 100 Train - Loss (one batch): 0.00420
Batch 110 Train - Loss (one batch): 0.00557
Batch 120 Train - Loss (one batch): 0.00489
Batch 130 Train - Loss (one batch): 0.00508
Batch 140 Train - Loss (one batch): 0.00412
Batch 150 Train - Loss (one batch): 0.00349
Batch 160 Train - Loss (one batch): 0.00395
Batch 170 Train - Loss (one batch): 0.00593
Batch 180 Train - Loss (one batch): 0.00614
Batch 190 Train - Loss (one batch): 0.00721
Batch 200 Train - Loss (one batch): 0.00698
Batch 210 Train - Loss (one batch): 0.00528
Batch 220 Train - Loss (one batch): 0.00419
- Epoch 005, ExpID 70285
Train - Loss (one batch): 0.00601
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00641, 0.00641, 0.08006, 0.04310, 81.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.00608, 0.00608, 0.07796, 0.04295, 83.53%
Time spent: 18.41s
Batch 0 Train - Loss (one batch): 0.00917
Batch 10 Train - Loss (one batch): 0.00563
Batch 20 Train - Loss (one batch): 0.00508
Batch 30 Train - Loss (one batch): 0.00413
Batch 40 Train - Loss (one batch): 0.00349
Batch 50 Train - Loss (one batch): 0.00568
Batch 60 Train - Loss (one batch): 0.00464
Batch 70 Train - Loss (one batch): 0.00422
Batch 80 Train - Loss (one batch): 0.00431
Batch 90 Train - Loss (one batch): 0.00561
Batch 100 Train - Loss (one batch): 0.00495
Batch 110 Train - Loss (one batch): 0.00552
Batch 120 Train - Loss (one batch): 0.00529
Batch 130 Train - Loss (one batch): 0.00502
Batch 140 Train - Loss (one batch): 0.00470
Batch 150 Train - Loss (one batch): 0.00555
Batch 160 Train - Loss (one batch): 0.00586
Batch 170 Train - Loss (one batch): 0.00479
Batch 180 Train - Loss (one batch): 0.00633
Batch 190 Train - Loss (one batch): 0.00432
Batch 200 Train - Loss (one batch): 0.00421
Batch 210 Train - Loss (one batch): 0.00476
Batch 220 Train - Loss (one batch): 0.00509
- Epoch 006, ExpID 70285
Train - Loss (one batch): 0.00635
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00671, 0.00671, 0.08189, 0.04353, 55.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.00608, 0.00608, 0.07796, 0.04295, 83.53%
Time spent: 16.15s
Batch 0 Train - Loss (one batch): 0.00748
Batch 10 Train - Loss (one batch): 0.00342
Batch 20 Train - Loss (one batch): 0.00478
Batch 30 Train - Loss (one batch): 0.00357
Batch 40 Train - Loss (one batch): 0.00547
Batch 50 Train - Loss (one batch): 0.00500
Batch 60 Train - Loss (one batch): 0.00345
Batch 70 Train - Loss (one batch): 0.00495
Batch 80 Train - Loss (one batch): 0.00387
Batch 90 Train - Loss (one batch): 0.00568
Batch 100 Train - Loss (one batch): 0.00513
Batch 110 Train - Loss (one batch): 0.00527
Batch 120 Train - Loss (one batch): 0.01252
Batch 130 Train - Loss (one batch): 0.00502
Batch 140 Train - Loss (one batch): 0.00471
Batch 150 Train - Loss (one batch): 0.00481
Batch 160 Train - Loss (one batch): 0.00487
Batch 170 Train - Loss (one batch): 0.00404
Batch 180 Train - Loss (one batch): 0.00637
Batch 190 Train - Loss (one batch): 0.00470
Batch 200 Train - Loss (one batch): 0.00486
Batch 210 Train - Loss (one batch): 0.00535
Batch 220 Train - Loss (one batch): 0.00548
- Epoch 007, ExpID 70285
Train - Loss (one batch): 0.00433
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00630, 0.00630, 0.07936, 0.04232, 58.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.00608, 0.00608, 0.07798, 0.04256, 61.48%
Time spent: 19.67s
Batch 0 Train - Loss (one batch): 0.00456
Batch 10 Train - Loss (one batch): 0.00536
Batch 20 Train - Loss (one batch): 0.00464
Batch 30 Train - Loss (one batch): 0.00579
Batch 40 Train - Loss (one batch): 0.00433
Batch 50 Train - Loss (one batch): 0.00441
Batch 60 Train - Loss (one batch): 0.00569
Batch 70 Train - Loss (one batch): 0.00426
Batch 80 Train - Loss (one batch): 0.00494
Batch 90 Train - Loss (one batch): 0.00385
Batch 100 Train - Loss (one batch): 0.00576
Batch 110 Train - Loss (one batch): 0.00466
Batch 120 Train - Loss (one batch): 0.00375
Batch 130 Train - Loss (one batch): 0.00532
Batch 140 Train - Loss (one batch): 0.00492
Batch 150 Train - Loss (one batch): 0.00539
Batch 160 Train - Loss (one batch): 0.01186
Batch 170 Train - Loss (one batch): 0.00506
Batch 180 Train - Loss (one batch): 0.00462
Batch 190 Train - Loss (one batch): 0.00503
Batch 200 Train - Loss (one batch): 0.00496
Batch 210 Train - Loss (one batch): 0.00455
Batch 220 Train - Loss (one batch): 0.00697
- Epoch 008, ExpID 70285
Train - Loss (one batch): 0.00354
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00617, 0.00617, 0.07852, 0.04167, 75.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.00576, 0.00576, 0.07588, 0.04139, 77.74%
Time spent: 19.10s
Batch 0 Train - Loss (one batch): 0.00714
Batch 10 Train - Loss (one batch): 0.00433
Batch 20 Train - Loss (one batch): 0.00530
Batch 30 Train - Loss (one batch): 0.00370
Batch 40 Train - Loss (one batch): 0.00537
Batch 50 Train - Loss (one batch): 0.00657
Batch 60 Train - Loss (one batch): 0.00556
Batch 70 Train - Loss (one batch): 0.00276
Batch 80 Train - Loss (one batch): 0.00537
Batch 90 Train - Loss (one batch): 0.00373
Batch 100 Train - Loss (one batch): 0.00441
Batch 110 Train - Loss (one batch): 0.00394
Batch 120 Train - Loss (one batch): 0.00368
Batch 130 Train - Loss (one batch): 0.00496
Batch 140 Train - Loss (one batch): 0.00587
Batch 150 Train - Loss (one batch): 0.00509
Batch 160 Train - Loss (one batch): 0.00502
Batch 170 Train - Loss (one batch): 0.00446
Batch 180 Train - Loss (one batch): 0.00301
Batch 190 Train - Loss (one batch): 0.00348
Batch 200 Train - Loss (one batch): 0.00603
Batch 210 Train - Loss (one batch): 0.00468
Batch 220 Train - Loss (one batch): 0.00545
- Epoch 009, ExpID 70285
Train - Loss (one batch): 0.00403
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00701, 0.00701, 0.08374, 0.04746, 110.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.00576, 0.00576, 0.07588, 0.04139, 77.74%
Time spent: 16.70s
Batch 0 Train - Loss (one batch): 0.00504
Batch 10 Train - Loss (one batch): 0.00416
Batch 20 Train - Loss (one batch): 0.00523
Batch 30 Train - Loss (one batch): 0.00489
Batch 40 Train - Loss (one batch): 0.00599
Batch 50 Train - Loss (one batch): 0.00531
Batch 60 Train - Loss (one batch): 0.00356
Batch 70 Train - Loss (one batch): 0.00560
Batch 80 Train - Loss (one batch): 0.00388
Batch 90 Train - Loss (one batch): 0.00656
Batch 100 Train - Loss (one batch): 0.00422
Batch 110 Train - Loss (one batch): 0.00652
Batch 120 Train - Loss (one batch): 0.00419
Batch 130 Train - Loss (one batch): 0.00453
Batch 140 Train - Loss (one batch): 0.00368
Batch 150 Train - Loss (one batch): 0.00379
Batch 160 Train - Loss (one batch): 0.00557
Batch 170 Train - Loss (one batch): 0.00550
Batch 180 Train - Loss (one batch): 0.00476
Batch 190 Train - Loss (one batch): 0.00489
Batch 200 Train - Loss (one batch): 0.00564
Batch 210 Train - Loss (one batch): 0.00713
Batch 220 Train - Loss (one batch): 0.00400
- Epoch 010, ExpID 70285
Train - Loss (one batch): 0.00521
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00616, 0.00616, 0.07851, 0.04267, 121.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.00592, 0.00592, 0.07694, 0.04260, 120.61%
Time spent: 19.03s
Batch 0 Train - Loss (one batch): 0.00451
Batch 10 Train - Loss (one batch): 0.00476
Batch 20 Train - Loss (one batch): 0.00455
Batch 30 Train - Loss (one batch): 0.00489
Batch 40 Train - Loss (one batch): 0.00424
Batch 50 Train - Loss (one batch): 0.00437
Batch 60 Train - Loss (one batch): 0.00615
Batch 70 Train - Loss (one batch): 0.00400
Batch 80 Train - Loss (one batch): 0.00433
Batch 90 Train - Loss (one batch): 0.00535
Batch 100 Train - Loss (one batch): 0.00319
Batch 110 Train - Loss (one batch): 0.00640
Batch 120 Train - Loss (one batch): 0.00465
Batch 130 Train - Loss (one batch): 0.00673
Batch 140 Train - Loss (one batch): 0.00476
Batch 150 Train - Loss (one batch): 0.00400
Batch 160 Train - Loss (one batch): 0.00527
Batch 170 Train - Loss (one batch): 0.00618
Batch 180 Train - Loss (one batch): 0.00442
Batch 190 Train - Loss (one batch): 0.00373
Batch 200 Train - Loss (one batch): 0.00682
Batch 210 Train - Loss (one batch): 0.00491
Batch 220 Train - Loss (one batch): 0.00430
- Epoch 011, ExpID 70285
Train - Loss (one batch): 0.00463
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00612, 0.00612, 0.07821, 0.03949, 60.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.00572, 0.00572, 0.07564, 0.03937, 62.33%
Time spent: 19.02s
Batch 0 Train - Loss (one batch): 0.00571
Batch 10 Train - Loss (one batch): 0.00526
Batch 20 Train - Loss (one batch): 0.00513
Batch 30 Train - Loss (one batch): 0.00479
Batch 40 Train - Loss (one batch): 0.00623
Batch 50 Train - Loss (one batch): 0.00403
Batch 60 Train - Loss (one batch): 0.00261
Batch 70 Train - Loss (one batch): 0.00331
Batch 80 Train - Loss (one batch): 0.00369
Batch 90 Train - Loss (one batch): 0.00474
Batch 100 Train - Loss (one batch): 0.00395
Batch 110 Train - Loss (one batch): 0.00582
Batch 120 Train - Loss (one batch): 0.00315
Batch 130 Train - Loss (one batch): 0.00526
Batch 140 Train - Loss (one batch): 0.00514
Batch 150 Train - Loss (one batch): 0.00349
Batch 160 Train - Loss (one batch): 0.00309
Batch 170 Train - Loss (one batch): 0.00571
Batch 180 Train - Loss (one batch): 0.00344
Batch 190 Train - Loss (one batch): 0.00819
Batch 200 Train - Loss (one batch): 0.00602
Batch 210 Train - Loss (one batch): 0.00786
Batch 220 Train - Loss (one batch): 0.00373
- Epoch 012, ExpID 70285
Train - Loss (one batch): 0.00429
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00624, 0.00624, 0.07898, 0.04234, 50.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.00572, 0.00572, 0.07564, 0.03937, 62.33%
Time spent: 16.61s
Batch 0 Train - Loss (one batch): 0.00511
Batch 10 Train - Loss (one batch): 0.00406
Batch 20 Train - Loss (one batch): 0.00585
Batch 30 Train - Loss (one batch): 0.00371
Batch 40 Train - Loss (one batch): 0.00616
Batch 50 Train - Loss (one batch): 0.00344
Batch 60 Train - Loss (one batch): 0.00478
Batch 70 Train - Loss (one batch): 0.00374
Batch 80 Train - Loss (one batch): 0.00263
Batch 90 Train - Loss (one batch): 0.00458
Batch 100 Train - Loss (one batch): 0.01220
Batch 110 Train - Loss (one batch): 0.00626
Batch 120 Train - Loss (one batch): 0.00317
Batch 130 Train - Loss (one batch): 0.00412
Batch 140 Train - Loss (one batch): 0.00443
Batch 150 Train - Loss (one batch): 0.00347
Batch 160 Train - Loss (one batch): 0.00415
Batch 170 Train - Loss (one batch): 0.00388
Batch 180 Train - Loss (one batch): 0.00475
Batch 190 Train - Loss (one batch): 0.00349
Batch 200 Train - Loss (one batch): 0.00678
Batch 210 Train - Loss (one batch): 0.00325
Batch 220 Train - Loss (one batch): 0.00342
- Epoch 013, ExpID 70285
Train - Loss (one batch): 0.00562
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00608, 0.00608, 0.07800, 0.04026, 74.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.00564, 0.00564, 0.07509, 0.03998, 73.52%
Time spent: 19.26s
Batch 0 Train - Loss (one batch): 0.00406
Batch 10 Train - Loss (one batch): 0.00535
Batch 20 Train - Loss (one batch): 0.00816
Batch 30 Train - Loss (one batch): 0.00449
Batch 40 Train - Loss (one batch): 0.00381
Batch 50 Train - Loss (one batch): 0.00394
Batch 60 Train - Loss (one batch): 0.00491
Batch 70 Train - Loss (one batch): 0.00502
Batch 80 Train - Loss (one batch): 0.00517
Batch 90 Train - Loss (one batch): 0.00559
Batch 100 Train - Loss (one batch): 0.00278
Batch 110 Train - Loss (one batch): 0.00572
Batch 120 Train - Loss (one batch): 0.00443
Batch 130 Train - Loss (one batch): 0.01043
Batch 140 Train - Loss (one batch): 0.00511
Batch 150 Train - Loss (one batch): 0.00563
Batch 160 Train - Loss (one batch): 0.00529
Batch 170 Train - Loss (one batch): 0.00517
Batch 180 Train - Loss (one batch): 0.00324
Batch 190 Train - Loss (one batch): 0.00276
Batch 200 Train - Loss (one batch): 0.00514
Batch 210 Train - Loss (one batch): 0.00352
Batch 220 Train - Loss (one batch): 0.00458
- Epoch 014, ExpID 70285
Train - Loss (one batch): 0.00399
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00609, 0.00609, 0.07806, 0.04033, 80.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.00564, 0.00564, 0.07509, 0.03998, 73.52%
Time spent: 16.56s
Batch 0 Train - Loss (one batch): 0.00542
Batch 10 Train - Loss (one batch): 0.00344
Batch 20 Train - Loss (one batch): 0.00528
Batch 30 Train - Loss (one batch): 0.00336
Batch 40 Train - Loss (one batch): 0.00510
Batch 50 Train - Loss (one batch): 0.00463
Batch 60 Train - Loss (one batch): 0.00465
Batch 70 Train - Loss (one batch): 0.01163
Batch 80 Train - Loss (one batch): 0.00489
Batch 90 Train - Loss (one batch): 0.00325
Batch 100 Train - Loss (one batch): 0.00524
Batch 110 Train - Loss (one batch): 0.00305
Batch 120 Train - Loss (one batch): 0.00584
Batch 130 Train - Loss (one batch): 0.00456
Batch 140 Train - Loss (one batch): 0.00584
Batch 150 Train - Loss (one batch): 0.00461
Batch 160 Train - Loss (one batch): 0.00358
Batch 170 Train - Loss (one batch): 0.00438
Batch 180 Train - Loss (one batch): 0.00485
Batch 190 Train - Loss (one batch): 0.00351
Batch 200 Train - Loss (one batch): 0.00248
Batch 210 Train - Loss (one batch): 0.00492
Batch 220 Train - Loss (one batch): 0.00397
- Epoch 015, ExpID 70285
Train - Loss (one batch): 0.00642
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00613, 0.00613, 0.07832, 0.04040, 110.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.00564, 0.00564, 0.07509, 0.03998, 73.52%
Time spent: 16.68s
Batch 0 Train - Loss (one batch): 0.00394
Batch 10 Train - Loss (one batch): 0.00601
Batch 20 Train - Loss (one batch): 0.00853
Batch 30 Train - Loss (one batch): 0.00617
Batch 40 Train - Loss (one batch): 0.00403
Batch 50 Train - Loss (one batch): 0.00349
Batch 60 Train - Loss (one batch): 0.00265
Batch 70 Train - Loss (one batch): 0.00308
Batch 80 Train - Loss (one batch): 0.00505
Batch 90 Train - Loss (one batch): 0.00363
Batch 100 Train - Loss (one batch): 0.00437
Batch 110 Train - Loss (one batch): 0.00468
Batch 120 Train - Loss (one batch): 0.00437
Batch 130 Train - Loss (one batch): 0.00431
Batch 140 Train - Loss (one batch): 0.00377
Batch 150 Train - Loss (one batch): 0.00451
Batch 160 Train - Loss (one batch): 0.00425
Batch 170 Train - Loss (one batch): 0.00417
Batch 180 Train - Loss (one batch): 0.01262
Batch 190 Train - Loss (one batch): 0.00385
Batch 200 Train - Loss (one batch): 0.00338
Batch 210 Train - Loss (one batch): 0.00449
Batch 220 Train - Loss (one batch): 0.00393
- Epoch 016, ExpID 70285
Train - Loss (one batch): 0.00467
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00577, 0.00577, 0.07597, 0.03806, 81.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.00536, 0.00536, 0.07319, 0.03770, 78.16%
Time spent: 19.52s
Batch 0 Train - Loss (one batch): 0.00408
Batch 10 Train - Loss (one batch): 0.00462
Batch 20 Train - Loss (one batch): 0.00795
Batch 30 Train - Loss (one batch): 0.00363
Batch 40 Train - Loss (one batch): 0.00271
Batch 50 Train - Loss (one batch): 0.00375
Batch 60 Train - Loss (one batch): 0.00486
Batch 70 Train - Loss (one batch): 0.00392
Batch 80 Train - Loss (one batch): 0.00475
Batch 90 Train - Loss (one batch): 0.00438
Batch 100 Train - Loss (one batch): 0.00400
Batch 110 Train - Loss (one batch): 0.00305
Batch 120 Train - Loss (one batch): 0.00429
Batch 130 Train - Loss (one batch): 0.00283
Batch 140 Train - Loss (one batch): 0.00331
Batch 150 Train - Loss (one batch): 0.00450
Batch 160 Train - Loss (one batch): 0.00447
Batch 170 Train - Loss (one batch): 0.00580
Batch 180 Train - Loss (one batch): 0.00383
Batch 190 Train - Loss (one batch): 0.00493
Batch 200 Train - Loss (one batch): 0.00482
Batch 210 Train - Loss (one batch): 0.00297
Batch 220 Train - Loss (one batch): 0.00417
- Epoch 017, ExpID 70285
Train - Loss (one batch): 0.00512
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00631, 0.00631, 0.07946, 0.04332, 75.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.00536, 0.00536, 0.07319, 0.03770, 78.16%
Time spent: 17.64s
Batch 0 Train - Loss (one batch): 0.00305
Batch 10 Train - Loss (one batch): 0.00362
Batch 20 Train - Loss (one batch): 0.00523
Batch 30 Train - Loss (one batch): 0.00465
Batch 40 Train - Loss (one batch): 0.00448
Batch 50 Train - Loss (one batch): 0.00476
Batch 60 Train - Loss (one batch): 0.00337
Batch 70 Train - Loss (one batch): 0.00452
Batch 80 Train - Loss (one batch): 0.00396
Batch 90 Train - Loss (one batch): 0.00392
Batch 100 Train - Loss (one batch): 0.00511
Batch 110 Train - Loss (one batch): 0.00363
Batch 120 Train - Loss (one batch): 0.00361
Batch 130 Train - Loss (one batch): 0.00536
Batch 140 Train - Loss (one batch): 0.00309
Batch 150 Train - Loss (one batch): 0.00412
Batch 160 Train - Loss (one batch): 0.00339
Batch 170 Train - Loss (one batch): 0.00427
Batch 180 Train - Loss (one batch): 0.00341
Batch 190 Train - Loss (one batch): 0.00530
Batch 200 Train - Loss (one batch): 0.00329
Batch 210 Train - Loss (one batch): 0.00482
Batch 220 Train - Loss (one batch): 0.00432
- Epoch 018, ExpID 70285
Train - Loss (one batch): 0.00565
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00652, 0.00652, 0.08075, 0.04427, 70.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.00536, 0.00536, 0.07319, 0.03770, 78.16%
Time spent: 17.56s
Batch 0 Train - Loss (one batch): 0.00728
Batch 10 Train - Loss (one batch): 0.00528
Batch 20 Train - Loss (one batch): 0.00403
Batch 30 Train - Loss (one batch): 0.00375
Batch 40 Train - Loss (one batch): 0.00361
Batch 50 Train - Loss (one batch): 0.00288
Batch 60 Train - Loss (one batch): 0.00477
Batch 70 Train - Loss (one batch): 0.00470
Batch 80 Train - Loss (one batch): 0.00342
Batch 90 Train - Loss (one batch): 0.00492
Batch 100 Train - Loss (one batch): 0.00564
Batch 110 Train - Loss (one batch): 0.00386
Batch 120 Train - Loss (one batch): 0.00459
Batch 130 Train - Loss (one batch): 0.00296
Batch 140 Train - Loss (one batch): 0.00426
Batch 150 Train - Loss (one batch): 0.00642
Batch 160 Train - Loss (one batch): 0.00501
Batch 170 Train - Loss (one batch): 0.00547
Batch 180 Train - Loss (one batch): 0.00309
Batch 190 Train - Loss (one batch): 0.00500
Batch 200 Train - Loss (one batch): 0.00413
Batch 210 Train - Loss (one batch): 0.00467
Batch 220 Train - Loss (one batch): 0.00408
- Epoch 019, ExpID 70285
Train - Loss (one batch): 0.00407
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00634, 0.00634, 0.07962, 0.04231, 119.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.00536, 0.00536, 0.07319, 0.03770, 78.16%
Time spent: 16.63s
Batch 0 Train - Loss (one batch): 0.00387
Batch 10 Train - Loss (one batch): 0.00458
Batch 20 Train - Loss (one batch): 0.00444
Batch 30 Train - Loss (one batch): 0.00563
Batch 40 Train - Loss (one batch): 0.00550
Batch 50 Train - Loss (one batch): 0.00441
Batch 60 Train - Loss (one batch): 0.00464
Batch 70 Train - Loss (one batch): 0.00405
Batch 80 Train - Loss (one batch): 0.00415
Batch 90 Train - Loss (one batch): 0.00546
Batch 100 Train - Loss (one batch): 0.00503
Batch 110 Train - Loss (one batch): 0.00924
Batch 120 Train - Loss (one batch): 0.00436
Batch 130 Train - Loss (one batch): 0.00377
Batch 140 Train - Loss (one batch): 0.00358
Batch 150 Train - Loss (one batch): 0.00549
Batch 160 Train - Loss (one batch): 0.00463
Batch 170 Train - Loss (one batch): 0.00339
Batch 180 Train - Loss (one batch): 0.00621
Batch 190 Train - Loss (one batch): 0.00425
Batch 200 Train - Loss (one batch): 0.00456
Batch 210 Train - Loss (one batch): 0.00413
Batch 220 Train - Loss (one batch): 0.00301
- Epoch 020, ExpID 70285
Train - Loss (one batch): 0.00489
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00576, 0.00576, 0.07591, 0.03751, 80.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 19.00s
Batch 0 Train - Loss (one batch): 0.00418
Batch 10 Train - Loss (one batch): 0.00554
Batch 20 Train - Loss (one batch): 0.00445
Batch 30 Train - Loss (one batch): 0.00289
Batch 40 Train - Loss (one batch): 0.00420
Batch 50 Train - Loss (one batch): 0.00379
Batch 60 Train - Loss (one batch): 0.00523
Batch 70 Train - Loss (one batch): 0.00431
Batch 80 Train - Loss (one batch): 0.00372
Batch 90 Train - Loss (one batch): 0.00524
Batch 100 Train - Loss (one batch): 0.00427
Batch 110 Train - Loss (one batch): 0.00361
Batch 120 Train - Loss (one batch): 0.00540
Batch 130 Train - Loss (one batch): 0.00425
Batch 140 Train - Loss (one batch): 0.00237
Batch 150 Train - Loss (one batch): 0.00458
Batch 160 Train - Loss (one batch): 0.00311
Batch 170 Train - Loss (one batch): 0.00392
Batch 180 Train - Loss (one batch): 0.00411
Batch 190 Train - Loss (one batch): 0.00483
Batch 200 Train - Loss (one batch): 0.00446
Batch 210 Train - Loss (one batch): 0.00583
Batch 220 Train - Loss (one batch): 0.00305
- Epoch 021, ExpID 70285
Train - Loss (one batch): 0.00632
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00597, 0.00597, 0.07724, 0.03908, 92.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.61s
Batch 0 Train - Loss (one batch): 0.00443
Batch 10 Train - Loss (one batch): 0.00599
Batch 20 Train - Loss (one batch): 0.00515
Batch 30 Train - Loss (one batch): 0.00555
Batch 40 Train - Loss (one batch): 0.00398
Batch 50 Train - Loss (one batch): 0.00455
Batch 60 Train - Loss (one batch): 0.00319
Batch 70 Train - Loss (one batch): 0.00362
Batch 80 Train - Loss (one batch): 0.00475
Batch 90 Train - Loss (one batch): 0.00357
Batch 100 Train - Loss (one batch): 0.00476
Batch 110 Train - Loss (one batch): 0.00463
Batch 120 Train - Loss (one batch): 0.00502
Batch 130 Train - Loss (one batch): 0.00417
Batch 140 Train - Loss (one batch): 0.00349
Batch 150 Train - Loss (one batch): 0.00424
Batch 160 Train - Loss (one batch): 0.00380
Batch 170 Train - Loss (one batch): 0.00386
Batch 180 Train - Loss (one batch): 0.00363
Batch 190 Train - Loss (one batch): 0.00504
Batch 200 Train - Loss (one batch): 0.00451
Batch 210 Train - Loss (one batch): 0.00635
Batch 220 Train - Loss (one batch): 0.00435
- Epoch 022, ExpID 70285
Train - Loss (one batch): 0.00514
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00638, 0.00638, 0.07986, 0.04139, 74.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.54s
Batch 0 Train - Loss (one batch): 0.00406
Batch 10 Train - Loss (one batch): 0.00481
Batch 20 Train - Loss (one batch): 0.00460
Batch 30 Train - Loss (one batch): 0.00376
Batch 40 Train - Loss (one batch): 0.00320
Batch 50 Train - Loss (one batch): 0.00476
Batch 60 Train - Loss (one batch): 0.00335
Batch 70 Train - Loss (one batch): 0.00419
Batch 80 Train - Loss (one batch): 0.00355
Batch 90 Train - Loss (one batch): 0.00520
Batch 100 Train - Loss (one batch): 0.00332
Batch 110 Train - Loss (one batch): 0.00452
Batch 120 Train - Loss (one batch): 0.00343
Batch 130 Train - Loss (one batch): 0.00448
Batch 140 Train - Loss (one batch): 0.00315
Batch 150 Train - Loss (one batch): 0.00486
Batch 160 Train - Loss (one batch): 0.00392
Batch 170 Train - Loss (one batch): 0.00495
Batch 180 Train - Loss (one batch): 0.00535
Batch 190 Train - Loss (one batch): 0.00370
Batch 200 Train - Loss (one batch): 0.00512
Batch 210 Train - Loss (one batch): 0.00456
Batch 220 Train - Loss (one batch): 0.00334
- Epoch 023, ExpID 70285
Train - Loss (one batch): 0.00318
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00591, 0.00591, 0.07691, 0.03891, 103.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.58s
Batch 0 Train - Loss (one batch): 0.00298
Batch 10 Train - Loss (one batch): 0.00609
Batch 20 Train - Loss (one batch): 0.00347
Batch 30 Train - Loss (one batch): 0.00447
Batch 40 Train - Loss (one batch): 0.00282
Batch 50 Train - Loss (one batch): 0.00517
Batch 60 Train - Loss (one batch): 0.00413
Batch 70 Train - Loss (one batch): 0.00433
Batch 80 Train - Loss (one batch): 0.00456
Batch 90 Train - Loss (one batch): 0.00732
Batch 100 Train - Loss (one batch): 0.00450
Batch 110 Train - Loss (one batch): 0.00422
Batch 120 Train - Loss (one batch): 0.00549
Batch 130 Train - Loss (one batch): 0.00484
Batch 140 Train - Loss (one batch): 0.00394
Batch 150 Train - Loss (one batch): 0.00503
Batch 160 Train - Loss (one batch): 0.00413
Batch 170 Train - Loss (one batch): 0.00368
Batch 180 Train - Loss (one batch): 0.00408
Batch 190 Train - Loss (one batch): 0.00890
Batch 200 Train - Loss (one batch): 0.00455
Batch 210 Train - Loss (one batch): 0.00430
Batch 220 Train - Loss (one batch): 0.00504
- Epoch 024, ExpID 70285
Train - Loss (one batch): 0.00860
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00629, 0.00629, 0.07931, 0.04288, 102.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.60s
Batch 0 Train - Loss (one batch): 0.00484
Batch 10 Train - Loss (one batch): 0.00377
Batch 20 Train - Loss (one batch): 0.00470
Batch 30 Train - Loss (one batch): 0.00355
Batch 40 Train - Loss (one batch): 0.00576
Batch 50 Train - Loss (one batch): 0.00505
Batch 60 Train - Loss (one batch): 0.00568
Batch 70 Train - Loss (one batch): 0.00484
Batch 80 Train - Loss (one batch): 0.00593
Batch 90 Train - Loss (one batch): 0.00464
Batch 100 Train - Loss (one batch): 0.00466
Batch 110 Train - Loss (one batch): 0.00480
Batch 120 Train - Loss (one batch): 0.00480
Batch 130 Train - Loss (one batch): 0.00351
Batch 140 Train - Loss (one batch): 0.00427
Batch 150 Train - Loss (one batch): 0.00440
Batch 160 Train - Loss (one batch): 0.00380
Batch 170 Train - Loss (one batch): 0.00324
Batch 180 Train - Loss (one batch): 0.00332
Batch 190 Train - Loss (one batch): 0.00529
Batch 200 Train - Loss (one batch): 0.00405
Batch 210 Train - Loss (one batch): 0.00648
Batch 220 Train - Loss (one batch): 0.00302
- Epoch 025, ExpID 70285
Train - Loss (one batch): 0.00390
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00605, 0.00605, 0.07778, 0.04099, 108.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.60s
Batch 0 Train - Loss (one batch): 0.00785
Batch 10 Train - Loss (one batch): 0.00369
Batch 20 Train - Loss (one batch): 0.00416
Batch 30 Train - Loss (one batch): 0.00341
Batch 40 Train - Loss (one batch): 0.00479
Batch 50 Train - Loss (one batch): 0.00521
Batch 60 Train - Loss (one batch): 0.00312
Batch 70 Train - Loss (one batch): 0.00468
Batch 80 Train - Loss (one batch): 0.00365
Batch 90 Train - Loss (one batch): 0.00368
Batch 100 Train - Loss (one batch): 0.01128
Batch 110 Train - Loss (one batch): 0.00353
Batch 120 Train - Loss (one batch): 0.00433
Batch 130 Train - Loss (one batch): 0.00529
Batch 140 Train - Loss (one batch): 0.00292
Batch 150 Train - Loss (one batch): 0.00681
Batch 160 Train - Loss (one batch): 0.00317
Batch 170 Train - Loss (one batch): 0.00349
Batch 180 Train - Loss (one batch): 0.00481
Batch 190 Train - Loss (one batch): 0.00650
Batch 200 Train - Loss (one batch): 0.00343
Batch 210 Train - Loss (one batch): 0.00535
Batch 220 Train - Loss (one batch): 0.00566
- Epoch 026, ExpID 70285
Train - Loss (one batch): 0.00407
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00596, 0.00596, 0.07720, 0.04035, 133.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.85s
Batch 0 Train - Loss (one batch): 0.00482
Batch 10 Train - Loss (one batch): 0.00225
Batch 20 Train - Loss (one batch): 0.00341
Batch 30 Train - Loss (one batch): 0.00387
Batch 40 Train - Loss (one batch): 0.00536
Batch 50 Train - Loss (one batch): 0.00457
Batch 60 Train - Loss (one batch): 0.00456
Batch 70 Train - Loss (one batch): 0.00572
Batch 80 Train - Loss (one batch): 0.00478
Batch 90 Train - Loss (one batch): 0.00264
Batch 100 Train - Loss (one batch): 0.00415
Batch 110 Train - Loss (one batch): 0.00375
Batch 120 Train - Loss (one batch): 0.00440
Batch 130 Train - Loss (one batch): 0.00493
Batch 140 Train - Loss (one batch): 0.00467
Batch 150 Train - Loss (one batch): 0.00339
Batch 160 Train - Loss (one batch): 0.00408
Batch 170 Train - Loss (one batch): 0.00473
Batch 180 Train - Loss (one batch): 0.00320
Batch 190 Train - Loss (one batch): 0.00349
Batch 200 Train - Loss (one batch): 0.00596
Batch 210 Train - Loss (one batch): 0.00570
Batch 220 Train - Loss (one batch): 0.00372
- Epoch 027, ExpID 70285
Train - Loss (one batch): 0.00417
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00597, 0.00597, 0.07729, 0.03920, 103.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 17.44s
Batch 0 Train - Loss (one batch): 0.00376
Batch 10 Train - Loss (one batch): 0.00383
Batch 20 Train - Loss (one batch): 0.00467
Batch 30 Train - Loss (one batch): 0.00487
Batch 40 Train - Loss (one batch): 0.00384
Batch 50 Train - Loss (one batch): 0.00400
Batch 60 Train - Loss (one batch): 0.00395
Batch 70 Train - Loss (one batch): 0.00427
Batch 80 Train - Loss (one batch): 0.00577
Batch 90 Train - Loss (one batch): 0.00535
Batch 100 Train - Loss (one batch): 0.00487
Batch 110 Train - Loss (one batch): 0.00441
Batch 120 Train - Loss (one batch): 0.00332
Batch 130 Train - Loss (one batch): 0.00570
Batch 140 Train - Loss (one batch): 0.00594
Batch 150 Train - Loss (one batch): 0.00275
Batch 160 Train - Loss (one batch): 0.00535
Batch 170 Train - Loss (one batch): 0.00443
Batch 180 Train - Loss (one batch): 0.00259
Batch 190 Train - Loss (one batch): 0.00501
Batch 200 Train - Loss (one batch): 0.00505
Batch 210 Train - Loss (one batch): 0.00321
Batch 220 Train - Loss (one batch): 0.00410
- Epoch 028, ExpID 70285
Train - Loss (one batch): 0.00367
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00578, 0.00578, 0.07600, 0.03898, 61.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 17.48s
Batch 0 Train - Loss (one batch): 0.00656
Batch 10 Train - Loss (one batch): 0.00460
Batch 20 Train - Loss (one batch): 0.00431
Batch 30 Train - Loss (one batch): 0.00475
Batch 40 Train - Loss (one batch): 0.00517
Batch 50 Train - Loss (one batch): 0.00397
Batch 60 Train - Loss (one batch): 0.00335
Batch 70 Train - Loss (one batch): 0.00390
Batch 80 Train - Loss (one batch): 0.00416
Batch 90 Train - Loss (one batch): 0.00541
Batch 100 Train - Loss (one batch): 0.00341
Batch 110 Train - Loss (one batch): 0.00676
Batch 120 Train - Loss (one batch): 0.00409
Batch 130 Train - Loss (one batch): 0.00515
Batch 140 Train - Loss (one batch): 0.00373
Batch 150 Train - Loss (one batch): 0.00539
Batch 160 Train - Loss (one batch): 0.00538
Batch 170 Train - Loss (one batch): 0.00462
Batch 180 Train - Loss (one batch): 0.00510
Batch 190 Train - Loss (one batch): 0.00323
Batch 200 Train - Loss (one batch): 0.00466
Batch 210 Train - Loss (one batch): 0.00665
Batch 220 Train - Loss (one batch): 0.00297
- Epoch 029, ExpID 70285
Train - Loss (one batch): 0.00384
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00597, 0.00597, 0.07726, 0.04035, 84.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 17.52s
Batch 0 Train - Loss (one batch): 0.00524
Batch 10 Train - Loss (one batch): 0.00381
Batch 20 Train - Loss (one batch): 0.00341
Batch 30 Train - Loss (one batch): 0.00399
Batch 40 Train - Loss (one batch): 0.00299
Batch 50 Train - Loss (one batch): 0.00424
Batch 60 Train - Loss (one batch): 0.00388
Batch 70 Train - Loss (one batch): 0.00324
Batch 80 Train - Loss (one batch): 0.00325
Batch 90 Train - Loss (one batch): 0.00393
Batch 100 Train - Loss (one batch): 0.00621
Batch 110 Train - Loss (one batch): 0.00466
Batch 120 Train - Loss (one batch): 0.00587
Batch 130 Train - Loss (one batch): 0.00351
Batch 140 Train - Loss (one batch): 0.00464
Batch 150 Train - Loss (one batch): 0.00377
Batch 160 Train - Loss (one batch): 0.00453
Batch 170 Train - Loss (one batch): 0.00382
Batch 180 Train - Loss (one batch): 0.00511
Batch 190 Train - Loss (one batch): 0.01192
Batch 200 Train - Loss (one batch): 0.00476
Batch 210 Train - Loss (one batch): 0.00606
Batch 220 Train - Loss (one batch): 0.00432
- Epoch 030, ExpID 70285
Train - Loss (one batch): 0.00292
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00584, 0.00584, 0.07641, 0.03837, 58.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 17.31s
PID, device: 26708 cuda
Total records: 12000
Dataset n_samples: 12000 7200 2400 2400
Test record ids (first 20): ['137448', '148956', '136914', '155610', '133454', '156996', '145930', '154208', '138164', '144190', '141346', '136111', '133728', '135488', '145796', '153197', '133620', '150418', '138790', '137164']
Test record ids (last 20): ['152600', '137920', '145610', '144568', '134835', '143983', '133814', '156786', '145996', '162595', '149943', '135568', '150737', '143403', '151976', '135534', '162703', '146267', '142320', '143686']
data_max: tensor([9.0000e+01, 1.0000e+00, 4.6230e+02, 4.0000e+00, 4.7200e+02, 5.3000e+00,
        4.6950e+03, 1.6920e+04, 3.6400e+04, 8.2800e+01, 2.0900e+02, 3.6200e+02,
        2.2100e+01, 2.8300e+02, 1.0000e+00, 1.5000e+01, 1.5910e+03, 5.2000e+01,
        6.1200e+01, 3.0000e+02, 2.2900e+01, 3.1000e+01, 2.9000e+01, 2.9900e+02,
        1.0000e+00, 1.8000e+02, 2.1100e+02, 2.1800e+02, 3.0000e+02, 1.0000e+02,
        5.0000e+02, 7.3500e+02, 2.2920e+03, 1.0000e+02, 1.0000e+02, 2.9500e+02,
        4.2100e+01, 4.9600e+01, 2.9910e+01, 1.0245e+04, 6.2519e+03],
       device='cuda:0')
data_min: tensor([ 1.5000e+01, -1.0000e+00, -1.0000e+00,  1.0000e+00, -1.0000e+00,
         1.0000e+00,  1.1000e+01,  1.0000e+00,  5.0000e+00,  0.0000e+00,
         0.0000e+00,  2.8000e+01,  1.0000e-01, -1.0000e+00,  2.1000e-01,
         3.0000e+00,  8.0000e+00,  5.0000e+00,  5.0000e+00,  0.0000e+00,
         1.8000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,
         9.8000e+01, -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  4.0000e-01,  5.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -1.7800e+01,  1.0000e-01,  1.0000e-02,  0.0000e+00,
         0.0000e+00], device='cuda:0')
time_max: tensor(48., device='cuda:0')
n_train_batches: 225
Exp has been early stopped!
