/home/zepenghu/literature_project/t-PatchGNN/tPatchGNN/run_models.py
2024-09-16 11:57:10
run_models.py --dataset physionet --state def --history 24 --patience 10 --batch_size 32 --lr 1e-3 --patch_size 8 --stride 8 --nhead 1 --tf_layer 1 --nlayer 1 --te_dim 10 --node_dim 10 --hid_dim 64 --outlayer Linear --seed 1 --gpu 0
Namespace(state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=1, epoch=1000, patience=10, history=24, patch_size=8.0, stride=8.0, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='tPatchGNN', outlayer='Linear', hid_dim=64, te_dim=10, node_dim=10, gpu='0', npatch=3, device=device(type='cuda'), PID=99679, ndim=41)
Batch 0 Train - Loss (one batch): 0.18708
- Epoch 000, ExpID 27860
Train - Loss (one batch): 0.00823
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01012, 0.01012, 0.10060, 0.05976, 398.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.00898, 0.00898, 0.09477, 0.05823, 406.16%
Time spent: 30.70s
Batch 0 Train - Loss (one batch): 0.00946
- Epoch 001, ExpID 27860
Train - Loss (one batch): 0.00530
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00813, 0.00813, 0.09015, 0.05028, 106.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.00713, 0.00713, 0.08442, 0.04896, 105.96%
Time spent: 18.31s
Batch 0 Train - Loss (one batch): 0.00531
- Epoch 002, ExpID 27860
Train - Loss (one batch): 0.00421
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00722, 0.00722, 0.08498, 0.04360, 74.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.00623, 0.00623, 0.07896, 0.04224, 76.61%
Time spent: 18.48s
Batch 0 Train - Loss (one batch): 0.00489
- Epoch 003, ExpID 27860
Train - Loss (one batch): 0.00568
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00838, 0.00838, 0.09152, 0.04835, 126.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.00623, 0.00623, 0.07896, 0.04224, 76.61%
Time spent: 16.20s
Batch 0 Train - Loss (one batch): 0.00476
- Epoch 004, ExpID 27860
Train - Loss (one batch): 0.00444
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00744, 0.00744, 0.08626, 0.04863, 113.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.00623, 0.00623, 0.07896, 0.04224, 76.61%
Time spent: 16.73s
Batch 0 Train - Loss (one batch): 0.00388
- Epoch 005, ExpID 27860
Train - Loss (one batch): 0.00461
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00681, 0.00681, 0.08254, 0.04189, 61.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.00573, 0.00573, 0.07573, 0.04004, 63.62%
Time spent: 19.16s
Batch 0 Train - Loss (one batch): 0.00550
- Epoch 006, ExpID 27860
Train - Loss (one batch): 0.00812
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00710, 0.00710, 0.08425, 0.04300, 108.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.00573, 0.00573, 0.07573, 0.04004, 63.62%
Time spent: 16.45s
Batch 0 Train - Loss (one batch): 0.00309
- Epoch 007, ExpID 27860
Train - Loss (one batch): 0.00404
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00708, 0.00708, 0.08416, 0.04391, 103.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.00573, 0.00573, 0.07573, 0.04004, 63.62%
Time spent: 16.53s
Batch 0 Train - Loss (one batch): 0.00515
- Epoch 008, ExpID 27860
Train - Loss (one batch): 0.00484
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00693, 0.00693, 0.08323, 0.04203, 65.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.00573, 0.00573, 0.07573, 0.04004, 63.62%
Time spent: 16.39s
Batch 0 Train - Loss (one batch): 0.00413
- Epoch 009, ExpID 27860
Train - Loss (one batch): 0.00489
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00665, 0.00665, 0.08157, 0.04167, 94.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.00553, 0.00553, 0.07439, 0.03986, 96.77%
Time spent: 19.02s
Batch 0 Train - Loss (one batch): 0.00395
- Epoch 010, ExpID 27860
Train - Loss (one batch): 0.00423
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00691, 0.00691, 0.08315, 0.04244, 81.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.00553, 0.00553, 0.07439, 0.03986, 96.77%
Time spent: 16.48s
Batch 0 Train - Loss (one batch): 0.00453
- Epoch 011, ExpID 27860
Train - Loss (one batch): 0.00578
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00697, 0.00697, 0.08346, 0.04332, 57.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.00553, 0.00553, 0.07439, 0.03986, 96.77%
Time spent: 16.42s
Batch 0 Train - Loss (one batch): 0.00388
- Epoch 012, ExpID 27860
Train - Loss (one batch): 0.00317
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00720, 0.00720, 0.08485, 0.04533, 140.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.00553, 0.00553, 0.07439, 0.03986, 96.77%
Time spent: 16.43s
Batch 0 Train - Loss (one batch): 0.00474
- Epoch 013, ExpID 27860
Train - Loss (one batch): 0.00376
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00688, 0.00688, 0.08295, 0.04170, 88.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.00553, 0.00553, 0.07439, 0.03986, 96.77%
Time spent: 16.38s
Batch 0 Train - Loss (one batch): 0.00720
- Epoch 014, ExpID 27860
Train - Loss (one batch): 0.00270
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00674, 0.00674, 0.08208, 0.04053, 60.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.00553, 0.00553, 0.07439, 0.03986, 96.77%
Time spent: 16.53s
Batch 0 Train - Loss (one batch): 0.00290
- Epoch 015, ExpID 27860
Train - Loss (one batch): 0.00308
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00639, 0.00639, 0.07992, 0.04126, 108.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00542, 0.00542, 0.07363, 0.03932, 113.93%
Time spent: 20.14s
Batch 0 Train - Loss (one batch): 0.00378
- Epoch 016, ExpID 27860
Train - Loss (one batch): 0.00395
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00675, 0.00675, 0.08214, 0.04291, 108.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00542, 0.00542, 0.07363, 0.03932, 113.93%
Time spent: 17.36s
Batch 0 Train - Loss (one batch): 0.00435
- Epoch 017, ExpID 27860
Train - Loss (one batch): 0.00222
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00636, 0.00636, 0.07976, 0.03896, 80.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.00538, 0.00538, 0.07334, 0.03717, 87.14%
Time spent: 19.88s
Batch 0 Train - Loss (one batch): 0.00366
- Epoch 018, ExpID 27860
Train - Loss (one batch): 0.00992
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00660, 0.00660, 0.08123, 0.04411, 117.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.00538, 0.00538, 0.07334, 0.03717, 87.14%
Time spent: 16.41s
Batch 0 Train - Loss (one batch): 0.00305
- Epoch 019, ExpID 27860
Train - Loss (one batch): 0.00530
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00692, 0.00692, 0.08316, 0.04446, 134.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.00538, 0.00538, 0.07334, 0.03717, 87.14%
Time spent: 16.32s
Batch 0 Train - Loss (one batch): 0.00606
- Epoch 020, ExpID 27860
Train - Loss (one batch): 0.00314
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00656, 0.00656, 0.08102, 0.03995, 74.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.00538, 0.00538, 0.07334, 0.03717, 87.14%
Time spent: 16.41s
Batch 0 Train - Loss (one batch): 0.00457
- Epoch 021, ExpID 27860
Train - Loss (one batch): 0.00385
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00630, 0.00630, 0.07940, 0.03856, 66.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.00528, 0.00528, 0.07268, 0.03675, 71.88%
Time spent: 18.88s
Batch 0 Train - Loss (one batch): 0.00293
- Epoch 022, ExpID 27860
Train - Loss (one batch): 0.00438
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00639, 0.00639, 0.07996, 0.03980, 72.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.00528, 0.00528, 0.07268, 0.03675, 71.88%
Time spent: 16.45s
Batch 0 Train - Loss (one batch): 0.00343
- Epoch 023, ExpID 27860
Train - Loss (one batch): 0.00336
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00643, 0.00643, 0.08020, 0.03915, 65.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.00528, 0.00528, 0.07268, 0.03675, 71.88%
Time spent: 16.44s
Batch 0 Train - Loss (one batch): 0.00487
- Epoch 024, ExpID 27860
Train - Loss (one batch): 0.00639
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00637, 0.00637, 0.07983, 0.04251, 155.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.00528, 0.00528, 0.07268, 0.03675, 71.88%
Time spent: 16.53s
Batch 0 Train - Loss (one batch): 0.00378
- Epoch 025, ExpID 27860
Train - Loss (one batch): 0.00509
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00692, 0.00692, 0.08317, 0.04370, 78.10%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.00528, 0.00528, 0.07268, 0.03675, 71.88%
Time spent: 16.47s
Batch 0 Train - Loss (one batch): 0.00353
- Epoch 026, ExpID 27860
Train - Loss (one batch): 0.00339
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00645, 0.00645, 0.08029, 0.04001, 78.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.00528, 0.00528, 0.07268, 0.03675, 71.88%
Time spent: 16.57s
Batch 0 Train - Loss (one batch): 0.00333
- Epoch 027, ExpID 27860
Train - Loss (one batch): 0.00443
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00662, 0.00662, 0.08138, 0.04039, 84.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.00528, 0.00528, 0.07268, 0.03675, 71.88%
Time spent: 17.00s
Batch 0 Train - Loss (one batch): 0.00421
- Epoch 028, ExpID 27860
Train - Loss (one batch): 0.00425
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00654, 0.00654, 0.08086, 0.04057, 95.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.00528, 0.00528, 0.07268, 0.03675, 71.88%
Time spent: 17.36s
Batch 0 Train - Loss (one batch): 0.00454
- Epoch 029, ExpID 27860
Train - Loss (one batch): 0.00466
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00664, 0.00664, 0.08149, 0.04167, 118.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.00528, 0.00528, 0.07268, 0.03675, 71.88%
Time spent: 17.36s
Batch 0 Train - Loss (one batch): 0.00430
- Epoch 030, ExpID 27860
Train - Loss (one batch): 0.00467
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00651, 0.00651, 0.08070, 0.04096, 96.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.00528, 0.00528, 0.07268, 0.03675, 71.88%
Time spent: 17.32s
Batch 0 Train - Loss (one batch): 0.00394
- Epoch 031, ExpID 27860
Train - Loss (one batch): 0.00312
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00640, 0.00640, 0.07999, 0.04180, 123.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.00528, 0.00528, 0.07268, 0.03675, 71.88%
Time spent: 17.32s
PID, device: 99679 cuda
Experiment ID: 27860
Total records: 12000
Dataset n_samples: 12000 7200 2400 2400
Test record ids (first 20): ['156821', '156822', '156823', '156824', '156826', '156829', '156830', '156834', '156835', '156843', '156845', '156846', '156847', '156849', '156853', '156854', '156857', '156859', '156864', '156865']
Test record ids (last 20): ['162989', '162990', '162991', '162995', '162996', '162999', '163002', '163003', '163007', '163008', '163013', '163016', '163017', '163021', '163027', '163029', '163033', '163034', '163035', '163037']
data_max: tensor([9.0000e+01, 1.0000e+00, 4.6230e+02, 4.0000e+00, 4.7200e+02, 5.3000e+00,
        4.1060e+03, 1.6920e+04, 3.6400e+04, 5.9400e+01, 2.0900e+02, 3.6000e+02,
        2.2100e+01, 2.7200e+02, 1.0000e+00, 1.5000e+01, 1.2890e+03, 5.2000e+01,
        6.1800e+01, 3.0000e+02, 2.2900e+01, 3.1000e+01, 3.7500e+01, 3.0000e+02,
        1.0000e+00, 1.8000e+02, 2.1100e+02, 2.2800e+02, 3.0000e+02, 1.0000e+02,
        5.0000e+02, 7.3500e+02, 2.2920e+03, 1.0000e+02, 1.0000e+02, 2.9500e+02,
        4.2200e+01, 4.9600e+01, 2.4910e+01, 1.1000e+04, 6.2519e+03],
       device='cuda:0')
data_min: tensor([ 1.5000e+01, -1.0000e+00, -1.0000e+00,  1.0000e+00, -1.0000e+00,
         1.0000e+00,  1.2000e+01,  1.0000e+00,  4.0000e+00,  0.0000e+00,
         0.0000e+00,  2.8000e+01,  1.0000e-01, -1.0000e+00,  2.1000e-01,
         3.0000e+00,  8.0000e+00,  5.0000e+00,  5.0000e+00,  0.0000e+00,
         1.8000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,
         9.8000e+01, -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  5.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -1.7800e+01,  1.0000e-01,  1.0000e-02,  0.0000e+00,
         0.0000e+00], device='cuda:0')
time_max: tensor(48., device='cuda:0')
n_train_batches: 225
Exp has been early stopped!
/home/zepenghu/literature_project/t-PatchGNN/tPatchGNN/run_models.py
2024-09-16 12:07:45
run_models.py --dataset physionet --state def --history 24 --patience 10 --batch_size 32 --lr 1e-3 --patch_size 8 --stride 8 --nhead 1 --tf_layer 1 --nlayer 1 --te_dim 10 --node_dim 10 --hid_dim 64 --outlayer Linear --seed 2 --gpu 0
Namespace(state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=1, epoch=1000, patience=10, history=24, patch_size=8.0, stride=8.0, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, save='experiments/', load=None, seed=2, dataset='physionet', quantization=0.0, model='tPatchGNN', outlayer='Linear', hid_dim=64, te_dim=10, node_dim=10, gpu='0', npatch=3, device=device(type='cuda'), PID=100002, ndim=41)
Batch 0 Train - Loss (one batch): 0.07136
- Epoch 000, ExpID 60335
Train - Loss (one batch): 0.00616
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00932, 0.00932, 0.09655, 0.05234, 105.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.00876, 0.00876, 0.09361, 0.05221, 110.84%
Time spent: 21.72s
Batch 0 Train - Loss (one batch): 0.01089
- Epoch 001, ExpID 60335
Train - Loss (one batch): 0.00603
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00715, 0.00715, 0.08458, 0.04616, 138.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.00665, 0.00665, 0.08153, 0.04561, 141.49%
Time spent: 20.08s
Batch 0 Train - Loss (one batch): 0.00576
- Epoch 002, ExpID 60335
Train - Loss (one batch): 0.00638
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00666, 0.00666, 0.08163, 0.04408, 94.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.00633, 0.00633, 0.07959, 0.04382, 96.67%
Time spent: 19.37s
Batch 0 Train - Loss (one batch): 0.00670
- Epoch 003, ExpID 60335
Train - Loss (one batch): 0.00524
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00630, 0.00630, 0.07939, 0.04333, 233.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.00590, 0.00590, 0.07679, 0.04311, 241.58%
Time spent: 18.91s
Batch 0 Train - Loss (one batch): 0.00456
- Epoch 004, ExpID 60335
Train - Loss (one batch): 0.00444
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00600, 0.00600, 0.07749, 0.03947, 90.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00567, 0.00567, 0.07531, 0.03926, 87.16%
Time spent: 18.86s
Batch 0 Train - Loss (one batch): 0.00528
- Epoch 005, ExpID 60335
Train - Loss (one batch): 0.00743
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00633, 0.00633, 0.07958, 0.04156, 91.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00567, 0.00567, 0.07531, 0.03926, 87.16%
Time spent: 16.48s
Batch 0 Train - Loss (one batch): 0.00550
- Epoch 006, ExpID 60335
Train - Loss (one batch): 0.00502
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00606, 0.00606, 0.07783, 0.04285, 211.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00567, 0.00567, 0.07531, 0.03926, 87.16%
Time spent: 16.47s
Batch 0 Train - Loss (one batch): 0.00476
- Epoch 007, ExpID 60335
Train - Loss (one batch): 0.00440
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00605, 0.00605, 0.07777, 0.03970, 82.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00567, 0.00567, 0.07531, 0.03926, 87.16%
Time spent: 16.45s
Batch 0 Train - Loss (one batch): 0.00614
- Epoch 008, ExpID 60335
Train - Loss (one batch): 0.00410
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00618, 0.00618, 0.07864, 0.03882, 86.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00567, 0.00567, 0.07531, 0.03926, 87.16%
Time spent: 16.37s
Batch 0 Train - Loss (one batch): 0.00337
- Epoch 009, ExpID 60335
Train - Loss (one batch): 0.00661
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00634, 0.00634, 0.07963, 0.04021, 85.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00567, 0.00567, 0.07531, 0.03926, 87.16%
Time spent: 16.40s
Batch 0 Train - Loss (one batch): 0.00348
- Epoch 010, ExpID 60335
Train - Loss (one batch): 0.00452
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00591, 0.00591, 0.07685, 0.03911, 81.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.00547, 0.00547, 0.07399, 0.03894, 78.92%
Time spent: 18.88s
Batch 0 Train - Loss (one batch): 0.00580
- Epoch 011, ExpID 60335
Train - Loss (one batch): 0.00453
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00592, 0.00592, 0.07692, 0.04043, 139.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.00547, 0.00547, 0.07399, 0.03894, 78.92%
Time spent: 16.43s
Batch 0 Train - Loss (one batch): 0.00476
- Epoch 012, ExpID 60335
Train - Loss (one batch): 0.00376
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00623, 0.00623, 0.07893, 0.04055, 104.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.00547, 0.00547, 0.07399, 0.03894, 78.92%
Time spent: 16.54s
Batch 0 Train - Loss (one batch): 0.00348
- Epoch 013, ExpID 60335
Train - Loss (one batch): 0.00573
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00613, 0.00613, 0.07831, 0.04067, 77.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.00547, 0.00547, 0.07399, 0.03894, 78.92%
Time spent: 16.40s
Batch 0 Train - Loss (one batch): 0.00427
- Epoch 014, ExpID 60335
Train - Loss (one batch): 0.00465
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00642, 0.00642, 0.08010, 0.04309, 98.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.00547, 0.00547, 0.07399, 0.03894, 78.92%
Time spent: 16.43s
Batch 0 Train - Loss (one batch): 0.00512
- Epoch 015, ExpID 60335
Train - Loss (one batch): 0.00527
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00577, 0.00577, 0.07594, 0.03719, 71.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 18.94s
Batch 0 Train - Loss (one batch): 0.00377
- Epoch 016, ExpID 60335
Train - Loss (one batch): 0.00601
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00603, 0.00603, 0.07765, 0.03919, 96.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 16.57s
Batch 0 Train - Loss (one batch): 0.00462
- Epoch 017, ExpID 60335
Train - Loss (one batch): 0.00416
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00638, 0.00638, 0.07990, 0.04020, 64.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 16.49s
Batch 0 Train - Loss (one batch): 0.00460
- Epoch 018, ExpID 60335
Train - Loss (one batch): 0.00405
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00614, 0.00614, 0.07838, 0.03965, 84.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 16.52s
Batch 0 Train - Loss (one batch): 0.00379
- Epoch 019, ExpID 60335
Train - Loss (one batch): 0.00533
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00613, 0.00613, 0.07828, 0.04158, 153.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 16.54s
Batch 0 Train - Loss (one batch): 0.00396
- Epoch 020, ExpID 60335
Train - Loss (one batch): 0.00299
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00611, 0.00611, 0.07815, 0.04049, 112.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 16.48s
Batch 0 Train - Loss (one batch): 0.00343
- Epoch 021, ExpID 60335
Train - Loss (one batch): 0.00705
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00603, 0.00603, 0.07765, 0.04382, 133.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 16.55s
Batch 0 Train - Loss (one batch): 0.00625
- Epoch 022, ExpID 60335
Train - Loss (one batch): 0.00452
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00590, 0.00590, 0.07682, 0.03817, 63.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00533, 0.00533, 0.07299, 0.03690, 65.24%
Time spent: 17.17s
Batch 0 Train - Loss (one batch): 0.00470
- Epoch 023, ExpID 60335
Train - Loss (one batch): 0.00245
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00575, 0.00575, 0.07585, 0.03689, 79.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 20.03s
Batch 0 Train - Loss (one batch): 0.00382
- Epoch 024, ExpID 60335
Train - Loss (one batch): 0.00253
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00586, 0.00586, 0.07655, 0.03844, 69.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 17.41s
Batch 0 Train - Loss (one batch): 0.00475
- Epoch 025, ExpID 60335
Train - Loss (one batch): 0.00628
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00598, 0.00598, 0.07731, 0.04212, 127.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 17.30s
Batch 0 Train - Loss (one batch): 0.00497
- Epoch 026, ExpID 60335
Train - Loss (one batch): 0.00438
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00587, 0.00587, 0.07664, 0.03972, 91.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 17.34s
Batch 0 Train - Loss (one batch): 0.00439
- Epoch 027, ExpID 60335
Train - Loss (one batch): 0.00440
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00580, 0.00580, 0.07614, 0.03836, 122.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.72s
Batch 0 Train - Loss (one batch): 0.00486
- Epoch 028, ExpID 60335
Train - Loss (one batch): 0.00453
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00590, 0.00590, 0.07678, 0.03942, 126.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.50s
Batch 0 Train - Loss (one batch): 0.00640
- Epoch 029, ExpID 60335
Train - Loss (one batch): 0.00455
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00582, 0.00582, 0.07626, 0.03833, 97.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.40s
Batch 0 Train - Loss (one batch): 0.00492
- Epoch 030, ExpID 60335
Train - Loss (one batch): 0.00416
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00581, 0.00581, 0.07621, 0.03954, 132.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.48s
Batch 0 Train - Loss (one batch): 0.00484
- Epoch 031, ExpID 60335
Train - Loss (one batch): 0.00325
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00586, 0.00586, 0.07654, 0.03765, 78.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.51s
Batch 0 Train - Loss (one batch): 0.00378
- Epoch 032, ExpID 60335
Train - Loss (one batch): 0.00424
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00605, 0.00605, 0.07775, 0.03884, 81.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.32s
Batch 0 Train - Loss (one batch): 0.00267
- Epoch 033, ExpID 60335
Train - Loss (one batch): 0.00474
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00593, 0.00593, 0.07698, 0.03783, 76.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.00537, 0.00537, 0.07330, 0.03691, 78.67%
Time spent: 16.45s
PID, device: 100002 cuda
Experiment ID: 60335
Total records: 12000
Dataset n_samples: 12000 7200 2400 2400
Test record ids (first 20): ['137448', '148956', '136914', '155610', '133454', '156996', '145930', '154208', '138164', '144190', '141346', '136111', '133728', '135488', '145796', '153197', '133620', '150418', '138790', '137164']
Test record ids (last 20): ['152600', '137920', '145610', '144568', '134835', '143983', '133814', '156786', '145996', '162595', '149943', '135568', '150737', '143403', '151976', '135534', '162703', '146267', '142320', '143686']
data_max: tensor([9.0000e+01, 1.0000e+00, 4.6230e+02, 4.0000e+00, 4.7200e+02, 5.3000e+00,
        4.6950e+03, 1.6920e+04, 3.6400e+04, 8.2800e+01, 2.0900e+02, 3.6200e+02,
        2.2100e+01, 2.8300e+02, 1.0000e+00, 1.5000e+01, 1.5910e+03, 5.2000e+01,
        6.1200e+01, 3.0000e+02, 2.2900e+01, 3.1000e+01, 2.9000e+01, 2.9900e+02,
        1.0000e+00, 1.8000e+02, 2.1100e+02, 2.1800e+02, 3.0000e+02, 1.0000e+02,
        5.0000e+02, 7.3500e+02, 2.2920e+03, 1.0000e+02, 1.0000e+02, 2.9500e+02,
        4.2100e+01, 4.9600e+01, 2.9910e+01, 1.0245e+04, 6.2519e+03],
       device='cuda:0')
data_min: tensor([ 1.5000e+01, -1.0000e+00, -1.0000e+00,  1.0000e+00, -1.0000e+00,
         1.0000e+00,  1.1000e+01,  1.0000e+00,  5.0000e+00,  0.0000e+00,
         0.0000e+00,  2.8000e+01,  1.0000e-01, -1.0000e+00,  2.1000e-01,
         3.0000e+00,  8.0000e+00,  5.0000e+00,  5.0000e+00,  0.0000e+00,
         1.8000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,
         9.8000e+01, -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  4.0000e-01,  5.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -1.7800e+01,  1.0000e-01,  1.0000e-02,  0.0000e+00,
         0.0000e+00], device='cuda:0')
time_max: tensor(48., device='cuda:0')
n_train_batches: 225
Exp has been early stopped!
/home/zepenghu/literature_project/t-PatchGNN/tPatchGNN/run_models.py
2024-09-16 12:18:42
run_models.py --dataset physionet --state def --history 24 --patience 10 --batch_size 32 --lr 1e-3 --patch_size 8 --stride 8 --nhead 1 --tf_layer 1 --nlayer 1 --te_dim 10 --node_dim 10 --hid_dim 64 --outlayer Linear --seed 3 --gpu 0
Namespace(state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=1, epoch=1000, patience=10, history=24, patch_size=8.0, stride=8.0, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, save='experiments/', load=None, seed=3, dataset='physionet', quantization=0.0, model='tPatchGNN', outlayer='Linear', hid_dim=64, te_dim=10, node_dim=10, gpu='0', npatch=3, device=device(type='cuda'), PID=100257, ndim=41)
Batch 0 Train - Loss (one batch): 0.13143
- Epoch 000, ExpID 62666
Train - Loss (one batch): 0.00711
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00760, 0.00760, 0.08720, 0.05248, 173.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.00737, 0.00737, 0.08587, 0.05245, 207.28%
Time spent: 20.47s
Batch 0 Train - Loss (one batch): 0.00588
- Epoch 001, ExpID 62666
Train - Loss (one batch): 0.00474
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00636, 0.00636, 0.07977, 0.04255, 138.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.00620, 0.00620, 0.07873, 0.04285, 142.47%
Time spent: 18.43s
Batch 0 Train - Loss (one batch): 0.00421
- Epoch 002, ExpID 62666
Train - Loss (one batch): 0.00664
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00621, 0.00621, 0.07878, 0.04154, 81.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.00597, 0.00597, 0.07724, 0.04142, 80.25%
Time spent: 18.24s
Batch 0 Train - Loss (one batch): 0.00480
- Epoch 003, ExpID 62666
Train - Loss (one batch): 0.00528
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00599, 0.00599, 0.07740, 0.03925, 72.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.00569, 0.00569, 0.07545, 0.03927, 75.17%
Time spent: 18.29s
Batch 0 Train - Loss (one batch): 0.00486
- Epoch 004, ExpID 62666
Train - Loss (one batch): 0.00378
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00587, 0.00587, 0.07661, 0.03859, 76.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00561, 0.00561, 0.07492, 0.03883, 79.10%
Time spent: 18.23s
Batch 0 Train - Loss (one batch): 0.00479
- Epoch 005, ExpID 62666
Train - Loss (one batch): 0.00758
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00618, 0.00618, 0.07862, 0.04168, 79.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00561, 0.00561, 0.07492, 0.03883, 79.10%
Time spent: 15.89s
Batch 0 Train - Loss (one batch): 0.00342
- Epoch 006, ExpID 62666
Train - Loss (one batch): 0.00591
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00586, 0.00586, 0.07655, 0.03941, 84.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00558, 0.00558, 0.07472, 0.03981, 85.39%
Time spent: 18.20s
Batch 0 Train - Loss (one batch): 0.00258
- Epoch 007, ExpID 62666
Train - Loss (one batch): 0.00415
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00585, 0.00585, 0.07649, 0.03905, 72.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.00562, 0.00562, 0.07497, 0.03919, 71.91%
Time spent: 18.23s
Batch 0 Train - Loss (one batch): 0.00546
- Epoch 008, ExpID 62666
Train - Loss (one batch): 0.00612
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00596, 0.00596, 0.07718, 0.03890, 72.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.00562, 0.00562, 0.07497, 0.03919, 71.91%
Time spent: 15.92s
Batch 0 Train - Loss (one batch): 0.00449
- Epoch 009, ExpID 62666
Train - Loss (one batch): 0.00754
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00608, 0.00608, 0.07797, 0.04062, 98.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.00562, 0.00562, 0.07497, 0.03919, 71.91%
Time spent: 15.93s
Batch 0 Train - Loss (one batch): 0.00397
- Epoch 010, ExpID 62666
Train - Loss (one batch): 0.00461
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00706, 0.00706, 0.08405, 0.04733, 85.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.00562, 0.00562, 0.07497, 0.03919, 71.91%
Time spent: 15.93s
Batch 0 Train - Loss (one batch): 0.00583
- Epoch 011, ExpID 62666
Train - Loss (one batch): 0.00308
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00592, 0.00592, 0.07693, 0.03960, 88.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.00562, 0.00562, 0.07497, 0.03919, 71.91%
Time spent: 15.89s
Batch 0 Train - Loss (one batch): 0.00395
- Epoch 012, ExpID 62666
Train - Loss (one batch): 0.00503
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00594, 0.00594, 0.07710, 0.03874, 79.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.00562, 0.00562, 0.07497, 0.03919, 71.91%
Time spent: 16.27s
Batch 0 Train - Loss (one batch): 0.01304
- Epoch 013, ExpID 62666
Train - Loss (one batch): 0.00318
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00585, 0.00585, 0.07647, 0.03773, 65.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.00538, 0.00538, 0.07337, 0.03731, 63.23%
Time spent: 18.23s
Batch 0 Train - Loss (one batch): 0.00386
- Epoch 014, ExpID 62666
Train - Loss (one batch): 0.00528
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00573, 0.00573, 0.07571, 0.03672, 56.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 14, 0.00538, 0.00538, 0.07334, 0.03666, 53.95%
Time spent: 18.13s
Batch 0 Train - Loss (one batch): 0.00343
- Epoch 015, ExpID 62666
Train - Loss (one batch): 0.00517
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00572, 0.00572, 0.07565, 0.03758, 77.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00558, 0.00558, 0.07470, 0.03788, 73.49%
Time spent: 18.29s
Batch 0 Train - Loss (one batch): 0.00302
- Epoch 016, ExpID 62666
Train - Loss (one batch): 0.00464
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00608, 0.00608, 0.07795, 0.04041, 64.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00558, 0.00558, 0.07470, 0.03788, 73.49%
Time spent: 15.84s
Batch 0 Train - Loss (one batch): 0.00395
- Epoch 017, ExpID 62666
Train - Loss (one batch): 0.00699
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00588, 0.00588, 0.07670, 0.04043, 81.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00558, 0.00558, 0.07470, 0.03788, 73.49%
Time spent: 15.90s
Batch 0 Train - Loss (one batch): 0.00529
- Epoch 018, ExpID 62666
Train - Loss (one batch): 0.00278
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00609, 0.00609, 0.07806, 0.03954, 74.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00558, 0.00558, 0.07470, 0.03788, 73.49%
Time spent: 15.84s
Batch 0 Train - Loss (one batch): 0.00486
- Epoch 019, ExpID 62666
Train - Loss (one batch): 0.00553
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00618, 0.00618, 0.07862, 0.04359, 129.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00558, 0.00558, 0.07470, 0.03788, 73.49%
Time spent: 15.89s
Batch 0 Train - Loss (one batch): 0.00339
- Epoch 020, ExpID 62666
Train - Loss (one batch): 0.00359
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00593, 0.00593, 0.07702, 0.04123, 130.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00558, 0.00558, 0.07470, 0.03788, 73.49%
Time spent: 15.81s
Batch 0 Train - Loss (one batch): 0.00744
- Epoch 021, ExpID 62666
Train - Loss (one batch): 0.00372
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00578, 0.00578, 0.07600, 0.03766, 62.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.00558, 0.00558, 0.07470, 0.03788, 73.49%
Time spent: 16.03s
Batch 0 Train - Loss (one batch): 0.00272
- Epoch 022, ExpID 62666
Train - Loss (one batch): 0.00461
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00567, 0.00567, 0.07529, 0.03701, 81.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.00536, 0.00536, 0.07320, 0.03699, 81.71%
Time spent: 18.29s
Batch 0 Train - Loss (one batch): 0.00445
- Epoch 023, ExpID 62666
Train - Loss (one batch): 0.00402
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00578, 0.00578, 0.07602, 0.04245, 169.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.00536, 0.00536, 0.07320, 0.03699, 81.71%
Time spent: 15.91s
Batch 0 Train - Loss (one batch): 0.00588
- Epoch 024, ExpID 62666
Train - Loss (one batch): 0.00504
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00582, 0.00582, 0.07628, 0.03875, 67.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.00536, 0.00536, 0.07320, 0.03699, 81.71%
Time spent: 15.85s
Batch 0 Train - Loss (one batch): 0.00367
- Epoch 025, ExpID 62666
Train - Loss (one batch): 0.00577
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00590, 0.00590, 0.07681, 0.03994, 84.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.00536, 0.00536, 0.07320, 0.03699, 81.71%
Time spent: 15.92s
Batch 0 Train - Loss (one batch): 0.00323
- Epoch 026, ExpID 62666
Train - Loss (one batch): 0.00590
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00572, 0.00572, 0.07562, 0.03687, 85.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.00536, 0.00536, 0.07320, 0.03699, 81.71%
Time spent: 15.87s
Batch 0 Train - Loss (one batch): 0.00905
- Epoch 027, ExpID 62666
Train - Loss (one batch): 0.00510
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00623, 0.00623, 0.07895, 0.04100, 76.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.00536, 0.00536, 0.07320, 0.03699, 81.71%
Time spent: 15.83s
Batch 0 Train - Loss (one batch): 0.00379
- Epoch 028, ExpID 62666
Train - Loss (one batch): 0.00439
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00583, 0.00583, 0.07638, 0.03970, 107.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.00536, 0.00536, 0.07320, 0.03699, 81.71%
Time spent: 15.87s
Batch 0 Train - Loss (one batch): 0.00553
- Epoch 029, ExpID 62666
Train - Loss (one batch): 0.00568
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00557, 0.00557, 0.07461, 0.03901, 149.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 18.24s
Batch 0 Train - Loss (one batch): 0.00259
- Epoch 030, ExpID 62666
Train - Loss (one batch): 0.00457
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00586, 0.00586, 0.07656, 0.03800, 76.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 15.84s
Batch 0 Train - Loss (one batch): 0.00323
- Epoch 031, ExpID 62666
Train - Loss (one batch): 0.00275
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00597, 0.00597, 0.07725, 0.04050, 101.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 15.83s
Batch 0 Train - Loss (one batch): 0.00459
- Epoch 032, ExpID 62666
Train - Loss (one batch): 0.00504
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00564, 0.00564, 0.07513, 0.03729, 66.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 15.94s
Batch 0 Train - Loss (one batch): 0.00546
- Epoch 033, ExpID 62666
Train - Loss (one batch): 0.00470
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00587, 0.00587, 0.07660, 0.03829, 65.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 16.00s
Batch 0 Train - Loss (one batch): 0.00340
- Epoch 034, ExpID 62666
Train - Loss (one batch): 0.00316
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00657, 0.00657, 0.08103, 0.04222, 70.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 16.02s
Batch 0 Train - Loss (one batch): 0.00835
- Epoch 035, ExpID 62666
Train - Loss (one batch): 0.00430
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00585, 0.00585, 0.07646, 0.03925, 73.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 15.97s
Batch 0 Train - Loss (one batch): 0.00427
- Epoch 036, ExpID 62666
Train - Loss (one batch): 0.00408
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00591, 0.00591, 0.07688, 0.03737, 66.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 15.95s
Batch 0 Train - Loss (one batch): 0.00985
- Epoch 037, ExpID 62666
Train - Loss (one batch): 0.00306
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00609, 0.00609, 0.07803, 0.03834, 74.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 15.79s
Batch 0 Train - Loss (one batch): 0.00582
- Epoch 038, ExpID 62666
Train - Loss (one batch): 0.00820
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00585, 0.00585, 0.07650, 0.03789, 99.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 16.00s
Batch 0 Train - Loss (one batch): 0.00436
- Epoch 039, ExpID 62666
Train - Loss (one batch): 0.00320
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00562, 0.00562, 0.07495, 0.03694, 75.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.00534, 0.00534, 0.07304, 0.03904, 150.72%
Time spent: 15.93s
PID, device: 100257 cuda
Experiment ID: 62666
Total records: 12000
Dataset n_samples: 12000 7200 2400 2400
Test record ids (first 20): ['137448', '148956', '136914', '155610', '133454', '156996', '145930', '154208', '138164', '144190', '141346', '136111', '133728', '135488', '145796', '153197', '133620', '150418', '138790', '137164']
Test record ids (last 20): ['152600', '137920', '145610', '144568', '134835', '143983', '133814', '156786', '145996', '162595', '149943', '135568', '150737', '143403', '151976', '135534', '162703', '146267', '142320', '143686']
data_max: tensor([9.0000e+01, 1.0000e+00, 4.6230e+02, 4.0000e+00, 4.7200e+02, 5.3000e+00,
        4.6950e+03, 1.6920e+04, 3.6400e+04, 8.2800e+01, 2.0900e+02, 3.6200e+02,
        2.2100e+01, 2.8300e+02, 1.0000e+00, 1.5000e+01, 1.5910e+03, 5.2000e+01,
        6.1200e+01, 3.0000e+02, 2.2900e+01, 3.1000e+01, 2.9000e+01, 2.9900e+02,
        1.0000e+00, 1.8000e+02, 2.1100e+02, 2.1800e+02, 3.0000e+02, 1.0000e+02,
        5.0000e+02, 7.3500e+02, 2.2920e+03, 1.0000e+02, 1.0000e+02, 2.9500e+02,
        4.2100e+01, 4.9600e+01, 2.9910e+01, 1.0245e+04, 6.2519e+03],
       device='cuda:0')
data_min: tensor([ 1.5000e+01, -1.0000e+00, -1.0000e+00,  1.0000e+00, -1.0000e+00,
         1.0000e+00,  1.1000e+01,  1.0000e+00,  5.0000e+00,  0.0000e+00,
         0.0000e+00,  2.8000e+01,  1.0000e-01, -1.0000e+00,  2.1000e-01,
         3.0000e+00,  8.0000e+00,  5.0000e+00,  5.0000e+00,  0.0000e+00,
         1.8000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,
         9.8000e+01, -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  4.0000e-01,  5.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -1.7800e+01,  1.0000e-01,  1.0000e-02,  0.0000e+00,
         0.0000e+00], device='cuda:0')
time_max: tensor(48., device='cuda:0')
n_train_batches: 225
Exp has been early stopped!
/home/zepenghu/literature_project/t-PatchGNN/tPatchGNN/run_models.py
2024-09-16 12:30:58
run_models.py --dataset physionet --state def --history 24 --patience 10 --batch_size 32 --lr 1e-3 --patch_size 8 --stride 8 --nhead 1 --tf_layer 1 --nlayer 1 --te_dim 10 --node_dim 10 --hid_dim 64 --outlayer Linear --seed 4 --gpu 0
Namespace(state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=1, epoch=1000, patience=10, history=24, patch_size=8.0, stride=8.0, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, save='experiments/', load=None, seed=4, dataset='physionet', quantization=0.0, model='tPatchGNN', outlayer='Linear', hid_dim=64, te_dim=10, node_dim=10, gpu='0', npatch=3, device=device(type='cuda'), PID=100590, ndim=41)
Batch 0 Train - Loss (one batch): 0.11841
- Epoch 000, ExpID 87069
Train - Loss (one batch): 0.00632
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00775, 0.00775, 0.08806, 0.05023, 323.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.00723, 0.00723, 0.08505, 0.05052, 371.43%
Time spent: 20.26s
Batch 0 Train - Loss (one batch): 0.00481
- Epoch 001, ExpID 87069
Train - Loss (one batch): 0.00657
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00629, 0.00629, 0.07929, 0.04136, 84.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.00576, 0.00576, 0.07593, 0.04104, 88.00%
Time spent: 18.92s
Batch 0 Train - Loss (one batch): 0.00585
- Epoch 002, ExpID 87069
Train - Loss (one batch): 0.00551
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00646, 0.00646, 0.08035, 0.04228, 125.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.00576, 0.00576, 0.07593, 0.04104, 88.00%
Time spent: 16.55s
Batch 0 Train - Loss (one batch): 0.00487
- Epoch 003, ExpID 87069
Train - Loss (one batch): 0.00953
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00596, 0.00596, 0.07721, 0.04119, 166.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.00555, 0.00555, 0.07448, 0.04129, 179.13%
Time spent: 19.00s
Batch 0 Train - Loss (one batch): 0.00316
- Epoch 004, ExpID 87069
Train - Loss (one batch): 0.00372
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00589, 0.00589, 0.07674, 0.03839, 91.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00541, 0.00541, 0.07355, 0.03816, 95.21%
Time spent: 18.89s
Batch 0 Train - Loss (one batch): 0.00487
- Epoch 005, ExpID 87069
Train - Loss (one batch): 0.00437
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00616, 0.00616, 0.07846, 0.04035, 90.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.00541, 0.00541, 0.07355, 0.03816, 95.21%
Time spent: 16.41s
Batch 0 Train - Loss (one batch): 0.00450
- Epoch 006, ExpID 87069
Train - Loss (one batch): 0.00384
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00577, 0.00577, 0.07595, 0.03727, 92.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 18.99s
Batch 0 Train - Loss (one batch): 0.00426
- Epoch 007, ExpID 87069
Train - Loss (one batch): 0.00403
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00590, 0.00590, 0.07684, 0.04110, 136.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.40s
Batch 0 Train - Loss (one batch): 0.00464
- Epoch 008, ExpID 87069
Train - Loss (one batch): 0.00462
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00584, 0.00584, 0.07640, 0.03878, 88.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.46s
Batch 0 Train - Loss (one batch): 0.00454
- Epoch 009, ExpID 87069
Train - Loss (one batch): 0.00314
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00581, 0.00581, 0.07621, 0.03785, 114.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.39s
Batch 0 Train - Loss (one batch): 0.00931
- Epoch 010, ExpID 87069
Train - Loss (one batch): 0.00412
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00600, 0.00600, 0.07749, 0.03825, 55.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.43s
Batch 0 Train - Loss (one batch): 0.00369
- Epoch 011, ExpID 87069
Train - Loss (one batch): 0.00327
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00602, 0.00602, 0.07757, 0.03948, 86.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.37s
Batch 0 Train - Loss (one batch): 0.00384
- Epoch 012, ExpID 87069
Train - Loss (one batch): 0.00384
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00587, 0.00587, 0.07662, 0.03862, 88.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.54s
Batch 0 Train - Loss (one batch): 0.00418
- Epoch 013, ExpID 87069
Train - Loss (one batch): 0.00412
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00607, 0.00607, 0.07788, 0.03761, 89.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.48s
Batch 0 Train - Loss (one batch): 0.00427
- Epoch 014, ExpID 87069
Train - Loss (one batch): 0.00370
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00591, 0.00591, 0.07688, 0.03953, 166.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.38s
Batch 0 Train - Loss (one batch): 0.00501
- Epoch 015, ExpID 87069
Train - Loss (one batch): 0.00355
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00612, 0.00612, 0.07825, 0.04025, 60.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.41s
Batch 0 Train - Loss (one batch): 0.00473
- Epoch 016, ExpID 87069
Train - Loss (one batch): 0.00334
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00585, 0.00585, 0.07649, 0.03745, 78.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.00547, 0.00547, 0.07395, 0.03746, 96.30%
Time spent: 16.46s
PID, device: 100590 cuda
Experiment ID: 87069
Total records: 12000
Dataset n_samples: 12000 7200 2400 2400
Test record ids (first 20): ['137448', '148956', '136914', '155610', '133454', '156996', '145930', '154208', '138164', '144190', '141346', '136111', '133728', '135488', '145796', '153197', '133620', '150418', '138790', '137164']
Test record ids (last 20): ['152600', '137920', '145610', '144568', '134835', '143983', '133814', '156786', '145996', '162595', '149943', '135568', '150737', '143403', '151976', '135534', '162703', '146267', '142320', '143686']
data_max: tensor([9.0000e+01, 1.0000e+00, 4.6230e+02, 4.0000e+00, 4.7200e+02, 5.3000e+00,
        4.6950e+03, 1.6920e+04, 3.6400e+04, 8.2800e+01, 2.0900e+02, 3.6200e+02,
        2.2100e+01, 2.8300e+02, 1.0000e+00, 1.5000e+01, 1.5910e+03, 5.2000e+01,
        6.1200e+01, 3.0000e+02, 2.2900e+01, 3.1000e+01, 2.9000e+01, 2.9900e+02,
        1.0000e+00, 1.8000e+02, 2.1100e+02, 2.1800e+02, 3.0000e+02, 1.0000e+02,
        5.0000e+02, 7.3500e+02, 2.2920e+03, 1.0000e+02, 1.0000e+02, 2.9500e+02,
        4.2100e+01, 4.9600e+01, 2.9910e+01, 1.0245e+04, 6.2519e+03],
       device='cuda:0')
data_min: tensor([ 1.5000e+01, -1.0000e+00, -1.0000e+00,  1.0000e+00, -1.0000e+00,
         1.0000e+00,  1.1000e+01,  1.0000e+00,  5.0000e+00,  0.0000e+00,
         0.0000e+00,  2.8000e+01,  1.0000e-01, -1.0000e+00,  2.1000e-01,
         3.0000e+00,  8.0000e+00,  5.0000e+00,  5.0000e+00,  0.0000e+00,
         1.8000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,
         9.8000e+01, -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  4.0000e-01,  5.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -1.7800e+01,  1.0000e-01,  1.0000e-02,  0.0000e+00,
         0.0000e+00], device='cuda:0')
time_max: tensor(48., device='cuda:0')
n_train_batches: 225
Exp has been early stopped!
/home/zepenghu/literature_project/t-PatchGNN/tPatchGNN/run_models.py
2024-09-16 12:36:58
run_models.py --dataset physionet --state def --history 24 --patience 10 --batch_size 32 --lr 1e-3 --patch_size 8 --stride 8 --nhead 1 --tf_layer 1 --nlayer 1 --te_dim 10 --node_dim 10 --hid_dim 64 --outlayer Linear --seed 5 --gpu 0
Namespace(state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=1, epoch=1000, patience=10, history=24, patch_size=8.0, stride=8.0, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, save='experiments/', load=None, seed=5, dataset='physionet', quantization=0.0, model='tPatchGNN', outlayer='Linear', hid_dim=64, te_dim=10, node_dim=10, gpu='0', npatch=3, device=device(type='cuda'), PID=100869, ndim=41)
Batch 0 Train - Loss (one batch): 0.19215
- Epoch 000, ExpID 19127
Train - Loss (one batch): 0.00827
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00773, 0.00773, 0.08791, 0.05117, 112.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.00745, 0.00745, 0.08633, 0.05113, 115.24%
Time spent: 19.76s
Batch 0 Train - Loss (one batch): 0.00494
- Epoch 001, ExpID 19127
Train - Loss (one batch): 0.00519
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00689, 0.00689, 0.08300, 0.04555, 141.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.00658, 0.00658, 0.08110, 0.04550, 152.19%
Time spent: 18.37s
Batch 0 Train - Loss (one batch): 0.00508
- Epoch 002, ExpID 19127
Train - Loss (one batch): 0.00593
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00683, 0.00683, 0.08266, 0.04555, 90.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.00680, 0.00680, 0.08244, 0.04583, 94.42%
Time spent: 18.15s
Batch 0 Train - Loss (one batch): 0.00471
- Epoch 003, ExpID 19127
Train - Loss (one batch): 0.00461
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00643, 0.00643, 0.08016, 0.04362, 74.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.00626, 0.00626, 0.07915, 0.04392, 76.64%
Time spent: 18.24s
Batch 0 Train - Loss (one batch): 0.00400
- Epoch 004, ExpID 19127
Train - Loss (one batch): 0.00381
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00656, 0.00656, 0.08102, 0.04405, 87.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.00626, 0.00626, 0.07915, 0.04392, 76.64%
Time spent: 16.12s
Batch 0 Train - Loss (one batch): 0.00659
- Epoch 005, ExpID 19127
Train - Loss (one batch): 0.00601
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00641, 0.00641, 0.08006, 0.04310, 81.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.00608, 0.00608, 0.07796, 0.04295, 83.53%
Time spent: 18.17s
Batch 0 Train - Loss (one batch): 0.00917
- Epoch 006, ExpID 19127
Train - Loss (one batch): 0.00635
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00671, 0.00671, 0.08189, 0.04353, 55.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.00608, 0.00608, 0.07796, 0.04295, 83.53%
Time spent: 15.95s
Batch 0 Train - Loss (one batch): 0.00748
- Epoch 007, ExpID 19127
Train - Loss (one batch): 0.00433
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00630, 0.00630, 0.07936, 0.04232, 58.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.00608, 0.00608, 0.07798, 0.04256, 61.48%
Time spent: 18.49s
Batch 0 Train - Loss (one batch): 0.00456
- Epoch 008, ExpID 19127
Train - Loss (one batch): 0.00354
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00617, 0.00617, 0.07852, 0.04167, 75.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.00576, 0.00576, 0.07588, 0.04139, 77.74%
Time spent: 18.35s
Batch 0 Train - Loss (one batch): 0.00714
- Epoch 009, ExpID 19127
Train - Loss (one batch): 0.00403
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00701, 0.00701, 0.08374, 0.04746, 110.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.00576, 0.00576, 0.07588, 0.04139, 77.74%
Time spent: 16.06s
Batch 0 Train - Loss (one batch): 0.00504
- Epoch 010, ExpID 19127
Train - Loss (one batch): 0.00521
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00616, 0.00616, 0.07851, 0.04267, 121.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.00592, 0.00592, 0.07694, 0.04260, 120.61%
Time spent: 18.21s
Batch 0 Train - Loss (one batch): 0.00451
- Epoch 011, ExpID 19127
Train - Loss (one batch): 0.00463
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00612, 0.00612, 0.07821, 0.03949, 60.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.00572, 0.00572, 0.07564, 0.03937, 62.33%
Time spent: 18.86s
Batch 0 Train - Loss (one batch): 0.00571
- Epoch 012, ExpID 19127
Train - Loss (one batch): 0.00429
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00624, 0.00624, 0.07898, 0.04234, 50.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.00572, 0.00572, 0.07564, 0.03937, 62.33%
Time spent: 16.62s
Batch 0 Train - Loss (one batch): 0.00511
- Epoch 013, ExpID 19127
Train - Loss (one batch): 0.00562
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00608, 0.00608, 0.07800, 0.04026, 74.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.00564, 0.00564, 0.07509, 0.03998, 73.52%
Time spent: 19.00s
Batch 0 Train - Loss (one batch): 0.00406
- Epoch 014, ExpID 19127
Train - Loss (one batch): 0.00399
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00609, 0.00609, 0.07806, 0.04033, 80.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.00564, 0.00564, 0.07509, 0.03998, 73.52%
Time spent: 16.44s
Batch 0 Train - Loss (one batch): 0.00542
- Epoch 015, ExpID 19127
Train - Loss (one batch): 0.00642
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00613, 0.00613, 0.07832, 0.04040, 110.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.00564, 0.00564, 0.07509, 0.03998, 73.52%
Time spent: 16.41s
Batch 0 Train - Loss (one batch): 0.00394
- Epoch 016, ExpID 19127
Train - Loss (one batch): 0.00467
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00577, 0.00577, 0.07597, 0.03806, 81.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.00536, 0.00536, 0.07319, 0.03770, 78.16%
Time spent: 18.85s
Batch 0 Train - Loss (one batch): 0.00408
- Epoch 017, ExpID 19127
Train - Loss (one batch): 0.00512
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00631, 0.00631, 0.07946, 0.04332, 75.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.00536, 0.00536, 0.07319, 0.03770, 78.16%
Time spent: 17.11s
Batch 0 Train - Loss (one batch): 0.00305
- Epoch 018, ExpID 19127
Train - Loss (one batch): 0.00565
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00652, 0.00652, 0.08075, 0.04427, 70.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.00536, 0.00536, 0.07319, 0.03770, 78.16%
Time spent: 17.35s
Batch 0 Train - Loss (one batch): 0.00728
- Epoch 019, ExpID 19127
Train - Loss (one batch): 0.00407
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00634, 0.00634, 0.07962, 0.04231, 119.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.00536, 0.00536, 0.07319, 0.03770, 78.16%
Time spent: 17.44s
Batch 0 Train - Loss (one batch): 0.00387
- Epoch 020, ExpID 19127
Train - Loss (one batch): 0.00489
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00576, 0.00576, 0.07591, 0.03751, 80.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 19.83s
Batch 0 Train - Loss (one batch): 0.00418
- Epoch 021, ExpID 19127
Train - Loss (one batch): 0.00632
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00597, 0.00597, 0.07724, 0.03908, 92.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.27s
Batch 0 Train - Loss (one batch): 0.00443
- Epoch 022, ExpID 19127
Train - Loss (one batch): 0.00514
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00638, 0.00638, 0.07986, 0.04139, 74.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.31s
Batch 0 Train - Loss (one batch): 0.00406
- Epoch 023, ExpID 19127
Train - Loss (one batch): 0.00318
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00591, 0.00591, 0.07691, 0.03891, 103.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.25s
Batch 0 Train - Loss (one batch): 0.00298
- Epoch 024, ExpID 19127
Train - Loss (one batch): 0.00860
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00629, 0.00629, 0.07931, 0.04288, 102.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.34s
Batch 0 Train - Loss (one batch): 0.00484
- Epoch 025, ExpID 19127
Train - Loss (one batch): 0.00390
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00605, 0.00605, 0.07778, 0.04099, 108.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.27s
Batch 0 Train - Loss (one batch): 0.00785
- Epoch 026, ExpID 19127
Train - Loss (one batch): 0.00407
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00596, 0.00596, 0.07720, 0.04035, 133.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.30s
Batch 0 Train - Loss (one batch): 0.00482
- Epoch 027, ExpID 19127
Train - Loss (one batch): 0.00417
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00597, 0.00597, 0.07729, 0.03920, 103.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.27s
Batch 0 Train - Loss (one batch): 0.00376
- Epoch 028, ExpID 19127
Train - Loss (one batch): 0.00367
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00578, 0.00578, 0.07600, 0.03898, 61.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.33s
Batch 0 Train - Loss (one batch): 0.00656
- Epoch 029, ExpID 19127
Train - Loss (one batch): 0.00384
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00597, 0.00597, 0.07726, 0.04035, 84.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.37s
Batch 0 Train - Loss (one batch): 0.00524
- Epoch 030, ExpID 19127
Train - Loss (one batch): 0.00292
Val - Loss, MSE, RMSE, MAE, MAPE: 0.00584, 0.00584, 0.07641, 0.03837, 58.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.00532, 0.00532, 0.07291, 0.03724, 85.03%
Time spent: 16.39s
PID, device: 100869 cuda
Experiment ID: 19127
Total records: 12000
Dataset n_samples: 12000 7200 2400 2400
Test record ids (first 20): ['137448', '148956', '136914', '155610', '133454', '156996', '145930', '154208', '138164', '144190', '141346', '136111', '133728', '135488', '145796', '153197', '133620', '150418', '138790', '137164']
Test record ids (last 20): ['152600', '137920', '145610', '144568', '134835', '143983', '133814', '156786', '145996', '162595', '149943', '135568', '150737', '143403', '151976', '135534', '162703', '146267', '142320', '143686']
data_max: tensor([9.0000e+01, 1.0000e+00, 4.6230e+02, 4.0000e+00, 4.7200e+02, 5.3000e+00,
        4.6950e+03, 1.6920e+04, 3.6400e+04, 8.2800e+01, 2.0900e+02, 3.6200e+02,
        2.2100e+01, 2.8300e+02, 1.0000e+00, 1.5000e+01, 1.5910e+03, 5.2000e+01,
        6.1200e+01, 3.0000e+02, 2.2900e+01, 3.1000e+01, 2.9000e+01, 2.9900e+02,
        1.0000e+00, 1.8000e+02, 2.1100e+02, 2.1800e+02, 3.0000e+02, 1.0000e+02,
        5.0000e+02, 7.3500e+02, 2.2920e+03, 1.0000e+02, 1.0000e+02, 2.9500e+02,
        4.2100e+01, 4.9600e+01, 2.9910e+01, 1.0245e+04, 6.2519e+03],
       device='cuda:0')
data_min: tensor([ 1.5000e+01, -1.0000e+00, -1.0000e+00,  1.0000e+00, -1.0000e+00,
         1.0000e+00,  1.1000e+01,  1.0000e+00,  5.0000e+00,  0.0000e+00,
         0.0000e+00,  2.8000e+01,  1.0000e-01, -1.0000e+00,  2.1000e-01,
         3.0000e+00,  8.0000e+00,  5.0000e+00,  5.0000e+00,  0.0000e+00,
         1.8000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,
         9.8000e+01, -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  4.0000e-01,  5.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -1.7800e+01,  1.0000e-01,  1.0000e-02,  0.0000e+00,
         0.0000e+00], device='cuda:0')
time_max: tensor(48., device='cuda:0')
n_train_batches: 225
Exp has been early stopped!
